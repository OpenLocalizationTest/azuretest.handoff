<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="pl-pl" original="2/22/2016 7:21:49 AM" tool-id="MarkdownTransformer" product-name="N/A" product-version="N/A" build-num="1">
    <header>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">9eef7a52eb6bba5978ade4fb6396dfe613190b51</xliffext:olfilehash>
      <tool tool-id="MarkdownTransformer" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group extype="content">
        <group id="101">
          <trans-unit id="101" xml:space="preserve">
            <source>MapReduce and SSH connection with Hadoop in HDInsight | Microsoft Azure</source>
            <target state="new">MapReduce and SSH connection with Hadoop in HDInsight | Microsoft Azure</target>
          </trans-unit>
          <trans-unit id="102" xml:space="preserve">
            <source>Learn how to use SSH to run MapReduce jobs using Hadoop on HDInsight.</source>
            <target state="new">Learn how to use SSH to run MapReduce jobs using Hadoop on HDInsight.</target>
          </trans-unit>
          <trans-unit id="103" xml:space="preserve">
            <source>Use MapReduce with Hadoop on HDInsight with SSH</source>
            <target state="new">Use MapReduce with Hadoop on HDInsight with SSH</target>
          </trans-unit>
          <trans-unit id="104" xml:space="preserve">
            <source><ph id="1">&lt;token href="../../includes/hdinsight-selector-use-mapreduce.md"/&gt;</ph></source>
            <target state="new"><ph id="1">&lt;token href="../../includes/hdinsight-selector-use-mapreduce.md"/&gt;</ph></target>
          </trans-unit>
          <trans-unit id="105" xml:space="preserve">
            <source>In this article, you will learn how to use Secure Shell (SSH) to connect to a Hadoop on HDInsight cluster and then submit MapReduce jobs by using Hadoop commands.</source>
            <target state="new">In this article, you will learn how to use Secure Shell (SSH) to connect to a Hadoop on HDInsight cluster and then submit MapReduce jobs by using Hadoop commands.</target>
          </trans-unit>
          <trans-unit id="106" xml:space="preserve">
            <source>If you are already familiar with using Linux-based Hadoop servers, but you are new to HDInsight, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Linux-based HDInsight tips<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">If you are already familiar with using Linux-based Hadoop servers, but you are new to HDInsight, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Linux-based HDInsight tips<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="107" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Prerequisites</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Prerequisites</target>
          </trans-unit>
          <trans-unit id="108" xml:space="preserve">
            <source>To complete the steps in this article, you will need the following:</source>
            <target state="new">To complete the steps in this article, you will need the following:</target>
          </trans-unit>
          <trans-unit id="109" xml:space="preserve">
            <source>A Linux-based HDInsight (Hadoop on HDInsight) cluster</source>
            <target state="new">A Linux-based HDInsight (Hadoop on HDInsight) cluster</target>
          </trans-unit>
          <trans-unit id="110" xml:space="preserve">
            <source>An SSH client.</source>
            <target state="new">An SSH client.</target>
          </trans-unit>
          <trans-unit id="111" xml:space="preserve">
            <source>Linux, Unix, and Mac operating systems should come with an SSH client.</source>
            <target state="new">Linux, Unix, and Mac operating systems should come with an SSH client.</target>
          </trans-unit>
          <trans-unit id="112" xml:space="preserve">
            <source>Windows users must download a client, such as <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>PuTTY<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">Windows users must download a client, such as <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>PuTTY<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="113" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Connect with SSH</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Connect with SSH</target>
          </trans-unit>
          <trans-unit id="114" xml:space="preserve">
            <source>Connect to the fully qualified domain name (FQDN) of your HDInsight cluster by using the SSH command.</source>
            <target state="new">Connect to the fully qualified domain name (FQDN) of your HDInsight cluster by using the SSH command.</target>
          </trans-unit>
          <trans-unit id="115" xml:space="preserve">
            <source>The FQDN will be the name you gave the cluster, followed by <bpt id="2">&lt;strong&gt;</bpt>.azurehdinsight.net<ept id="2">&lt;/strong&gt;</ept>.</source>
            <target state="new">The FQDN will be the name you gave the cluster, followed by <bpt id="2">&lt;strong&gt;</bpt>.azurehdinsight.net<ept id="2">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="116" xml:space="preserve">
            <source>For example, the following would connect to a cluster named <bpt id="2">&lt;strong&gt;</bpt>myhdinsight<ept id="2">&lt;/strong&gt;</ept>:</source>
            <target state="new">For example, the following would connect to a cluster named <bpt id="2">&lt;strong&gt;</bpt>myhdinsight<ept id="2">&lt;/strong&gt;</ept>:</target>
          </trans-unit>
          <trans-unit id="117" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>If you provided a certificate key for SSH authentication<ept id="1">&lt;/strong&gt;</ept> when you created the HDInsight cluster, you may need to specify the location of the private key on your client system, for example:</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>If you provided a certificate key for SSH authentication<ept id="1">&lt;/strong&gt;</ept> when you created the HDInsight cluster, you may need to specify the location of the private key on your client system, for example:</target>
          </trans-unit>
          <trans-unit id="118" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>If you provided a password for SSH authentication<ept id="1">&lt;/strong&gt;</ept> when you created the HDInsight cluster, you will need to provide the password when prompted.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>If you provided a password for SSH authentication<ept id="1">&lt;/strong&gt;</ept> when you created the HDInsight cluster, you will need to provide the password when prompted.</target>
          </trans-unit>
          <trans-unit id="119" xml:space="preserve">
            <source>For more information on using SSH with HDInsight, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, OS X, and Unix<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information on using SSH with HDInsight, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, OS X, and Unix<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="120" xml:space="preserve">
            <source>PuTTY (Windows clients)</source>
            <target state="new">PuTTY (Windows clients)</target>
          </trans-unit>
          <trans-unit id="121" xml:space="preserve">
            <source>Windows does not provide a built-in SSH client.</source>
            <target state="new">Windows does not provide a built-in SSH client.</target>
          </trans-unit>
          <trans-unit id="122" xml:space="preserve">
            <source>We recommend using <bpt id="2">&lt;strong&gt;</bpt>PuTTY<ept id="2">&lt;/strong&gt;</ept>, which can be downloaded from <bpt id="4CapsExtId1">&lt;link&gt;</bpt><bpt id="4CapsExtId2">&lt;linkText&gt;</bpt>http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html<ept id="4CapsExtId2">&lt;/linkText&gt;</ept><bpt id="4CapsExtId3">&lt;title&gt;</bpt><ept id="4CapsExtId3">&lt;/title&gt;</ept><ept id="4CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">We recommend using <bpt id="2">&lt;strong&gt;</bpt>PuTTY<ept id="2">&lt;/strong&gt;</ept>, which can be downloaded from <bpt id="4CapsExtId1">&lt;link&gt;</bpt><bpt id="4CapsExtId2">&lt;linkText&gt;</bpt>http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html<ept id="4CapsExtId2">&lt;/linkText&gt;</ept><bpt id="4CapsExtId3">&lt;title&gt;</bpt><ept id="4CapsExtId3">&lt;/title&gt;</ept><ept id="4CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="123" xml:space="preserve">
            <source>For more information on using PuTTY, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows <ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information on using PuTTY, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows <ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="124" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Use Hadoop commands</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Use Hadoop commands</target>
          </trans-unit>
          <trans-unit id="125" xml:space="preserve">
            <source>After you are connected to the HDInsight cluster, use the following <bpt id="2">&lt;strong&gt;</bpt>Hadoop<ept id="2">&lt;/strong&gt;</ept> command to start a MapReduce job:</source>
            <target state="new">After you are connected to the HDInsight cluster, use the following <bpt id="2">&lt;strong&gt;</bpt>Hadoop<ept id="2">&lt;/strong&gt;</ept> command to start a MapReduce job:</target>
          </trans-unit>
          <trans-unit id="126" xml:space="preserve">
            <source>This starts the <bpt id="2">&lt;strong&gt;</bpt>wordcount<ept id="2">&lt;/strong&gt;</ept> class, which is contained in the <bpt id="4">&lt;strong&gt;</bpt>hadoop-mapreduce-examples.jar<ept id="4">&lt;/strong&gt;</ept> file.</source>
            <target state="new">This starts the <bpt id="2">&lt;strong&gt;</bpt>wordcount<ept id="2">&lt;/strong&gt;</ept> class, which is contained in the <bpt id="4">&lt;strong&gt;</bpt>hadoop-mapreduce-examples.jar<ept id="4">&lt;/strong&gt;</ept> file.</target>
          </trans-unit>
          <trans-unit id="127" xml:space="preserve">
            <source>As input, it uses the <bpt id="2">&lt;strong&gt;</bpt>wasb://example/data/gutenberg/davinci.txt<ept id="2">&lt;/strong&gt;</ept> document, and output is stored at <bpt id="4">&lt;strong&gt;</bpt>wasb:///example/data/WordCountOutput<ept id="4">&lt;/strong&gt;</ept>.</source>
            <target state="new">As input, it uses the <bpt id="2">&lt;strong&gt;</bpt>wasb://example/data/gutenberg/davinci.txt<ept id="2">&lt;/strong&gt;</ept> document, and output is stored at <bpt id="4">&lt;strong&gt;</bpt>wasb:///example/data/WordCountOutput<ept id="4">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="128" xml:space="preserve">
            <source>For more information about this MapReduce job and the example data, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce in Hadoop on HDInsight<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information about this MapReduce job and the example data, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce in Hadoop on HDInsight<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="129" xml:space="preserve">
            <source>The job emits details as it processes, and it returns information similar to the following when the job completes:</source>
            <target state="new">The job emits details as it processes, and it returns information similar to the following when the job completes:</target>
          </trans-unit>
          <trans-unit id="130" xml:space="preserve">
            <source>When the job completes, use the following command to list the output files that are stored at <bpt id="2">&lt;strong&gt;</bpt>wasb://example/data/WordCountOutput<ept id="2">&lt;/strong&gt;</ept>:</source>
            <target state="new">When the job completes, use the following command to list the output files that are stored at <bpt id="2">&lt;strong&gt;</bpt>wasb://example/data/WordCountOutput<ept id="2">&lt;/strong&gt;</ept>:</target>
          </trans-unit>
          <trans-unit id="131" xml:space="preserve">
            <source>This should display two files, <bpt id="2">&lt;strong&gt;</bpt>_SUCCESS<ept id="2">&lt;/strong&gt;</ept> and <bpt id="4">&lt;strong&gt;</bpt>part-r-00000<ept id="4">&lt;/strong&gt;</ept>.</source>
            <target state="new">This should display two files, <bpt id="2">&lt;strong&gt;</bpt>_SUCCESS<ept id="2">&lt;/strong&gt;</ept> and <bpt id="4">&lt;strong&gt;</bpt>part-r-00000<ept id="4">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="132" xml:space="preserve">
            <source>The <bpt id="2">&lt;strong&gt;</bpt>part-r-00000<ept id="2">&lt;/strong&gt;</ept> file contains the output for this job.</source>
            <target state="new">The <bpt id="2">&lt;strong&gt;</bpt>part-r-00000<ept id="2">&lt;/strong&gt;</ept> file contains the output for this job.</target>
          </trans-unit>
          <trans-unit id="133" xml:space="preserve">
            <source>Some MapReduce jobs may split the results across multiple <bpt id="2">&lt;strong&gt;</bpt>part-r-#####<ept id="2">&lt;/strong&gt;</ept> files.</source>
            <target state="new">Some MapReduce jobs may split the results across multiple <bpt id="2">&lt;strong&gt;</bpt>part-r-#####<ept id="2">&lt;/strong&gt;</ept> files.</target>
          </trans-unit>
          <trans-unit id="134" xml:space="preserve">
            <source>If so, use the ##### suffix to indicate the order of the files.</source>
            <target state="new">If so, use the ##### suffix to indicate the order of the files.</target>
          </trans-unit>
          <trans-unit id="135" xml:space="preserve">
            <source>To view the output, use the following command:</source>
            <target state="new">To view the output, use the following command:</target>
          </trans-unit>
          <trans-unit id="136" xml:space="preserve">
            <source>This displays a list of the words that are contained in the <bpt id="2">&lt;strong&gt;</bpt>wasb://example/data/gutenberg/davinci.txt<ept id="2">&lt;/strong&gt;</ept> file and the number of times each word occured.</source>
            <target state="new">This displays a list of the words that are contained in the <bpt id="2">&lt;strong&gt;</bpt>wasb://example/data/gutenberg/davinci.txt<ept id="2">&lt;/strong&gt;</ept> file and the number of times each word occured.</target>
          </trans-unit>
          <trans-unit id="137" xml:space="preserve">
            <source>The following is an example of the data that will be contained in the file:</source>
            <target state="new">The following is an example of the data that will be contained in the file:</target>
          </trans-unit>
          <trans-unit id="138" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Summary</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Summary</target>
          </trans-unit>
          <trans-unit id="139" xml:space="preserve">
            <source>As you can see, Hadoop commands provide an easy way to run MapReduce jobs in an HDInsight cluster and then view the job output.</source>
            <target state="new">As you can see, Hadoop commands provide an easy way to run MapReduce jobs in an HDInsight cluster and then view the job output.</target>
          </trans-unit>
          <trans-unit id="140" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Next steps</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Next steps</target>
          </trans-unit>
          <trans-unit id="141" xml:space="preserve">
            <source>For general information about MapReduce jobs in HDInsight:</source>
            <target state="new">For general information about MapReduce jobs in HDInsight:</target>
          </trans-unit>
          <trans-unit id="142" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce on HDInsight Hadoop<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce on HDInsight Hadoop<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="143" xml:space="preserve">
            <source>For information about other ways you can work with Hadoop on HDInsight:</source>
            <target state="new">For information about other ways you can work with Hadoop on HDInsight:</target>
          </trans-unit>
          <trans-unit id="144" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with Hadoop on HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with Hadoop on HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="145" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Pig with Hadoop on HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Pig with Hadoop on HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="146" xml:space="preserve">
            <source>test</source>
            <target state="new">test</target>
          </trans-unit>
        </group>
      </group>
    </body>
  </file>
</xliff>