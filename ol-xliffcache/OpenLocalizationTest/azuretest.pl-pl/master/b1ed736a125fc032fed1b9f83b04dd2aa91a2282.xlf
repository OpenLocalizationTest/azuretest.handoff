<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="pl-pl" original="2/22/2016 7:22:17 AM" tool-id="MarkdownTransformer" product-name="N/A" product-version="N/A" build-num="1">
    <header>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">b1ed736a125fc032fed1b9f83b04dd2aa91a2282</xliffext:olfilehash>
      <tool tool-id="MarkdownTransformer" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group extype="content">
        <group id="101">
          <trans-unit id="101" xml:space="preserve">
            <source>Use Hadoop Pig with Remote Desktop in HDInsight | Microsoft Azure</source>
            <target state="new">Use Hadoop Pig with Remote Desktop in HDInsight | Microsoft Azure</target>
          </trans-unit>
          <trans-unit id="102" xml:space="preserve">
            <source>Learn how to use the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based Hadoop cluster in HDInsight.</source>
            <target state="new">Learn how to use the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based Hadoop cluster in HDInsight.</target>
          </trans-unit>
          <trans-unit id="103" xml:space="preserve">
            <source>Run Pig jobs from a Remote Desktop connection</source>
            <target state="new">Run Pig jobs from a Remote Desktop connection</target>
          </trans-unit>
          <trans-unit id="104" xml:space="preserve">
            <source><ph id="1">&lt;token href="../../includes/hdinsight-selector-use-pig.md"/&gt;</ph></source>
            <target state="new"><ph id="1">&lt;token href="../../includes/hdinsight-selector-use-pig.md"/&gt;</ph></target>
          </trans-unit>
          <trans-unit id="105" xml:space="preserve">
            <source>This document provides a walkthrough for using the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based HDInsight cluster.</source>
            <target state="new">This document provides a walkthrough for using the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="106" xml:space="preserve">
            <source>Pig Latin allows you to create MapReduce applications by describing data transformations, rather than map and reduce functions.</source>
            <target state="new">Pig Latin allows you to create MapReduce applications by describing data transformations, rather than map and reduce functions.</target>
          </trans-unit>
          <trans-unit id="107" xml:space="preserve">
            <source>In this document, learn how to</source>
            <target state="new">In this document, learn how to</target>
          </trans-unit>
          <trans-unit id="108" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Prerequisites</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Prerequisites</target>
          </trans-unit>
          <trans-unit id="109" xml:space="preserve">
            <source>To complete the steps in this article, you will need the following.</source>
            <target state="new">To complete the steps in this article, you will need the following.</target>
          </trans-unit>
          <trans-unit id="110" xml:space="preserve">
            <source>A Windows-based HDInsight (Hadoop on HDInsight) cluster</source>
            <target state="new">A Windows-based HDInsight (Hadoop on HDInsight) cluster</target>
          </trans-unit>
          <trans-unit id="111" xml:space="preserve">
            <source>A client computer running Windows 10, Windows 8, or Windows 7</source>
            <target state="new">A client computer running Windows 10, Windows 8, or Windows 7</target>
          </trans-unit>
          <trans-unit id="112" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Connect with Remote Desktop</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Connect with Remote Desktop</target>
          </trans-unit>
          <trans-unit id="113" xml:space="preserve">
            <source>Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Connect to HDInsight clusters using RDP<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Connect to HDInsight clusters using RDP<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="114" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Use the Pig command</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Use the Pig command</target>
          </trans-unit>
          <trans-unit id="115" xml:space="preserve">
            <source>After you have a Remote Desktop connection, start the <bpt id="2">&lt;strong&gt;</bpt>Hadoop Command Line<ept id="2">&lt;/strong&gt;</ept> by using the icon on the desktop.</source>
            <target state="new">After you have a Remote Desktop connection, start the <bpt id="2">&lt;strong&gt;</bpt>Hadoop Command Line<ept id="2">&lt;/strong&gt;</ept> by using the icon on the desktop.</target>
          </trans-unit>
          <trans-unit id="116" xml:space="preserve">
            <source>Use the following to start the Pig command:</source>
            <target state="new">Use the following to start the Pig command:</target>
          </trans-unit>
          <trans-unit id="117" xml:space="preserve">
            <source>You will be presented with a <bpt id="2">&lt;code&gt;</bpt>grunt&gt;<ept id="2">&lt;/code&gt;</ept> prompt.</source>
            <target state="new">You will be presented with a <bpt id="2">&lt;code&gt;</bpt>grunt&gt;<ept id="2">&lt;/code&gt;</ept> prompt.</target>
          </trans-unit>
          <trans-unit id="118" xml:space="preserve">
            <source>Enter the following statement:</source>
            <target state="new">Enter the following statement:</target>
          </trans-unit>
          <trans-unit id="119" xml:space="preserve">
            <source>This command loads the contents of the sample.log file into the LOGS file.</source>
            <target state="new">This command loads the contents of the sample.log file into the LOGS file.</target>
          </trans-unit>
          <trans-unit id="120" xml:space="preserve">
            <source>You can view the contents of the file by using the following command:</source>
            <target state="new">You can view the contents of the file by using the following command:</target>
          </trans-unit>
          <trans-unit id="121" xml:space="preserve">
            <source>Transform the data by applying a regular expression to extract only the logging level from each record:</source>
            <target state="new">Transform the data by applying a regular expression to extract only the logging level from each record:</target>
          </trans-unit>
          <trans-unit id="122" xml:space="preserve">
            <source>You can use <bpt id="2">&lt;strong&gt;</bpt>DUMP<ept id="2">&lt;/strong&gt;</ept> to view the data after the transformation.</source>
            <target state="new">You can use <bpt id="2">&lt;strong&gt;</bpt>DUMP<ept id="2">&lt;/strong&gt;</ept> to view the data after the transformation.</target>
          </trans-unit>
          <trans-unit id="123" xml:space="preserve">
            <source>In this case, <bpt id="2">&lt;code&gt;</bpt>DUMP LEVELS;<ept id="2">&lt;/code&gt;</ept>.</source>
            <target state="new">In this case, <bpt id="2">&lt;code&gt;</bpt>DUMP LEVELS;<ept id="2">&lt;/code&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="124" xml:space="preserve">
            <source>Continue applying transformations by using the following statements.</source>
            <target state="new">Continue applying transformations by using the following statements.</target>
          </trans-unit>
          <trans-unit id="125" xml:space="preserve">
            <source>Use <bpt id="2">&lt;code&gt;</bpt>DUMP<ept id="2">&lt;/code&gt;</ept> to view the result of the transformation after each step.</source>
            <target state="new">Use <bpt id="2">&lt;code&gt;</bpt>DUMP<ept id="2">&lt;/code&gt;</ept> to view the result of the transformation after each step.</target>
          </trans-unit>
          <trans-unit id="126" xml:space="preserve">
            <source>Statement</source>
            <target state="new">Statement</target>
          </trans-unit>
          <trans-unit id="127" xml:space="preserve">
            <source>What it does</source>
            <target state="new">What it does</target>
          </trans-unit>
          <trans-unit id="128" xml:space="preserve">
            <source>FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;</source>
            <target state="new">FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;</target>
          </trans-unit>
          <trans-unit id="129" xml:space="preserve">
            <source>Removes rows that contain a null value for the log level and stores the results into FILTEREDLEVELS.</source>
            <target state="new">Removes rows that contain a null value for the log level and stores the results into FILTEREDLEVELS.</target>
          </trans-unit>
          <trans-unit id="130" xml:space="preserve">
            <source>GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;</source>
            <target state="new">GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;</target>
          </trans-unit>
          <trans-unit id="131" xml:space="preserve">
            <source>Groups the rows by log level and stores the results into GROUPEDLEVELS.</source>
            <target state="new">Groups the rows by log level and stores the results into GROUPEDLEVELS.</target>
          </trans-unit>
          <trans-unit id="132" xml:space="preserve">
            <source>FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL, COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;</source>
            <target state="new">FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL, COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;</target>
          </trans-unit>
          <trans-unit id="133" xml:space="preserve">
            <source>Creates a new set of data that contains each unique log level value and how many times it occurs. This is stored into FREQUENCIES</source>
            <target state="new">Creates a new set of data that contains each unique log level value and how many times it occurs. This is stored into FREQUENCIES</target>
          </trans-unit>
          <trans-unit id="134" xml:space="preserve">
            <source>RESULT = order FREQUENCIES by COUNT desc;</source>
            <target state="new">RESULT = order FREQUENCIES by COUNT desc;</target>
          </trans-unit>
          <trans-unit id="135" xml:space="preserve">
            <source>Orders the log levels by count (descending,) and stores into RESULT</source>
            <target state="new">Orders the log levels by count (descending,) and stores into RESULT</target>
          </trans-unit>
          <trans-unit id="136" xml:space="preserve">
            <source>You can also save the results of a transformation by using the <bpt id="2">&lt;code&gt;</bpt>STORE<ept id="2">&lt;/code&gt;</ept> statement.</source>
            <target state="new">You can also save the results of a transformation by using the <bpt id="2">&lt;code&gt;</bpt>STORE<ept id="2">&lt;/code&gt;</ept> statement.</target>
          </trans-unit>
          <trans-unit id="137" xml:space="preserve">
            <source>For example, the following command saves the <bpt id="2">&lt;code&gt;</bpt>RESULT<ept id="2">&lt;/code&gt;</ept> to the <bpt id="4">&lt;strong&gt;</bpt>/example/data/pigout<ept id="4">&lt;/strong&gt;</ept> directory in the default storage container for your cluster:</source>
            <target state="new">For example, the following command saves the <bpt id="2">&lt;code&gt;</bpt>RESULT<ept id="2">&lt;/code&gt;</ept> to the <bpt id="4">&lt;strong&gt;</bpt>/example/data/pigout<ept id="4">&lt;/strong&gt;</ept> directory in the default storage container for your cluster:</target>
          </trans-unit>
          <trans-unit id="138" xml:space="preserve">
            <source>The data is stored in the specified directory in files named <bpt id="2">&lt;strong&gt;</bpt>part-nnnnn<ept id="2">&lt;/strong&gt;</ept>.</source>
            <target state="new">The data is stored in the specified directory in files named <bpt id="2">&lt;strong&gt;</bpt>part-nnnnn<ept id="2">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="139" xml:space="preserve">
            <source>If the directory already exists, you will receive an error message.</source>
            <target state="new">If the directory already exists, you will receive an error message.</target>
          </trans-unit>
          <trans-unit id="140" xml:space="preserve">
            <source>To exit the grunt prompt, enter the following statement.</source>
            <target state="new">To exit the grunt prompt, enter the following statement.</target>
          </trans-unit>
          <trans-unit id="141" xml:space="preserve">
            <source>Pig Latin batch files</source>
            <target state="new">Pig Latin batch files</target>
          </trans-unit>
          <trans-unit id="142" xml:space="preserve">
            <source>You can also use the Pig command to run Pig Latin that is contained in a file.</source>
            <target state="new">You can also use the Pig command to run Pig Latin that is contained in a file.</target>
          </trans-unit>
          <trans-unit id="143" xml:space="preserve">
            <source>After exiting the grunt prompt, open <bpt id="2">&lt;strong&gt;</bpt>Notepad<ept id="2">&lt;/strong&gt;</ept> and create a new file named <bpt id="4">&lt;strong&gt;</bpt>pigbatch.pig<ept id="4">&lt;/strong&gt;</ept> in the <bpt id="6">&lt;strong&gt;</bpt>%PIG_HOME%<ept id="6">&lt;/strong&gt;</ept> directory.</source>
            <target state="new">After exiting the grunt prompt, open <bpt id="2">&lt;strong&gt;</bpt>Notepad<ept id="2">&lt;/strong&gt;</ept> and create a new file named <bpt id="4">&lt;strong&gt;</bpt>pigbatch.pig<ept id="4">&lt;/strong&gt;</ept> in the <bpt id="6">&lt;strong&gt;</bpt>%PIG_HOME%<ept id="6">&lt;/strong&gt;</ept> directory.</target>
          </trans-unit>
          <trans-unit id="144" xml:space="preserve">
            <source>Type or paste the following lines into the <bpt id="2">&lt;strong&gt;</bpt>pigbatch.pig<ept id="2">&lt;/strong&gt;</ept> file, and then save it:</source>
            <target state="new">Type or paste the following lines into the <bpt id="2">&lt;strong&gt;</bpt>pigbatch.pig<ept id="2">&lt;/strong&gt;</ept> file, and then save it:</target>
          </trans-unit>
          <trans-unit id="145" xml:space="preserve">
            <source>Use the following to run the <bpt id="2">&lt;strong&gt;</bpt>pigbatch.pig<ept id="2">&lt;/strong&gt;</ept> file using the pig command.</source>
            <target state="new">Use the following to run the <bpt id="2">&lt;strong&gt;</bpt>pigbatch.pig<ept id="2">&lt;/strong&gt;</ept> file using the pig command.</target>
          </trans-unit>
          <trans-unit id="146" xml:space="preserve">
            <source>When the batch job completes, you should see the following output, which should be the same as when you used <bpt id="2">&lt;code&gt;</bpt>DUMP RESULT;<ept id="2">&lt;/code&gt;</ept> in the previous steps:</source>
            <target state="new">When the batch job completes, you should see the following output, which should be the same as when you used <bpt id="2">&lt;code&gt;</bpt>DUMP RESULT;<ept id="2">&lt;/code&gt;</ept> in the previous steps:</target>
          </trans-unit>
          <trans-unit id="147" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Summary</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Summary</target>
          </trans-unit>
          <trans-unit id="148" xml:space="preserve">
            <source>As you can see, the Pig command allows you to interactively run MapReduce operations, or run Pig Latin jobs that are stored in a batch file.</source>
            <target state="new">As you can see, the Pig command allows you to interactively run MapReduce operations, or run Pig Latin jobs that are stored in a batch file.</target>
          </trans-unit>
          <trans-unit id="149" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Next steps</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Next steps</target>
          </trans-unit>
          <trans-unit id="150" xml:space="preserve">
            <source>For general information about Pig in HDInsight:</source>
            <target state="new">For general information about Pig in HDInsight:</target>
          </trans-unit>
          <trans-unit id="151" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Pig with Hadoop on HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Pig with Hadoop on HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="152" xml:space="preserve">
            <source>For information about other ways you can work with Hadoop on HDInsight:</source>
            <target state="new">For information about other ways you can work with Hadoop on HDInsight:</target>
          </trans-unit>
          <trans-unit id="153" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with Hadoop on HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with Hadoop on HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="154" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce with Hadoop on HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce with Hadoop on HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="155" xml:space="preserve">
            <source>test</source>
            <target state="new">test</target>
          </trans-unit>
        </group>
      </group>
    </body>
  </file>
</xliff>