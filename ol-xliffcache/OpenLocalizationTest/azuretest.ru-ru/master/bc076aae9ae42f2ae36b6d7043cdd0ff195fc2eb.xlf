<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="ru-ru" original="2/22/2016 12:50:51 AM" tool-id="MarkdownTransformer" product-name="N/A" product-version="N/A" build-num="1">
    <header>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">bc076aae9ae42f2ae36b6d7043cdd0ff195fc2eb</xliffext:olfilehash>
      <tool tool-id="MarkdownTransformer" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group extype="content">
        <group id="101">
          <trans-unit id="101" xml:space="preserve">
            <source>Develop Scalding MapReduce jobs with Maven | Microsoft Azure</source>
            <target state="new">Develop Scalding MapReduce jobs with Maven | Microsoft Azure</target>
          </trans-unit>
          <trans-unit id="102" xml:space="preserve">
            <source>Learn how to use Maven to create a Scalding MapReduce job, then deploy and run the job on a Hadoop on HDInsight cluster.</source>
            <target state="new">Learn how to use Maven to create a Scalding MapReduce job, then deploy and run the job on a Hadoop on HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="103" xml:space="preserve">
            <source>Develop Scalding MapReduce jobs with Apache Hadoop on HDInsight</source>
            <target state="new">Develop Scalding MapReduce jobs with Apache Hadoop on HDInsight</target>
          </trans-unit>
          <trans-unit id="104" xml:space="preserve">
            <source>Scalding is a Scala library that makes it easy to create Hadoop MapReduce jobs.</source>
            <target state="new">Scalding is a Scala library that makes it easy to create Hadoop MapReduce jobs.</target>
          </trans-unit>
          <trans-unit id="105" xml:space="preserve">
            <source>It offers a concise syntax, as well as tight integration with Scala.</source>
            <target state="new">It offers a concise syntax, as well as tight integration with Scala.</target>
          </trans-unit>
          <trans-unit id="106" xml:space="preserve">
            <source>In this document, learn how to use Maven to create a basic word count MapReduce job written in Scalding.</source>
            <target state="new">In this document, learn how to use Maven to create a basic word count MapReduce job written in Scalding.</target>
          </trans-unit>
          <trans-unit id="107" xml:space="preserve">
            <source>You will then learn how to deploy and run this job on an HDInsight cluster.</source>
            <target state="new">You will then learn how to deploy and run this job on an HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="108" xml:space="preserve">
            <source>Prerequisites</source>
            <target state="new">Prerequisites</target>
          </trans-unit>
          <trans-unit id="109" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>An Azure subscription<ept id="1">&lt;/strong&gt;</ept>.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>An Azure subscription<ept id="1">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="110" xml:space="preserve">
            <source>See <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Get Azure free trial<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">See <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Get Azure free trial<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="111" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>A Windows or Linux based Hadoop on HDInsight cluster<ept id="1">&lt;/strong&gt;</ept>.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>A Windows or Linux based Hadoop on HDInsight cluster<ept id="1">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="112" xml:space="preserve">
            <source>See <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Linux-based Hadoop on HDInsight<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> or <bpt id="4CapsExtId1">&lt;link&gt;</bpt><bpt id="4CapsExtId2">&lt;linkText&gt;</bpt>Provision Windows-based Hadoop on HDInsight<ept id="4CapsExtId2">&lt;/linkText&gt;</ept><bpt id="4CapsExtId3">&lt;title&gt;</bpt><ept id="4CapsExtId3">&lt;/title&gt;</ept><ept id="4CapsExtId1">&lt;/link&gt;</ept> for more information.</source>
            <target state="new">See <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Linux-based Hadoop on HDInsight<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> or <bpt id="4CapsExtId1">&lt;link&gt;</bpt><bpt id="4CapsExtId2">&lt;linkText&gt;</bpt>Provision Windows-based Hadoop on HDInsight<ept id="4CapsExtId2">&lt;/linkText&gt;</ept><bpt id="4CapsExtId3">&lt;title&gt;</bpt><ept id="4CapsExtId3">&lt;/title&gt;</ept><ept id="4CapsExtId1">&lt;/link&gt;</ept> for more information.</target>
          </trans-unit>
          <trans-unit id="113" xml:space="preserve">
            <source>**<bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Maven<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>**</source>
            <target state="new">**<bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Maven<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>**</target>
          </trans-unit>
          <trans-unit id="114" xml:space="preserve">
            <source>**<bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Java platform JDK<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> 7 or later**</source>
            <target state="new">**<bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Java platform JDK<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> 7 or later**</target>
          </trans-unit>
          <trans-unit id="115" xml:space="preserve">
            <source>Create and build the project</source>
            <target state="new">Create and build the project</target>
          </trans-unit>
          <trans-unit id="116" xml:space="preserve">
            <source>Use the following command to create a new Maven project:</source>
            <target state="new">Use the following command to create a new Maven project:</target>
          </trans-unit>
          <trans-unit id="117" xml:space="preserve">
            <source>This command will create a new directory named <bpt id="2">&lt;strong&gt;</bpt>scaldingwordcount<ept id="2">&lt;/strong&gt;</ept>, and create the scaffolding for an Scala application.</source>
            <target state="new">This command will create a new directory named <bpt id="2">&lt;strong&gt;</bpt>scaldingwordcount<ept id="2">&lt;/strong&gt;</ept>, and create the scaffolding for an Scala application.</target>
          </trans-unit>
          <trans-unit id="118" xml:space="preserve">
            <source>In the <bpt id="2">&lt;strong&gt;</bpt>scaldingwordcount<ept id="2">&lt;/strong&gt;</ept> directory, open the <bpt id="4">&lt;strong&gt;</bpt>pom.xml<ept id="4">&lt;/strong&gt;</ept> file and replace the contents with the following:</source>
            <target state="new">In the <bpt id="2">&lt;strong&gt;</bpt>scaldingwordcount<ept id="2">&lt;/strong&gt;</ept> directory, open the <bpt id="4">&lt;strong&gt;</bpt>pom.xml<ept id="4">&lt;/strong&gt;</ept> file and replace the contents with the following:</target>
          </trans-unit>
          <trans-unit id="119" xml:space="preserve">
            <source>This file describes the project, dependencies, and plugins.</source>
            <target state="new">This file describes the project, dependencies, and plugins.</target>
          </trans-unit>
          <trans-unit id="120" xml:space="preserve">
            <source>Here are the important entries:</source>
            <target state="new">Here are the important entries:</target>
          </trans-unit>
          <trans-unit id="121" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>maven.compiler.source<ept id="1">&lt;/strong&gt;</ept> and <bpt id="3">&lt;strong&gt;</bpt>maven.compiler.target<ept id="3">&lt;/strong&gt;</ept>: sets the Java version for this project</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>maven.compiler.source<ept id="1">&lt;/strong&gt;</ept> and <bpt id="3">&lt;strong&gt;</bpt>maven.compiler.target<ept id="3">&lt;/strong&gt;</ept>: sets the Java version for this project</target>
          </trans-unit>
          <trans-unit id="122" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>repositories<ept id="1">&lt;/strong&gt;</ept>: the repositories that contain the dependency files used by this project</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>repositories<ept id="1">&lt;/strong&gt;</ept>: the repositories that contain the dependency files used by this project</target>
          </trans-unit>
          <trans-unit id="123" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>scalding-core_2.11<ept id="1">&lt;/strong&gt;</ept> and <bpt id="3">&lt;strong&gt;</bpt>hadoop-core<ept id="3">&lt;/strong&gt;</ept>: this project depends on both Scalding and Hadoop core packages</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>scalding-core_2.11<ept id="1">&lt;/strong&gt;</ept> and <bpt id="3">&lt;strong&gt;</bpt>hadoop-core<ept id="3">&lt;/strong&gt;</ept>: this project depends on both Scalding and Hadoop core packages</target>
          </trans-unit>
          <trans-unit id="124" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>maven-scala-plugin<ept id="1">&lt;/strong&gt;</ept>: plugin to compile scala applications</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>maven-scala-plugin<ept id="1">&lt;/strong&gt;</ept>: plugin to compile scala applications</target>
          </trans-unit>
          <trans-unit id="125" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>maven-shade-plugin<ept id="1">&lt;/strong&gt;</ept>: plugin to create shaded (fat) jars.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>maven-shade-plugin<ept id="1">&lt;/strong&gt;</ept>: plugin to create shaded (fat) jars.</target>
          </trans-unit>
          <trans-unit id="126" xml:space="preserve">
            <source>This plugin applies filters and transformations; specificially:</source>
            <target state="new">This plugin applies filters and transformations; specificially:</target>
          </trans-unit>
          <trans-unit id="127" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>filters<ept id="1">&lt;/strong&gt;</ept>: The filters applied modify the meta information included with in the jar file.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>filters<ept id="1">&lt;/strong&gt;</ept>: The filters applied modify the meta information included with in the jar file.</target>
          </trans-unit>
          <trans-unit id="128" xml:space="preserve">
            <source>To prevent signing exceptions at runtime, this excludes various signature files that may be included with dependencies.</source>
            <target state="new">To prevent signing exceptions at runtime, this excludes various signature files that may be included with dependencies.</target>
          </trans-unit>
          <trans-unit id="129" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>executions<ept id="1">&lt;/strong&gt;</ept>: The package phase execution configuration specifies the <bpt id="3">&lt;strong&gt;</bpt>com.twitter.scalding.Tool<ept id="3">&lt;/strong&gt;</ept> class as the main class for the package.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>executions<ept id="1">&lt;/strong&gt;</ept>: The package phase execution configuration specifies the <bpt id="3">&lt;strong&gt;</bpt>com.twitter.scalding.Tool<ept id="3">&lt;/strong&gt;</ept> class as the main class for the package.</target>
          </trans-unit>
          <trans-unit id="130" xml:space="preserve">
            <source>Without this, you would need to specify com.twitter.scalding.Tool, as well as the class that contains the application logic, when running the job with the hadoop command.</source>
            <target state="new">Without this, you would need to specify com.twitter.scalding.Tool, as well as the class that contains the application logic, when running the job with the hadoop command.</target>
          </trans-unit>
          <trans-unit id="131" xml:space="preserve">
            <source>Delete the <bpt id="2">&lt;strong&gt;</bpt>src/test<ept id="2">&lt;/strong&gt;</ept> directory, as you will not be creating tests with this example.</source>
            <target state="new">Delete the <bpt id="2">&lt;strong&gt;</bpt>src/test<ept id="2">&lt;/strong&gt;</ept> directory, as you will not be creating tests with this example.</target>
          </trans-unit>
          <trans-unit id="132" xml:space="preserve">
            <source>Open the <bpt id="2">&lt;strong&gt;</bpt>src/main/scala/com/microsoft/example/app.scala<ept id="2">&lt;/strong&gt;</ept> file and replace the contents with the following:</source>
            <target state="new">Open the <bpt id="2">&lt;strong&gt;</bpt>src/main/scala/com/microsoft/example/app.scala<ept id="2">&lt;/strong&gt;</ept> file and replace the contents with the following:</target>
          </trans-unit>
          <trans-unit id="133" xml:space="preserve">
            <source>This implements a basic word count job.</source>
            <target state="new">This implements a basic word count job.</target>
          </trans-unit>
          <trans-unit id="134" xml:space="preserve">
            <source>Save and close the files.</source>
            <target state="new">Save and close the files.</target>
          </trans-unit>
          <trans-unit id="135" xml:space="preserve">
            <source>Use the following command from the <bpt id="2">&lt;strong&gt;</bpt>scaldingwordcount<ept id="2">&lt;/strong&gt;</ept> directory to build and package the application:</source>
            <target state="new">Use the following command from the <bpt id="2">&lt;strong&gt;</bpt>scaldingwordcount<ept id="2">&lt;/strong&gt;</ept> directory to build and package the application:</target>
          </trans-unit>
          <trans-unit id="136" xml:space="preserve">
            <source>Once this job completes, the package containing the WordCount application can be found at <bpt id="2">&lt;strong&gt;</bpt>target/scaldingwordcount-1.0-SNAPSHOT.jar<ept id="2">&lt;/strong&gt;</ept>.</source>
            <target state="new">Once this job completes, the package containing the WordCount application can be found at <bpt id="2">&lt;strong&gt;</bpt>target/scaldingwordcount-1.0-SNAPSHOT.jar<ept id="2">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="137" xml:space="preserve">
            <source>Run the job on a Linux-based cluster</source>
            <target state="new">Run the job on a Linux-based cluster</target>
          </trans-unit>
          <trans-unit id="138" xml:space="preserve">
            <source>The following steps use SSH and the Hadoop command.</source>
            <target state="new">The following steps use SSH and the Hadoop command.</target>
          </trans-unit>
          <trans-unit id="139" xml:space="preserve">
            <source>For other methods of running MapReduce jobs, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce in Hadoop on HDInsight<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For other methods of running MapReduce jobs, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce in Hadoop on HDInsight<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="140" xml:space="preserve">
            <source>Use the following command to upload the package to your HDInsight cluster:</source>
            <target state="new">Use the following command to upload the package to your HDInsight cluster:</target>
          </trans-unit>
          <trans-unit id="141" xml:space="preserve">
            <source>This copies the files from the local system to the head node.</source>
            <target state="new">This copies the files from the local system to the head node.</target>
          </trans-unit>
          <trans-unit id="142" xml:space="preserve">
            <source>If you used a password to secure your SSH account, you will be prompted for the password.</source>
            <target state="new">If you used a password to secure your SSH account, you will be prompted for the password.</target>
          </trans-unit>
          <trans-unit id="143" xml:space="preserve">
            <source>If you used an SSH key, you may have to use the <bpt id="2">&lt;code&gt;</bpt>-i<ept id="2">&lt;/code&gt;</ept> parameter and the path to the private key.</source>
            <target state="new">If you used an SSH key, you may have to use the <bpt id="2">&lt;code&gt;</bpt>-i<ept id="2">&lt;/code&gt;</ept> parameter and the path to the private key.</target>
          </trans-unit>
          <trans-unit id="144" xml:space="preserve">
            <source>For example, <bpt id="2">&lt;code&gt;</bpt>scp -i /path/to/private/key target/scaldingwordcount-1.0-SNAPSHOT.jar username@clustername-ssh.azurehdinsight.net:.<ept id="2">&lt;/code&gt;</ept></source>
            <target state="new">For example, <bpt id="2">&lt;code&gt;</bpt>scp -i /path/to/private/key target/scaldingwordcount-1.0-SNAPSHOT.jar username@clustername-ssh.azurehdinsight.net:.<ept id="2">&lt;/code&gt;</ept></target>
          </trans-unit>
          <trans-unit id="145" xml:space="preserve">
            <source>Use the following command to connect to the cluster head node:</source>
            <target state="new">Use the following command to connect to the cluster head node:</target>
          </trans-unit>
          <trans-unit id="146" xml:space="preserve">
            <source>If you used a password to secure your SSH account, you will be prompted for the password.</source>
            <target state="new">If you used a password to secure your SSH account, you will be prompted for the password.</target>
          </trans-unit>
          <trans-unit id="147" xml:space="preserve">
            <source>If you used an SSH key, you may have to use the <bpt id="2">&lt;code&gt;</bpt>-i<ept id="2">&lt;/code&gt;</ept> parameter and the path to the private key.</source>
            <target state="new">If you used an SSH key, you may have to use the <bpt id="2">&lt;code&gt;</bpt>-i<ept id="2">&lt;/code&gt;</ept> parameter and the path to the private key.</target>
          </trans-unit>
          <trans-unit id="148" xml:space="preserve">
            <source>For example, <bpt id="2">&lt;code&gt;</bpt>ssh -i /path/to/private/key username@clustername-ssh.azurehdinsight.net<ept id="2">&lt;/code&gt;</ept></source>
            <target state="new">For example, <bpt id="2">&lt;code&gt;</bpt>ssh -i /path/to/private/key username@clustername-ssh.azurehdinsight.net<ept id="2">&lt;/code&gt;</ept></target>
          </trans-unit>
          <trans-unit id="149" xml:space="preserve">
            <source>Once connected to the head node, use the following command to run the word cound job</source>
            <target state="new">Once connected to the head node, use the following command to run the word cound job</target>
          </trans-unit>
          <trans-unit id="150" xml:space="preserve">
            <source>This runs the WordCount class you implemented earlier.</source>
            <target state="new">This runs the WordCount class you implemented earlier.</target>
          </trans-unit>
          <trans-unit id="151" xml:space="preserve">
            <source><bpt id="1">&lt;code&gt;</bpt>--hdfs<ept id="1">&lt;/code&gt;</ept> instructs the job to use HDFS.</source>
            <target state="new"><bpt id="1">&lt;code&gt;</bpt>--hdfs<ept id="1">&lt;/code&gt;</ept> instructs the job to use HDFS.</target>
          </trans-unit>
          <trans-unit id="152" xml:space="preserve">
            <source><bpt id="1">&lt;code&gt;</bpt>--input<ept id="1">&lt;/code&gt;</ept> specifies the input text file, while <bpt id="3">&lt;code&gt;</bpt>--output<ept id="3">&lt;/code&gt;</ept> specifies the output location.</source>
            <target state="new"><bpt id="1">&lt;code&gt;</bpt>--input<ept id="1">&lt;/code&gt;</ept> specifies the input text file, while <bpt id="3">&lt;code&gt;</bpt>--output<ept id="3">&lt;/code&gt;</ept> specifies the output location.</target>
          </trans-unit>
          <trans-unit id="153" xml:space="preserve">
            <source>After the job completes, use the following to view the output.</source>
            <target state="new">After the job completes, use the following to view the output.</target>
          </trans-unit>
          <trans-unit id="154" xml:space="preserve">
            <source>This will display information similar to the following:</source>
            <target state="new">This will display information similar to the following:</target>
          </trans-unit>
          <trans-unit id="155" xml:space="preserve">
            <source>Run the job on a Windows-based cluster</source>
            <target state="new">Run the job on a Windows-based cluster</target>
          </trans-unit>
          <trans-unit id="156" xml:space="preserve">
            <source>The following steps use Windows PowerShell.</source>
            <target state="new">The following steps use Windows PowerShell.</target>
          </trans-unit>
          <trans-unit id="157" xml:space="preserve">
            <source>For other methods of running MapReduce jobs, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce in Hadoop on HDInsight<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For other methods of running MapReduce jobs, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce in Hadoop on HDInsight<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="158" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install and configure Azure PowerShell<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install and configure Azure PowerShell<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="159" xml:space="preserve">
            <source>Download <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>hdinsight-tools.psm1<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> and save to a file named <bpt id="4">&lt;strong&gt;</bpt>hdinsight-tools.psm1<ept id="4">&lt;/strong&gt;</ept>.</source>
            <target state="new">Download <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>hdinsight-tools.psm1<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> and save to a file named <bpt id="4">&lt;strong&gt;</bpt>hdinsight-tools.psm1<ept id="4">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="160" xml:space="preserve">
            <source>Open a new <bpt id="2">&lt;strong&gt;</bpt>Azure PoweShell<ept id="2">&lt;/strong&gt;</ept> session and enter the following command.</source>
            <target state="new">Open a new <bpt id="2">&lt;strong&gt;</bpt>Azure PoweShell<ept id="2">&lt;/strong&gt;</ept> session and enter the following command.</target>
          </trans-unit>
          <trans-unit id="161" xml:space="preserve">
            <source>If hdinsight-tools.psm1 isn't in the current directory, provide the path to the file:</source>
            <target state="new">If hdinsight-tools.psm1 isn't in the current directory, provide the path to the file:</target>
          </trans-unit>
          <trans-unit id="162" xml:space="preserve">
            <source>This imports several functions for working with files in HDInsight.</source>
            <target state="new">This imports several functions for working with files in HDInsight.</target>
          </trans-unit>
          <trans-unit id="163" xml:space="preserve">
            <source>Use the following commands to upload the jar file containing the WordCount job.</source>
            <target state="new">Use the following commands to upload the jar file containing the WordCount job.</target>
          </trans-unit>
          <trans-unit id="164" xml:space="preserve">
            <source>Replace <bpt id="2">&lt;code&gt;</bpt>CLUSTERNAME<ept id="2">&lt;/code&gt;</ept> with the name of your HDInsight cluster:</source>
            <target state="new">Replace <bpt id="2">&lt;code&gt;</bpt>CLUSTERNAME<ept id="2">&lt;/code&gt;</ept> with the name of your HDInsight cluster:</target>
          </trans-unit>
          <trans-unit id="165" xml:space="preserve">
            <source>Once the upload has completed, use the following commands to run the job:</source>
            <target state="new">Once the upload has completed, use the following commands to run the job:</target>
          </trans-unit>
          <trans-unit id="166" xml:space="preserve">
            <source>Once the job completes, use the following to download the job output:</source>
            <target state="new">Once the job completes, use the following to download the job output:</target>
          </trans-unit>
          <trans-unit id="167" xml:space="preserve">
            <source>The output consists of tab delimited word and count values.</source>
            <target state="new">The output consists of tab delimited word and count values.</target>
          </trans-unit>
          <trans-unit id="168" xml:space="preserve">
            <source>use the following command to display the results.</source>
            <target state="new">use the following command to display the results.</target>
          </trans-unit>
          <trans-unit id="169" xml:space="preserve">
            <source>The file should contain values similar to the following:</source>
            <target state="new">The file should contain values similar to the following:</target>
          </trans-unit>
          <trans-unit id="170" xml:space="preserve">
            <source>If the output is empty, or the file doesn't exist, you can use the following to view any errors that occurred when running the job:</source>
            <target state="new">If the output is empty, or the file doesn't exist, you can use the following to view any errors that occurred when running the job:</target>
          </trans-unit>
          <trans-unit id="171" xml:space="preserve">
            <source>Next steps</source>
            <target state="new">Next steps</target>
          </trans-unit>
          <trans-unit id="172" xml:space="preserve">
            <source>Now that you have learned how to use Scalding to create MapReduce jobs for HDInsight, use the following links to explore other ways to work with Azure HDInsight.</source>
            <target state="new">Now that you have learned how to use Scalding to create MapReduce jobs for HDInsight, use the following links to explore other ways to work with Azure HDInsight.</target>
          </trans-unit>
          <trans-unit id="173" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="174" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Pig with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Pig with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="175" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce jobs with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce jobs with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="176" xml:space="preserve">
            <source>test</source>
            <target state="new">test</target>
          </trans-unit>
        </group>
      </group>
    </body>
  </file>
</xliff>