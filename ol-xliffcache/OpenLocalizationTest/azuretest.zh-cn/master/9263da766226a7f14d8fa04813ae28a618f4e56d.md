<properties
   pageTitle="Autoscaling guidance | Microsoft Azure"
   description="Guidance upon how to autoscale to dynamically allocate resources required by an application."
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="masimms"
   editor=""
   tags=""/>

<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="04/28/2015"
   ms.author="masashin"/>

# AutoScaling orientation

![](media/best-practices-auto-scaling/pnp-logo.png)

## Vue d'ensemble
AutoScaling est le processus d'allouer dynamiquement les ressources requises par une application pour correspondre les exigences de performance et de satisfaire les contrats de niveau de service (SLA) tout en minimisant les coûts d'exécution. Comme le volume de travail se développe, une application peut nécessiter des ressources supplémentaires pour lui permettre d'accomplir ses tâches en temps opportun. Comme demande de relâche, les ressources peuvent être désallouées pour minimiser les coûts tout en conservant un rendement adéquat et réunion SLA.
AutoScaling profite de l'élasticité des environnements hébergés nuage tout en facilitant la gestion des frais généraux en réduisant la nécessité pour un opérateur de constamment surveiller les performances d'un système et prendre des décisions concernant l'ajout ou la suppression des ressources.
> Échelle automatique s'applique à toutes les ressources utilisées par une application, pas seulement les ressources de calcul. Par exemple, si votre système utilise des files d'attente pour envoyer et recevoir des informations, il pourrait créer des files d'attente supplémentaires tel qu'il évolue.

## Types de mise à l'échelle
Mise à l'échelle en général prend l'une des deux formes — mise à l'échelle horizontale et verticale :

- **Mise à l'échelle verticale** (souvent dénommé _mise à l'échelle de haut en bas_) requires that you modify the hardware (expand or reduce its capacity and performance), or redeploy the solution using alternative hardware that has the appropriate capacity and performance. In a cloud environment, the hardware platform is typically a virtualized environment. Unless the original hardware was substantially overprovisioned, with the consequent upfront capital expense, vertically scaling up in this environment involves provisioning more powerful resources, and then moving the system onto these new resources. Vertical scaling is often a disruptive process that requires making the system temporarily unavailable while it is being redeployed. It may be possible to keep the original system running while the new hardware is provisioned and brought online, but there will likely be some interruption while the processing transitions from the old environment to the new one. It is uncommon to use autoscaling to implement a vertical scaling strategy.
- **L'échelle horizontale** (souvent dénommé _mise à l'échelle et en_) nécessite le déploiement de la solution sur plus ou moins de ressources, qui sont généralement des ressources des produits plutôt que des systèmes de grande puissants. La solution peut continuer à s'exécuter sans interruption alors que ces ressources sont mis en service. Lorsque le processus de déploiement est terminé, les copies des éléments qui composent la solution pouvant être déployées sur ces ressources supplémentaires et mises à la disposition. Si la demande diminue, on peuvent récupérer les ressources supplémentaires après que les éléments à l'aide de leur ont été fermées correctement. Beaucoup de systèmes basés sur un nuage, y compris Microsoft Azure, prend en charge l'automatisation de cette forme de mise à l'échelle.

## Implémentation d'une stratégie de mise
Mise en œuvre d'une stratégie d'autoscaling généralement implique les composants et les processus suivants :

- Instrumentation et surveillance de systèmes au niveau application, le service et infrastructure qui capturent des indicateurs clés comme les temps de réponse, longueur de la file d'attente, l'utilisation du processeur et utilisation de la mémoire.
- Prise de décision logique qui peut évaluer les facteurs d'échelle contrôlés contre les seuils système prédéfini ou ses horaires et prendre des décisions concernant s'il faut ou non de l'échelle.
- Composants qui sont chargés d'effectuer les tâches associées à la mise à l'échelle du système, telles que le provisionnement ou désapprovisionnement des ressources.
- Essais, contrôle et mise au point de la stratégie d'autoscaling pour assurer qu'elles fonctionnent comme prévu.

Plupart des environnements cloud computing, tels que Microsoft Azure, fournissent des mécanismes d'autoscaling intégré cette adresse des scénarios courants. Si l'environnement ou le service que vous utilisez ne fournit pas le nécessaire automatisé de mise à l'échelle de la fonctionnalité, ou si vous avez des exigences extrêmes autoscaling au-delà de ses capacités, une implémentation personnalisée peut être nécessaire pour recueillir les opérationnels et les paramètres système, les analyser pour identifier les données pertinentes et de s'ajuster ressources en conséquence.

## Considérations relatives à la mise en œuvre autoscaling
Échelle automatique n'est pas une solution instantanée. Tout simplement ajouter des ressources à un système ou exécute plusieurs instances d'un processus ne garantit pas qu'il améliorera la performance du système.  Tenez compte des points suivants lorsque vous concevez une stratégie autoscaling :

- The system must be designed to be horizontally scalable. Avoid making assumptions about instance affinity; do not design solutions that require that the code is always running in a specific instance of a process. When scaling a cloud service or web site horizontally, do not assume that a series of requests from the same source will always be routed to the same instance. For the same reason, design services to be stateless to avoid requiring a series of requests from an application to always be routed to the same instance of a service. When designing a service that reads messages from a queue and processes them, do not make any assumptions about which instance of the service handles a specific message because autoscaling could start additional instances of a service as the queue length grows. The [Modèle de consommateurs concurrente](http://msdn.microsoft.com/library/dn568101.aspx) décrit comment gérer ce scénario.
- Si la solution implémente une tâche de longue durée, concevoir cette tâche pour prendre en charge l'évolution et l'incrustation dans. Sans être dûment soins, une telle tâche pourrait empêcher une instance d'un processus de fermeture proprement lorsque le système évolue, ou il pourrait perdre des données si le processus est arrêté par la force. Idéalement, Refactoriser une tâche longue et briser le traitement qu'il effectue en morceaux plus petits et discrets. Le [Modèle de filtres et tuyaux](http://msdn.microsoft.com/library/dn568100.aspx) fournit un exemple de comment vous pouvez y parvenir. Alternativement, vous pouvez implémenter un mécanisme de contrôle que les registres d'état d'informations sur la tâche à intervalles réguliers et enregistrer cet État dans le stockage durable qui peut être consulté par toute instance du processus d'exécution de la tâche. De cette façon, si le processus est arrêté, les travaux qu'elle exécutait se résument depuis le dernier point de contrôle à l'aide d'une autre instance.
- Lorsque les tâches de fond courir sur les instances de calcul distincte, comme dans les rôles de travailleur de Services Cloud application hébergée, vous devrez peut-être évoluer les différentes parties de l'application à l'aide de différentes politiques de mise à l'échelle. Par exemple, vous devrez peut-être déployer les instances supplémentaires de calcul de l'interface utilisateur sans pour autant augmenter le nombre d'instances de calcul d'arrière-plan, ou le contraire de cela. Si vous offrez des différents niveaux de service (par exemple les paquets de base et de grande qualité de service), vous devrez peut-être évoluer les ressources de calcul pour les forfaits de services premium plus agressivement que celles des paquets de service de base afin de respecter les SLA.
- Envisagez d'utiliser la longueur de la file d'attente sur lesquelles UI et fond calculent instances communiquent comme un pilote pour votre stratégie d'échelle automatique. C'est le meilleur indicateur d'un déséquilibre ou une différence entre le courant de charge et la capacité de traitement de la tâche en arrière-plan.
- Si vous basez votre stratégie autoscaling sur compteurs qui mesurent les processus métiers, tels que le nombre de commandes passées par heure ou le temps d'exécution moyen d'une transaction complexe, s'assurer que vous comprenez pleinement la relation entre les résultats de ces types de compteurs et les exigences de capacité de calcul réel. Il peut être nécessaire à l'échelle de plusieurs composants ou compute unit en réponse aux changements dans les compteurs de processus d'affaires.  
- Pour empêcher un système de tenter de faire évoluer excessivement et afin d'éviter les coûts associés à des milliers d'instances en cours d'exécution, envisager de limiter le nombre maximal d'instances qui peuvent être ajoutés automatiquement. Plupart des mécanismes autoscaling vous permettent de spécifier le nombre minimal et maximal d'instances d'une règle. En outre, examiner gracieusement dégradants les fonctionnalités que le système offre si le nombre maximal d'instances ont été déployés et le système est toujours surchargé.
- Gardez à l'esprit qu'autoscaling pourrait ne pas être le mécanisme le plus approprié pour gérer un sursaut dans la charge de travail. Cela prend du temps à disposition et de démarrer de nouvelles instances d'un service ou d'ajouter des ressources à un système, et le PIC sera peut-être dépassée au moment où que ces ressources supplémentaires ont été mis à la disposition. Dans ce scénario, il peut être préférable d'étrangler le service. Pour plus d'informations, consultez le [Modèle de limitation](http://msdn.microsoft.com/library/dn589798.aspx).
- À l'inverse, si vous avez besoin de la capacité de traiter toutes les demandes lorsque le volume varie rapidement, et le coût n'est pas un facteur important, pensez à utiliser une stratégie agressive de mise à l'échelle automatique qui démarre plus rapidement les instances supplémentaires, ou en utilisant une stratégie planifiée qui commence un nombre suffisant de cas pour atteindre le maximum de charge avant que la charge est prévue.
- The autoscaling mechanism should monitor the autoscaling process and log the details of each autoscaling event (what triggered it, what resources were added or removed, and when). If you create a custom autoscaling mechanism, ensure that it incorporates this capability. The information can be analyzed to help measure the effectiveness of the autoscaling strategy, and tune it if necessary—both in the short term as the usage patterns become more obvious, and over the long term as the business expands or the requirements of the application evolve. If an application reaches the upper limit defined for autoscaling, the mechanism might also alert an operator who could manually start additional resources if the situation warrants this. Note that, under these circumstances, the operator may also be responsible for manually removing these resources after the workload eases.

## Échelle automatique dans une solution d'Azur
Il existe plusieurs options de configuration autoscaling pour vos solutions d'Azur :

- **Azure Autoscaling**. Cette fonctionnalité prend en charge les scénarios de mise à l'échelle plus courants selon le calendrier et, éventuellement, déclenché la mise à l'échelle des opérations basées sur les mesures d'exécution (tels que l'utilisation du processeur, file d'attente de longueur, ou construit des compteurs dans et personnalisés). Vous pouvez configurer des stratégies d'autoscaling simple pour une solution rapidement et facilement en utilisant le portail de gestion d'Azur et vous pouvez utiliser la bibliothèque de gestion des Services de surveillance Azure pour configurer autoscaling règles avec un degré plus fin de contrôle. Pour plus d'informations, reportez-vous à la section [L'azur bibliothèque de gestion des Services de surveillance](#the-azure-monitoring-services-management-library).
- **Une solution personnalisée** basé sur le diagnostic, surveillance et fonctionnalités de gestion de service d'Azur. Par exemple, vous pouvez utiliser Azure diagnostics, code personnalisé, ou la [Pack d'administration System Center pour Azure](http://www.microsoft.com/download/details.aspx?id=38414) à surveiller en permanence les performances de l'application ; et le [Azur Service Management API REST](http://msdn.microsoft.com/library/azure/ee460799.aspx), le [Bibliothèques de gestion de Microsoft Azure](https://www.nuget.org/packages/Microsoft.WindowsAzure.Management.Libraries), ou le [Bloc d'Application AutoScaling](http://msdn.microsoft.com/library/hh680892%28v=pandp.50%29.aspx) à l'échelle et en. Les métriques pour le déclenchement d'une opération de mise à l'échelle peuvent être n'importe quel compteur intégré ou personnalisé, ou autres instruments que vous implémentez l'application. Toutefois, une solution personnalisée n'est pas simple à implémenter et devraient être considérées seulement si aucune des méthodes précédentes peut satisfaire vos besoins. Notez que le bloc d'Application Autoscaling est un framework open source et n'est pas pris en charge directement par Microsoft.
- **Services de tiers** comme [Paraleap AzureWatch](http://www.paraleap.com/AzureWatch) qui vous permettent de faire évoluer une solution basée sur les horaires, service charge et système d'indicateurs de performance, des règles personnalisées et des combinaisons de différents types de règles.

Lorsque vous choisissez quelle solution autoscaling à adopter, considérez les points suivants :

- Utiliser le construit en autoscaling caractéristiques de la plate-forme, s'ils peuvent répondre à vos exigences. Si ce n'est pas le cas, examiner attentivement si vous avez vraiment besoin des fonctionnalités de mise à l'échelle plus complexes. Quelques exemples de dépassement au-delà de ceux qui que propose la fonction intégrée de mise à l'échelle automatique peuvent inclure plus de granularité du contrôle, différentes façons de détecter les éléments déclencheurs de mise à l'échelle, l'échelle à travers des abonnements, mise à l'échelle des autres types de ressources et plus encore.
- Consider if you can predict the load on the application with sufficient accuracy to depend only on scheduled autoscaling (adding and removing instances to meet anticipated peaks in demand). Where this is not possible, use reactive autoscaling based on metrics collected at runtime to allow the application to handle unpredictable changes in demand. However, it is typically appropriate to combine these approaches. For example, create a strategy that adds resources such as compute, storage, and queues based on a schedule of the times when you know the application is most busy. This helps to ensure that capacity is available when required without the delay encountered when starting new instances. In addition, for each scheduled rule, define metrics that allow reactive autoscaling during that period to ensure that the application can handle sustained but unpredictable peaks in demand.
- Il est souvent difficile de comprendre la relation entre les exigences de métrique et de la capacité, surtout lorsqu'une application est déployée au départ. Préférez à disposition des capacités supplémentaires un peu au début et puis surveiller et ajuster les règles autoscaling pour porter la capacité de rapprocher à la charge réelle.

### À l'aide de Azure Autoscaling
Azure Autoscaling vous permet de configurer l'échelle et l'évolution dans les options pour une solution. Azure Autoscaling peut automatiquement ajouter et supprimer des instances de Services Cloud Azure et rôles de travail, Services mobiles d'Azur applications web et Sites Web d'Azur. Il peut aussi permettre la mise à l'échelle automatique de démarrage et l'arrêt des instances de Machines virtuelles d'Azure. Une stratégie d'Azure autoscaling compose de deux ensembles de facteurs :

- Basé sur la planification autoscaling qui puisse garantir des instances supplémentaires sont disponibles pour coïncider avec un pic attendu dans l'usage et qui s'adapte dans une fois passé l'heure de pointe. Cela permet de vous assurer que vous avez suffisamment instances en cours d'exécution sans attendre que le système réagit à la charge.
- Autoscaling axée sur les métriques qui réagit à des facteurs tels que l'utilisation moyenne du processeur au cours de la dernière heure, ou l'arriéré des messages que la solution s'exécute dans un stockage Azur ou file d'attente Service Bus. Cela permet à l'application de réagir séparément des règles planifiées autoscaling pour accommoder les changements planifiés ou imprévus de la demande.

Considérez les points suivants lorsque vous utilisez Azure Autoscaling :

- Votre stratégie autoscaling combine régulier et axée sur les mesures de mise à l'échelle. Vous pouvez spécifier deux types de règles pour un service, afin qu'une application évolue sur un calendrier et en réponse aux changements de charge.
- Vous devez configurer les règles de l'Azure Autoscaling et surveiller les performances de votre application au fil du temps. Les résultats de cette surveillance permet d'ajuster la façon dans laquelle le système évolue si nécessaire. Cependant, gardez à l'esprit cette échelle automatique n'est pas un processus instantané — il faut du temps pour réagir à une métrique comme moyenne CPU utilisation excédant (ou inférieurs) un seuil spécifié.
- Autoscaling rules that use a detection mechanism based on a measured trigger attribute (such as CPU usage or queue length) use an aggregated value over time, rather than the instantaneous values, to trigger an autoscaling action. By default, the aggregate is an average of the values. This prevents the system from reacting too quickly, or causing rapid oscillation. It also allows time for new instances that are auto-started to settle into running mode, preventing additional autoscaling actions from occurring while the new instances are starting up. For Cloud Services and Virtual Machines, the default period for the aggregation is 45 minutes, so it can take up to this period of time for the metric to trigger autoscaling in response to spikes in demand. You can change the aggregation period by using the SDK, but be aware that periods of less than 25 minutes may cause unpredictable results (see [Auto Echelonnement pourcentage CPU avec l'azur bibliothèque de gestion des Services de surveillance des Services Cloud](http://rickrainey.com/2013/12/15/auto-scaling-cloud-services-on-cpu-percentage-with-the-windows-azure-monitoring-services-management-library/) Pour plus d'informations). Pour les Sites Web d'Azur, la période est beaucoup plus courte, ce qui permet de nouvelles instances être disponible dans environ cinq minutes après un changement à la mesure moyenne de déclencheur.
- Si vous configurez l'échelle automatique en utilisant le kit de développement plutôt que sur le portail web, vous pouvez spécifier une planification plus détaillée au cours de laquelle les règles sont actifs. Vous pouvez également créer vos propres paramètres et utilisez-les avec ou sans qu'aucun de ceux déjà existants dans vos règles d'échelle automatique. Par exemple, vous pouvez utiliser les compteurs alternatifs tels que le nombre de requêtes par seconde ou de la disponibilité moyenne de mémoire, ou utiliser des compteurs personnalisés qui mesurent des processus d'entreprise. Pour plus d'informations, reportez-vous à la section [L'azur bibliothèque de gestion des Services de surveillance](#the-azure-monitoring-services-management-library).
- Lorsque autoscaling Azure des Machines virtuelles, vous devez déployer plusieurs instances de l'ordinateur virtuel qui est égal au nombre maximal, vous permettrez autoscaling commencer. Ces instances doivent faire partie de l'ensemble de la disponibilité de même. Le mécanisme d'échelle automatique de Machines virtuelles ne créer ni supprimer des instances de l'ordinateur virtuel ; au lieu de cela, les règles d'échelle automatique vous configurez démarrera et stoppera un nombre approprié de ces instances. Pour plus d'informations, consultez [À l'échelle automatiquement une application Web rôles, rôles de travail ou des Machines virtuelles en cours d'exécution](cloud-services-how-to-scale.md#autoscale).
- Si les nouvelles instances ne peut pas être démarrés, peut-être parce que le maximum pour un abonnement a été atteint (par exemple, le nombre maximal de noyaux en utilisant le service de Machines virtuelles) ou une erreur se produit lors du démarrage, le portail peut montrer qu'une opération autoscaling a réussi. Cependant, les **ChangeDeploymentConfiguration** les événements affichés dans le portail affichera seulement qu'un démarrage du service a été demandé et il n'y n'aura aucun cas indiquer qu'il a été achevé avec succès.
- Dans Azure Autoscaling, vous pouvez utiliser le portail web UI de lier les ressources telles que des instances de base de données SQL et les files d'attente pour une instance de service de calcul. Cela vous permet d'accéder plus facilement aux séparé manuel et automatique de mise à l'échelle des options de configuration pour chacun des ressources liées. Pour plus d'informations, consultez [Comment : lier une ressource à un service de Cloud Computing](cloud-services-how-to-manage.md#linkresources) dans la page Comment faire pour gérer les Services de Cloud et de la page [Comment faire évoluer une Application](cloud-services-how-to-scale.md).
- Lorsque vous configurez plusieurs règles et politiques, il est possible qu'ils soit en conflit entre eux. Azure Autoscaling utilise les règles suivantes de résolution des conflits pour s'assurer qu'il y a toujours un nombre suffisant d'instances en cours d'exécution :
  - Échelle des opérations a toujours préséance sur échelle en opérations.
  - Quelle échelle des conflits d'opérations, la règle qui initie la plus forte augmentation du nombre d'instances est prioritaire.
  - À quelle échelle en conflit d'opérations, la règle qui initie la plus petite diminution du nombre d'instances est prioritaire.

<a name="the-azure-monitoring-services-management-library"></a>

### L'azur bibliothèque de gestion des Services de surveillance
Vous pouvez utiliser l'API de gestion de Service pour configurer Azure Autoscaling avec un degré plus fin du contrôle et accéder aux fonctionnalités qui ne sont pas disponibles via le portail web. Cette API est accessible directement comme une API REST de Web, ou par l'intermédiaire de la bibliothèque de gestion des Services de surveillance Azure.

Azure Autoscaling est configuré en spécifiant autoscaling profils pour les rôles de Services Cloud, ensembles de disponibilité des Machines virtuelles, Azure Web Sites (en tant que batteries de serveurs dans un espace Web) ou Services Mobile Azure. Chaque profil, dont une cible peut avoir jusqu'à 20, indique :

- Quand il doit être appliqué (à l'aide d'une récurrence ou un intervalle de date fixe),
- Le nombre maximal d'instances (le minimum, le maximum et le nombre par défaut)
- Quelles sont les règles autoscaling sont en vigueur

Le portail web permet la configuration d'un ensemble fixe de profils, essentiellement distinguer jour/nuit et jour de semaine/week-end, avec une seule paire d'échelle règles basées sur l'utilisation du processeur ou de la longueur de la file d'attente. En utilisant l'API de gestion de Service au lieu de cela, vous pouvez configurer les dates d'applicabilité de grains plus fins pour les profils et spécifier jusqu'à dix règles avec les déclencheurs basées sur des métriques disponibles pour le Service de surveillance d'Azur.

AutoScaling règles sont composent d'un déclencheur qui indique quelle règle s'applique, et une action d'ampleur qui indique la modification à effectuer sur la configuration de la cible. Au moment de l'écriture, la seule action de prise en charge a été une augmentation ou diminution dans le nombre d'instances.

Les éléments déclencheurs de règles autoscaling reposent sur les paramètres disponibles. Les valeurs pour les paramètres configurés sont prélevées périodiquement les sources appropriées, tel que défini dans la configuration d'échelle automatique. Lorsque chaque règle d'un profil actif est évalué, les valeurs de la métrique spécifié sur la gâchette sont regroupées dans le temps et dans l'ensemble des cas (le cas échéant), et ce total est comparé à un seuil pour indiquer si la règle s'applique. Agrégats valides au fil du temps sont moyenne (la valeur par défaut), minimum, maximum, enfin, total et compter. Agrégats valides sur des instances sont minimum, maximum et moyenne (la valeur par défaut).

Les métriques disponibles pour les déclencheurs sont Azure storage et longueurs de Bus Service de file d'attente, les compteurs de performance standard publié par Azure Diagnostics, et n'importe quel compteur de performance personnalisé publié par chaque rôle ou de la machine virtuelle. Dans une solution de Cloud Services, lorsqu'il s'agit des compteurs de performance autres que ceux disponibles par défaut, vous devez modifier le paramètre de niveau de surveillance dans l'interface utilisateur du "Minimum" à "Verbose" pour le service.

Pour plus d'informations, voir :

- Kit de développement logiciel de surveillance [Bibliothèque de classes](http://msdn.microsoft.com/library/azure/dn510414.aspx)
- [Comment configurer les compteurs de Performance](http://msdn.microsoft.com/library/azure/dn535595.aspx)
- [Opérations à l'échelle automatique](http://msdn.microsoft.com/library/azure/dn510374.aspx)
- [Ajouter des paramètres de Autoscale](http://msdn.microsoft.com/library/azure/dn510372.aspx)
- [Auto Echelonnement pourcentage CPU avec l'azur bibliothèque de gestion des Services de surveillance des Services Cloud](http://rickrainey.com/2013/12/15/auto-scaling-cloud-services-on-cpu-percentage-with-the-windows-azure-monitoring-services-management-library/)
- [Comment utiliser la bibliothèque de gestion de Services de surveillance Azure pour créer une règle de Autoscale](http://blogs.msdn.com/b/cie/archive/2014/02/20/how-to-use-windows-azure-monitoring-services-management-library-to-create-an-autoscale-rule.aspx)

## Lignes directrices et modèles liés
Les modèles et les lignes directrices suivantes peuvent également être pertinents à votre scénario lorsque vous implémentez autoscaling :

- [Modèle de limitation](http://msdn.microsoft.com/library/dn589798.aspx). Ce modèle décrit comment une application peut continuer à fonctionner et à répondre aux contrats de niveau de service, lorsqu'une demande accrue ajoutera une charge extrême sur les ressources. La limitation peut servir avec autoscaling pour empêcher un système d'être débordés, tandis que le système évolue sur.
- [Modèle de consommateurs concurrentes](http://msdn.microsoft.com/library/dn568101.aspx). Ce modèle décrit comment implémenter un pool d'instances de service qui peut gérer les messages de n'importe quelle instance de l'application. Échelle automatique peut être utilisé pour démarrer et arrêter des instances de service pour correspondre à la charge de travail attendue. Cette approche permet un système pour traiter plusieurs messages en même temps pour optimiser le débit, d'améliorer l'évolutivité et la disponibilité et équilibrer la charge de travail.
- [Instrumentation et des conseils de télémétrie](http://msdn.microsoft.com/library/dn589775.aspx). Instrumentation et télémétrie sont vitales pour la collecte des informations qui peuvent de piloter le processus d'échelle automatique.

## Plus d'informations
- [Comment faire évoluer une Application](cloud-services-how-to-scale.md)
- [À l'échelle automatiquement une application Web rôles, rôles de travail ou des Machines virtuelles en cours d'exécution](cloud-services-how-to-manage.md#linkresources)
- [Comment : lier une ressource à un service de Cloud Computing](cloud-services-how-to-manage.md#linkresources)
- [Ressources liées à l'échelle](cloud-services-how-to-scale.md#scalelink)
- [Bibliothèque de gestion des Services de surveillance de Azure](http://www.nuget.org/packages/Microsoft.WindowsAzure.Management.Monitoring)
- [Azur Service Management API REST](http://msdn.microsoft.com/library/azure/ee460799.aspx)
- [Opérations à l'échelle automatique](http://msdn.microsoft.com/library/azure/dn510374.aspx)
- [Microsoft.WindowsAzure.Management.Monitoring.Autoscale Namespace](http://msdn.microsoft.com/library/azure/microsoft.windowsazure.management.monitoring.autoscale.aspx)
- Le [Bloc d'Application AutoScaling](http://msdn.microsoft.com/library/hh680892%28v=pandp.50%29.aspx) scénarios clés et de la documentation sur MSDN.
