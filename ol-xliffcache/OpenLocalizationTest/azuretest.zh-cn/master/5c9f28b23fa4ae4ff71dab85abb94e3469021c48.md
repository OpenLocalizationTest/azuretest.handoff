<properties
   pageTitle="Autoscaling guidance | Microsoft Azure"
   description="Guidance upon how to autoscale to dynamically allocate resources required by an application."
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="masimms"
   editor=""
   tags=""/>

<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="04/28/2015"
   ms.author="masashin"/>

# Automatische Skalierung Anleitung

![](media/best-practices-auto-scaling/pnp-logo.png)

## Übersicht
Automatische Skalierung ist der Prozess der dynamisch Zuteilung der Ressourcen, die von einer Anwendung zum Zuordnen von Leistungsanforderungen und Servicevereinbarungen (SLAs) zu erfüllen, bei gleichzeitiger Minimierung der Laufzeit Kosten benötigt. Mit zunehmender Arbeitsaufwand erfordern eine Anwendung zusätzliche Mittel für die Durchführung seiner Aufgaben rechtzeitig zu aktivieren. Als Nachfrage nachlassen, können Ressourcen, Kosten zu minimieren und noch gleichzeitig ausreichende Leistung und Einhaltung von SLAs aufgehoben.
Automatische Skalierung nutzt die Elastizität der Wolke gehosteten Umgebungen während Lockerung Verwaltung overhead durch Verringerung der Notwendigkeit eines Operators kontinuierlich überwachen die Leistung eines Systems und Entscheidungen über das Hinzufügen oder Entfernen von Ressourcen.
> Automatische Skalierung bezieht sich auf alle Ressourcen, die von einer Anwendung, nicht nur die Compute-Ressourcen verwendet. Beispielsweise wenn Ihr System Nachrichtenwarteschlangen verwendet senden und empfangen von Informationen, konnte es zusätzliche Warteschlangen erstellt werden.

## Arten der Skalierung
Skalierung in der Regel dauert eine von zwei Formen – vertikale und horizontale Skalierung:

- **Vertikale Skalierung** (oft bezeichnet als _rauf und runter skalieren_) requires that you modify the hardware (expand or reduce its capacity and performance), or redeploy the solution using alternative hardware that has the appropriate capacity and performance. In a cloud environment, the hardware platform is typically a virtualized environment. Unless the original hardware was substantially overprovisioned, with the consequent upfront capital expense, vertically scaling up in this environment involves provisioning more powerful resources, and then moving the system onto these new resources. Vertical scaling is often a disruptive process that requires making the system temporarily unavailable while it is being redeployed. It may be possible to keep the original system running while the new hardware is provisioned and brought online, but there will likely be some interruption while the processing transitions from the old environment to the new one. It is uncommon to use autoscaling to implement a vertical scaling strategy.
- **Horizontale Skalierung** (oft bezeichnet als _Skalierung und_) erfordert die Lösung auf zusätzliche oder weniger Ressourcen, die in der Regel Rohstoff-Ressourcen anstatt High-Power-Systeme sind bereitstellen. Die Lösung kann weiterhin ohne Unterbrechung ausgeführt, während diese Ressourcen bereitgestellt werden. Wenn der Bereitstellungsprozess abgeschlossen ist, können Kopien der Elemente, aus die die Lösung besteht auf diese zusätzlichen Ressourcen bereitgestellt und zur Verfügung gestellt werden. Wenn die Nachfrage sinkt, können die zusätzlichen Mittel zurückgefordert werden, nachdem die Elemente, deren Verwendung ordnungsgemäß heruntergefahren wurde. Viele Cloud-basierte Systeme, einschließlich Microsoft Azure, unterstützen die Automatisierung dieser Form der Skalierung.

## Umsetzung einer Strategie für die automatische Skalierung
Umsetzung einer Strategie für die automatische Skalierung in der Regel umfasst die folgenden Komponenten und Prozesse:

- Mess- und Überwachungssysteme Ebene der Anwendung, Service und Infrastruktur, die wichtige Kennzahlen wie Reaktionszeiten, Warteschlangenlängen, Prozessorauslastung und Speichernutzung zu erfassen.
- Entscheidungs-Logik, die kann die überwachten Skalierungsfaktoren gegen vordefinierte System Schwellenwerte oder Zeitpläne zu bewerten und Entscheidungen bezüglich ob oder nicht zu skalieren.
- Komponenten, die für die Durchführung von Aufgaben im Zusammenhang mit der Skalierung des Systems, z.B. Bereitstellung oder de Bereitstellung Ressourcen verantwortlich sind.
- Prüfung, Überwachung und Optimierung der Autoscaling-Strategie, um sicherzustellen, dass es funktioniert wie erwartet.

Die meisten Cloud-basierte Umgebungen wie Microsoft Azure, bieten integrierte automatische Skalierung Mechanismen dieser Adresse-Szenarien. Wenn die Umwelt oder den Service, den Sie verwenden nicht die erforderliche automatische Skalierung Funktionen, oder wenn Sie extreme Autoskalierung Anforderungen außerhalb seiner Möglichkeiten haben, eine benutzerdefinierte Implementierung kann erforderlich sein, Betriebs- und Systemkennzahlen sammeln, analysieren Sie, um relevante Daten zu identifizieren und dann Ressourcen entsprechend skalieren.

## Überlegungen zum Implementieren von autoscaling
Automatische Skalierung ist keine sofortige Lösung. Einfach ein System Ressourcen hinzufügen oder laufen mehrere Instanzen eines Prozesses garantiert nicht, dass die Leistung des Systems verbessert wird.  Beachten Sie die folgenden Punkte beim Entwerfen einer Strategie für die automatische Skalierung:

- The system must be designed to be horizontally scalable. Avoid making assumptions about instance affinity; do not design solutions that require that the code is always running in a specific instance of a process. When scaling a cloud service or web site horizontally, do not assume that a series of requests from the same source will always be routed to the same instance. For the same reason, design services to be stateless to avoid requiring a series of requests from an application to always be routed to the same instance of a service. When designing a service that reads messages from a queue and processes them, do not make any assumptions about which instance of the service handles a specific message because autoscaling could start additional instances of a service as the queue length grows. The [Konkurrierende Verbraucher Muster](http://msdn.microsoft.com/library/dn568101.aspx) beschreibt dieses Szenario zu behandeln.
- Wenn die Lösung eine langwierige Aufgabe implementiert, entwerfen Sie, diese Aufgabe zu unterstützen sowohl Skalierung Skalierung in. Ohne angemessene Pflege, eine solche Aufgabe könnte verhindern, dass eine Instanz eines Prozesses Herunterfahren sauber zu sein, wenn das System skaliert, oder es könnten Daten verlieren, wenn der Prozess gewaltsam beendet ist. Idealerweise umgestalten Sie eine langwierige Aufgabe und brechen Sie die Verarbeitung, die sie in kleinere, diskrete Klumpen ausführt. Die [Rohre und Filter-Muster](http://msdn.microsoft.com/library/dn568100.aspx) Zeigt anhand eines Beispiels, wie Sie dies erreichen können. Alternativ können Sie einen Checkpoint-Mechanismus implementieren, dass Datensätze über die Aufgabe in regelmäßigen Abständen Zustandsinformationen, und speichern diesen Zustand im dauerhaften Speicher, die von einer beliebigen Instanz des Prozesses Ausführen des Tasks zugegriffen werden kann. Auf diese Weise wenn der Prozess heruntergefahren, ist kann die Arbeit, mit der es ausgeführt wurde ab dem letzten Checkpoint fortgesetzt werden mithilfe einer anderen Instanz.
- Wenn Tasks im Hintergrund laufen auf separaten Compute Instanzen, wie z. B. im Worker-Funktionen von Cloud-Diensten Anwendung gehostet, müssen Sie möglicherweise verschiedene Teile der Anwendung, verwendet unterschiedliche Skalierung Richtlinien zu skalieren. Beispielsweise müssen Sie möglicherweise zusätzliche UI Compute Instanzen bereitzustellen, ohne erhöhen die Anzahl der Hintergrund Compute Instanzen oder das Gegenteil davon. Wenn Sie auf verschiedene Ebenen des Dienstes (z. B. Basis- und Premium-Service-Pakete) anbieten, müssen Sie die Compute-Ressourcen für Premium-Service-Pakete noch aggressiver als die Grundversorgung Pakete dezentral skalieren um SLAs erfüllen.
- Erwägen Sie die Länge der Warteschlange über die Benutzeroberfläche und Hintergrund compute-Instanzen als Fahrer für Ihre Autoscaling-Strategie kommunizieren. Dies ist der beste Indikator für ein Ungleichgewicht oder die Differenz zwischen der aktuellen Belastung und die Verarbeitungskapazität der Hintergrundtask.
- Wenn Sie Ihre Strategie Autoscaling Indikatoren zugrunde, das Messen von Geschäftsprozessen, z. B. die Anzahl der Bestellungen pro Stunde oder die Durchschnittszeit der Ausführung einer komplexen Transaktion sicherzustellen Sie, dass Sie die Beziehung zwischen den Ergebnissen von diesen Typen von Indikatoren und der tatsächlichen Compute-Kapazitätsbedarf verstehen. Es möglicherweise erforderlich, um mehrere Komponenten oder Einheit in Reaktion auf Änderungen im Geschäft Prozessleistungsindikatoren zu berechnen.  
- Um zu verhindern, dass ein System versuchen zu skalieren, und mit vielen Tausenden von Instanzen ausgeführt verbundenen Kosten zu vermeiden, sollten Sie begrenzen die maximale Anzahl von Instanzen, die automatisch hinzugefügt werden können. Die meisten Autoscaling-Mechanismen können Sie die minimale und maximale Anzahl von Instanzen für eine Regel angeben. Darüber hinaus berücksichtigen Sie anmutig, dass beeinträchtigen die Funktionalität, die das System bereitstellt, wenn die maximale Anzahl von Instanzen bereitgestellt wurden und das System noch überlastet ist.
- Halten Sie im Verstand die Autoskalierung möglicherweise nicht die am besten geeigneten Mechanismus, um eine plötzlich auftretende Arbeitsbelastung zu behandeln. Es braucht Zeit, um Bereitstellung und starten neue Instanzen eines Diensts oder ein System Ressourcen hinzufügen und die Spitze sind vergangen, durch die Zeit, die diese zusätzlichen Ressourcen zur Verfügung gestellt werden. In diesem Szenario kann es besser, den Dienst zu beschränken sein. Weitere Informationen finden Sie unter der [Muster-Drosselung](http://msdn.microsoft.com/library/dn589798.aspx).
- Umgekehrt, wenn Sie die Fähigkeit brauchen, alle Anforderungen zu verarbeiten, wenn die Lautstärke schnell schwankt und Kosten kein wichtiger Faktor, eine aggressive Strategie automatische Skalierung, die zusätzliche Instanzen schneller beginnt in Betracht ziehen, oder mit einer geplanten Richtlinie, die eine ausreichende Anzahl von Instanzen, die die maximale beginnt zu, bevor Laden dieser Load wird erwartet.
- The autoscaling mechanism should monitor the autoscaling process and log the details of each autoscaling event (what triggered it, what resources were added or removed, and when). If you create a custom autoscaling mechanism, ensure that it incorporates this capability. The information can be analyzed to help measure the effectiveness of the autoscaling strategy, and tune it if necessary—both in the short term as the usage patterns become more obvious, and over the long term as the business expands or the requirements of the application evolve. If an application reaches the upper limit defined for autoscaling, the mechanism might also alert an operator who could manually start additional resources if the situation warrants this. Note that, under these circumstances, the operator may also be responsible for manually removing these resources after the workload eases.

## Automatische Skalierung in einer Azure-Lösung
Es gibt mehrere Optionen für die Konfiguration von Grundgröße für Ihre Azure Lösungen:

- **Azurblaue Autoskalierung**. Dieses Feature unterstützt die häufigsten Skalierung Szenarien basierend auf einem Zeitplan und optional ausgelöst Skalierung basierend auf Common Language Runtime Metriken Geschäfte (z.B. Prozessorauslastung, Warteschlangenlänge oder errichtet in und benutzerdefinierte Leistungsindikatoren). Sie können einfache Autoscaling-Richtlinien für eine Lösung konfigurieren, schnell und leicht mit Azure Management Portal, und Sie können die Azure Monitoring Services Management Library Autoscaling-Regeln mit eine feinere Steuerung konfigurieren. Weitere Informationen finden Sie im Abschnitt [Die Azure Monitoring Services Management-Bibliothek](#the-azure-monitoring-services-management-library).
- **Eine benutzerdefinierte Lösung** auf der Grundlage der Diagnose, Überwachung und Service-Management-Funktionen von Azure. Sie könnten z. B. Azure-Diagnose, benutzerdefinierten Code, oder die [System Center Management Pack für Azure](http://www.microsoft.com/download/details.aspx?id=38414) Leistung der Anwendung kontinuierlich zu überwachen; und die [Azurblaue Servicemanagement REST-API](http://msdn.microsoft.com/library/azure/ee460799.aspx), die [Microsoft Azure Management Bibliotheken](https://www.nuget.org/packages/Microsoft.WindowsAzure.Management.Libraries), oder die [Automatische Skalierung Application Block](http://msdn.microsoft.com/library/hh680892%28v=pandp.50%29.aspx) und zu skalieren. Die Metriken für die Auslösung einer Skalierungsvorgang kann integrierte oder benutzerdefinierte Zähler oder anderen Instrumenten, die Sie innerhalb der Anwendung zu implementieren. Eine benutzerdefinierte Lösung ist jedoch nicht einfach zu implementieren, und sollte nur erwogen werden, wenn keiner der früheren Ansätzen Ihre Anforderungen erfüllen kann. Beachten Sie, dass die Autoskalierung Application Block ein open-sourced-Framework ist und ist direkt von Microsoft nicht unterstützt.
- **Dienstleistungen Dritter** wie [Paraleap AzureWatch](http://www.paraleap.com/AzureWatch) deren Hilfe Sie eine Lösung basierend auf Zeitpläne, Dienst-Auslastung und Performance-Indikatoren, benutzerdefinierte Regeln und Kombinationen der verschiedenen Arten von Regeln zu skalieren.

Bei der Auswahl welche Autoscaling-Lösung anzunehmen, beachten Sie die folgenden Punkte:

- Verwenden Sie die eingebaute Autoscaling-Funktionen der Plattform, wenn sie Ihre Anforderungen erfüllen können. Wenn dies nicht der Fall ist, sorgfältig überlegen, ob Sie wirklich komplexeren Skalierung Features benötigen. Beispiele für zusätzliche Anforderungen hinausgehen, bietet eine integrierte automatische Skalierung Funktion können mehr Granularität des Steuerelements, verschiedene Möglichkeiten, Triggerereignisse für Skalierung, Skalierung über Abonnements, Skalierung andere Arten von Ressourcen und mehr zu erkennen sind.
- Consider if you can predict the load on the application with sufficient accuracy to depend only on scheduled autoscaling (adding and removing instances to meet anticipated peaks in demand). Where this is not possible, use reactive autoscaling based on metrics collected at runtime to allow the application to handle unpredictable changes in demand. However, it is typically appropriate to combine these approaches. For example, create a strategy that adds resources such as compute, storage, and queues based on a schedule of the times when you know the application is most busy. This helps to ensure that capacity is available when required without the delay encountered when starting new instances. In addition, for each scheduled rule, define metrics that allow reactive autoscaling during that period to ensure that the application can handle sustained but unpredictable peaks in demand.
- Es ist oft schwer zu verstehen, die Beziehung zwischen Metrik und Kapazität Anforderungen, vor allem, wenn eine Anwendung zunächst bereitgestellt wird. Lieber Stellen Sie ein wenig zusätzliche Kapazität zu Beginn, und dann überwachen und optimieren die Autoskalierung Regeln zu der tatsächlichen Belastung die Kapazität näher bringen.

### Verwendung von himmelblau Autoskalierung
Azurblaue Autoskalierung können Sie konfigurieren, dezentrales Skalieren und Skalieren in Optionen für eine Lösung. Azurblaue Autoskalierung kann automatisch hinzufügen und Entfernen von Instanzen von Azure Cloud Services Web und Worker-Funktionen, Azure Mobile Dienste und Web-Sites von Azure-Anwendungen. Es können auch automatische Skalierung durch starten und Beenden von Instanzen des Azure Virtual Machines. Eine himmelblau Autoscaling-Strategie umfasst zwei Gruppen von Faktoren:

- Zeitplan-basierte Grundgröße, die sicherstellen kann, zusätzliche Instanzen stehen zeitgleich mit einem erwarteten Peak im Gebrauch und skalieren können, sobald die Spitzenzeit bestanden hat. Dadurch können Sie sicherstellen, dass Sie genügend Instanzen bereits ausgeführt, ohne abzuwarten, bis das System auf die Belastung reagieren.
- Auf der Grundlage von Metriken Grundgröße, die reagiert auf Faktoren wie durchschnittliche CPU-Auslastung über die letzte Stunde oder den Rückstand von Nachrichten, die die Lösung in einer Azure Storage- oder Service Bus Warteschlange verarbeitet. Dadurch kann die Anwendung separat von den geplanten Autoscaling-Regeln, ungeplante oder unvorhergesehene Veränderungen der Nachfrage unterzubringen zu reagieren.

Beachten Sie die folgenden Punkte bei der Verwendung von Azure Grundgröße:

- Ihre Autoscaling-Strategie kombiniert sowohl geplante als auch Metriken-basierte Skalierung. Sie können beide Arten von Regeln für einen Dienst angeben, so dass eine Anwendung auf einem Zeitplan und in Reaktion auf Änderungen der Belastung skaliert.
- Sie sollten die Azure Autoscaling-Regeln konfigurieren und überwachen Sie die Performance Ihrer Anwendung im Laufe der Zeit. Nutzen Sie die Ergebnisse dieser Überwachung, die Art und Weise anpassen, in der das System bei Bedarf skaliert. Behalten Sie jedoch beachten, dass automatische Skalierung ist keinen momentanen Prozess — es braucht Zeit, um auf eine Metrik wie durchschnittliche CPU Auslastung überschreitet (oder unterschreiten) reagieren einen bestimmten Schwellenwert.
- Autoscaling rules that use a detection mechanism based on a measured trigger attribute (such as CPU usage or queue length) use an aggregated value over time, rather than the instantaneous values, to trigger an autoscaling action. By default, the aggregate is an average of the values. This prevents the system from reacting too quickly, or causing rapid oscillation. It also allows time for new instances that are auto-started to settle into running mode, preventing additional autoscaling actions from occurring while the new instances are starting up. For Cloud Services and Virtual Machines, the default period for the aggregation is 45 minutes, so it can take up to this period of time for the metric to trigger autoscaling in response to spikes in demand. You can change the aggregation period by using the SDK, but be aware that periods of less than 25 minutes may cause unpredictable results (see [Automatische Skalierung von Cloud-Diensten auf CPU-Prozentsatz mit dem Azure Monitoring Services Management-Bibliothek](http://rickrainey.com/2013/12/15/auto-scaling-cloud-services-on-cpu-percentage-with-the-windows-azure-monitoring-services-management-library/) für weitere Informationen). Bei Azure-Websites ist die Mittelungszeitraum viel kürzer, so dass neue Instanzen in etwa fünf Minuten nach einer Änderung der durchschnittlichen Trigger-Maßnahme zur Verfügung.
- Wenn Sie Grundgröße, die mit dem SDK anstatt das Webportal konfigurieren, können Sie einen detaillierteren Zeitplan angeben, während, den die Regeln aktiv sind. Auch können eigene Metriken erstellen und verwenden Sie sie mit oder ohne die bereits vorhandenen Dateien in Ihren Autoscaling-Regeln. Sie möchten beispielsweise alternative Leistungsindikatoren, z. B. die Anzahl der Zugriffe pro Sekunde oder die durchschnittliche Speicherverfügbarkeit verwenden oder benutzerdefinierte Leistungsindikatoren, die bestimmte Geschäftsprozesse zu messen. Weitere Informationen finden Sie im Abschnitt [Die Azure Monitoring Services Management-Bibliothek](#the-azure-monitoring-services-management-library).
- Wenn Sie automatische Skalierung Azure virtuelle Maschinen, eine Anzahl von Instanzen der virtuellen Maschine bereitstellen müssen, der gleich auf die maximale Anzahl ist erlaubt Ihnen Autoskalierung starten. Diese Instanzen müssen Teil der gleichen Verfügbarkeit festgelegt sein. Der virtuellen Maschinen Autoscaling-Mechanismus nicht erstellen oder Löschen von Instanzen der virtuellen Maschine; Stattdessen werden die automatische Skalierung-Regeln, die Sie konfigurieren starten und beenden eine entsprechende Anzahl dieser Instanzen. Weitere Informationen finden Sie unter [Automatisch eine Anwendung unter Webrollen, Worker-Funktionen oder virtuelle Maschinen zu skalieren](cloud-services-how-to-scale.md#autoscale).
- Wenn neue Instanzen nicht gestartet werden können, kann vielleicht weil das Maximum für ein Abonnement (z. B. die maximale Anzahl der Kerne, wenn Sie den virtuellen Maschinen-Dienst verwenden) erreicht wurde oder ein Fehler, während des Startvorgangs Auftritt des Portals zeigen, dass ein automatische Skalierung der Vorgang war erfolgreich. Jedoch nachfolgende **ChangeDeploymentConfiguration** Veranstaltungen im Portal angezeigt werden nur angezeigt, dass ein Start des Dienstes angefordert wurde, und es wird kein Ereignis gibt an, dass dieser erfolgreich abgeschlossen wurde.
- In Azure Autoscaling können Sie das Web-Portal UI auf einer Dienstinstanz Compute Ressourcen wie z. B. SQL-Datenbank-Instanzen und Warteschlangen verlinken. Dadurch können Sie leichter die Separate manuelle und automatische Skalierung Konfigurationsoptionen für die verknüpften Ressourcen zugreifen. Weitere Informationen finden Sie unter [So wird's gemacht: eine Ressource mit einem Cloud-Service verknüpfen](cloud-services-how-to-manage.md#linkresources) auf der Seite zum Verwalten von Cloud-Diensten und der Seite [Wie eine Anwendung skaliert](cloud-services-how-to-scale.md).
- Wenn Sie mehrere Richtlinien und Regeln konfigurieren, besteht die Möglichkeit, dass sie miteinander in Konflikt geraten könnten. Azurblaue Autoskalierung verwendet die folgenden Konfliktlösungsregeln um sicherzustellen, dass immer eine ausreichende Anzahl von Instanzen ausgeführt:
  - Dezentrales Skalieren Operationen immer Vorrang gegenüber Skala in Betrieb.
  - Beim Skalieren Operationen Konflikt, die Regel, die die größte Zunahme der Anzahl der Instanzen initiiert hat Vorrang.
  - Beim Skalieren in Operationen Konflikt, die Regel, die die kleinste Abnahme der Zahl der Instanzen initiiert hat Vorrang.

<a name="the-azure-monitoring-services-management-library"></a>

### Die Azure Monitoring Services Management-Bibliothek
Können die Service Management API Azure Autoskalierung mit eine feinere Steuerung konfigurieren und auf Funktionen zugreifen, die nicht über das Webportal zur Verfügung stehen. Diese API wird direkt als eine REST-Webdienst-API oder über die Azure Monitoring Services Management-Bibliothek zugegriffen werden.

Himmelblau Grundgröße wird durch Angabe Autoskalierung Profile für Cloud-Services-Rollen, virtuelle Maschinen-Verfügbarkeit-Sätze, Azure Web-Sites (als Server-Farmen in einem Webspace) oder Azure-Mobile-Dienste konfiguriert. Jedes Profil, davon ein Ziel bis zu 20 haben kann, angibt:

- Wenn es ist, angewendet werden (über eine Wiederholung oder ein Fixtermin-Intervall)
- Die erlaubte Anzahl von Instanzen (Minimum, Maximum und Standardnummer)
- Welche Autoscaling-Regeln sind in Kraft

Das Webportal ermöglicht die Konfiguration des einen festen Satz von Profilen, Tag/Nacht im Wesentlichen zu unterscheiden und Wochentag/Wochenende-Profilen, mit einem Paar von Skala Regeln basierend auf CPU-Auslastung oder Warteschlangenlänge. Mithilfe der Service Management API können Sie differenziertere Anwendbarkeit Termine für Profile konfigurieren und geben Sie bis zu zehn Regeln mit Triggern, die Grundlage jeder Metrik der Azure-Monitoring-Service zur Verfügung.

Automatische Skalierung Regeln bestehen aus einen Trigger, die angibt, wann eine Regel gilt und eine Skala Aktion bezeichnen, die die Änderung auf die Konfiguration des Ziels durchführen. Zum Zeitpunkt des Schreibens die einzige unterstützte Aktion eine Zunahme oder Abnahme der Anzahl der Instanz.

Die Auslöser für Autoskalierung Regeln basieren auf verfügbaren Messdaten. Werte für die konfigurierten Metriken sind in regelmäßigen Abständen aus den entsprechenden Quellen geprüft, wie in der Autoscaling-Konfiguration definiert. Wenn jede Regel aus einem aktiven Profil ausgewertet wird, die Werte der Metrik auf den Trigger angegeben werden aggregiert, rechtzeitig und für Instanzen (falls zutreffend), und dieses Aggregat wird verglichen mit einem Schwellenwert an, ob die Regel angewendet wird. Gültige Aggregate im Laufe der Zeit sind Durchschnitt (Standard), Minimum, Maximum, schließlich insgesamt, und zählen. Gültige Aggregate über Instanzen sind Durchschnitt (Standard), Maximum und Minimum.

Die Metriken für Trigger verfügbar sind Azure Storage und Service Bus Warteschlangenlängen, die standard-Performance-Indikatoren von Azure-Diagnose, veröffentlicht und alle benutzerdefinierten Leistungsindikator veröffentlicht von jeder Rolle oder eine virtuelle Maschine. Bei einer Cloud-Services-Lösung standardmäßig im Umgang mit Leistungsindikatoren nicht verfügbar müssen Sie die Überwachung Einstellung in der Benutzeroberfläche von "Minimum" auf "Verbose" für den Dienst ändern.

Weitere Informationen finden Sie unter:

- Überwachung der SDK [Klassenbibliothek](http://msdn.microsoft.com/library/azure/dn510414.aspx)
- [Konfigurieren von Leistungsindikatoren](http://msdn.microsoft.com/library/azure/dn535595.aspx)
- [Operationen auf automatische Skalierung](http://msdn.microsoft.com/library/azure/dn510374.aspx)
- [Autoscale Einstellungen hinzufügen](http://msdn.microsoft.com/library/azure/dn510372.aspx)
- [Automatische Skalierung von Cloud-Diensten auf CPU-Prozentsatz mit dem Azure Monitoring Services Management-Bibliothek](http://rickrainey.com/2013/12/15/auto-scaling-cloud-services-on-cpu-percentage-with-the-windows-azure-monitoring-services-management-library/)
- [Wie man Azure Monitoring Services Management-Bibliothek verwenden, um eine Autoscale-Regel erstellen](http://blogs.msdn.com/b/cie/archive/2014/02/20/how-to-use-windows-azure-monitoring-services-management-library-to-create-an-autoscale-rule.aspx)

## Ähnliche Muster und Anleitungen
Die folgenden Muster und Anleitungen auch relevant für Ihr Szenario möglicherweise bei der Implementierung von Grundgröße:

- [Muster-Drosselung](http://msdn.microsoft.com/library/dn589798.aspx). Dieses Muster beschreibt, wie eine Anwendung fortgesetzt werden kann, funktionieren und die Erfüllung von Service Level Agreements, wenn ein Anstieg der Nachfrage eine extreme Belastung auf Ressourcen platziert. Drosselung mit Autoscaling einsetzbar verhindert ein System davor überwältigt und das System heraus skaliert.
- [Konkurrierende Verbraucher Muster](http://msdn.microsoft.com/library/dn568101.aspx). Dieses Muster beschreibt einen Pool von Dienstinstanzen zu implementieren, die Nachrichten jede Anwendungsinstanz behandeln können. Automatische Skalierung kann verwendet werden, zum Starten und Beenden von Dienstinstanzen entsprechend die erwartete Arbeitsauslastung. Dieser Ansatz ermöglicht es, ein System, um mehrere Nachrichten gleichzeitig und Durchsatz zu optimieren, Skalierbarkeit und Verfügbarkeit zu verbessern und Ausgleichen der Arbeitsauslastung zu verarbeiten.
- [Instrumentierung und Telemetrie-Anleitung](http://msdn.microsoft.com/library/dn589775.aspx). Instrumentierung und Telemetrie sind entscheidend für die Erfassung der Informationen, die den Grundgröße Prozess steuern kann.

## Weitere Informationen
- [Wie eine Anwendung skaliert](cloud-services-how-to-scale.md)
- [Automatisch eine Anwendung unter Webrollen, Worker-Funktionen oder virtuelle Maschinen zu skalieren](cloud-services-how-to-manage.md#linkresources)
- [So wird's gemacht: eine Ressource mit einem Cloud-Service verknüpfen](cloud-services-how-to-manage.md#linkresources)
- [Verknüpfte Ressourcen zu skalieren](cloud-services-how-to-scale.md#scalelink)
- [Azure Monitoring Services Management-Bibliothek](http://www.nuget.org/packages/Microsoft.WindowsAzure.Management.Monitoring)
- [Azurblaue Servicemanagement REST-API](http://msdn.microsoft.com/library/azure/ee460799.aspx)
- [Operationen auf automatische Skalierung](http://msdn.microsoft.com/library/azure/dn510374.aspx)
- [Microsoft.WindowsAzure.Management.Monitoring.Autoscale Namespace](http://msdn.microsoft.com/library/azure/microsoft.windowsazure.management.monitoring.autoscale.aspx)
- Die [Automatische Skalierung Application Block](http://msdn.microsoft.com/library/hh680892%28v=pandp.50%29.aspx) Dokumentation und Schlüssel-Szenarien auf MSDN.
