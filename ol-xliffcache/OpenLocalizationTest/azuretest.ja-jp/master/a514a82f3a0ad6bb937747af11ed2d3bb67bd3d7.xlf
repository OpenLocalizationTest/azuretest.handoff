<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="ja-jp" original="2/20/2016 8:59:06 AM" tool-id="MarkdownTransformer" product-name="N/A" product-version="N/A" build-num="1">
    <header>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">a514a82f3a0ad6bb937747af11ed2d3bb67bd3d7</xliffext:olfilehash>
      <tool tool-id="MarkdownTransformer" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group extype="content">
        <group id="101">
          <trans-unit id="101" xml:space="preserve">
            <source>Analyze flight delay data with Hadoop in HDInsight | Microsoft Azure</source>
            <target state="new">Analyze flight delay data with Hadoop in HDInsight | Microsoft Azure</target>
          </trans-unit>
          <trans-unit id="102" xml:space="preserve">
            <source>Learn how to use one Windows PowerShell script to provision an HDInsight cluster, run a Hive job, run a Sqoop job, and delete the cluster.</source>
            <target state="new">Learn how to use one Windows PowerShell script to provision an HDInsight cluster, run a Hive job, run a Sqoop job, and delete the cluster.</target>
          </trans-unit>
          <trans-unit id="103" xml:space="preserve">
            <source>Analyze flight delay data by using Hive in HDInsight</source>
            <target state="new">Analyze flight delay data by using Hive in HDInsight</target>
          </trans-unit>
          <trans-unit id="104" xml:space="preserve">
            <source>Hive provides a means of running Hadoop MapReduce jobs through an SQL-like scripting language called *<bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>HiveQL[hadoop-hiveql]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>*, which can be applied towards summarizing, querying, and analyzing large volumes of data.</source>
            <target state="new">Hive provides a means of running Hadoop MapReduce jobs through an SQL-like scripting language called *<bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>HiveQL[hadoop-hiveql]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>*, which can be applied towards summarizing, querying, and analyzing large volumes of data.</target>
          </trans-unit>
          <trans-unit id="105" xml:space="preserve">
            <source>One of the major benefits of Azure HDInsight is the separation of data storage and compute.</source>
            <target state="new">One of the major benefits of Azure HDInsight is the separation of data storage and compute.</target>
          </trans-unit>
          <trans-unit id="106" xml:space="preserve">
            <source>HDInsight uses Azure Blob storage for data storage.</source>
            <target state="new">HDInsight uses Azure Blob storage for data storage.</target>
          </trans-unit>
          <trans-unit id="107" xml:space="preserve">
            <source>A common MapReduce process can be broken into 3 parts:</source>
            <target state="new">A common MapReduce process can be broken into 3 parts:</target>
          </trans-unit>
          <trans-unit id="108" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Store data in Azure Blob storage.<ept id="1">&lt;/strong&gt;</ept> This can be a continuous process.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Store data in Azure Blob storage.<ept id="1">&lt;/strong&gt;</ept> This can be a continuous process.</target>
          </trans-unit>
          <trans-unit id="109" xml:space="preserve">
            <source>For example, weather data, sensor data, web logs, and in this case, flight delay data are saved into Azure Blob storage.</source>
            <target state="new">For example, weather data, sensor data, web logs, and in this case, flight delay data are saved into Azure Blob storage.</target>
          </trans-unit>
          <trans-unit id="110" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Run jobs.<ept id="1">&lt;/strong&gt;</ept> When it is time to process the data, you run a Windows PowerShell script (or a client application) to provision an HDInsight cluster, run jobs, and delete the cluster.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Run jobs.<ept id="1">&lt;/strong&gt;</ept> When it is time to process the data, you run a Windows PowerShell script (or a client application) to provision an HDInsight cluster, run jobs, and delete the cluster.</target>
          </trans-unit>
          <trans-unit id="111" xml:space="preserve">
            <source>The jobs save output data to Azure Blob storage.</source>
            <target state="new">The jobs save output data to Azure Blob storage.</target>
          </trans-unit>
          <trans-unit id="112" xml:space="preserve">
            <source>The output data is retained even after the cluster is deleted.</source>
            <target state="new">The output data is retained even after the cluster is deleted.</target>
          </trans-unit>
          <trans-unit id="113" xml:space="preserve">
            <source>This way, you pay for only what you have consumed.</source>
            <target state="new">This way, you pay for only what you have consumed.</target>
          </trans-unit>
          <trans-unit id="114" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Retrieve the output from Azure Blob storage<ept id="1">&lt;/strong&gt;</ept>, or in this tutorial, export the data to an Azure SQL database.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Retrieve the output from Azure Blob storage<ept id="1">&lt;/strong&gt;</ept>, or in this tutorial, export the data to an Azure SQL database.</target>
          </trans-unit>
          <trans-unit id="115" xml:space="preserve">
            <source>The following diagram illustrates the scenario and the structure of this tutorial:</source>
            <target state="new">The following diagram illustrates the scenario and the structure of this tutorial:</target>
          </trans-unit>
          <trans-unit id="116" xml:space="preserve">
            <source><bpt id="1">&lt;linkText&gt;</bpt>HDI.FlightDelays.flow<ept id="1">&lt;/linkText&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;linkText&gt;</bpt>HDI.FlightDelays.flow<ept id="1">&lt;/linkText&gt;</ept></target>
          </trans-unit>
          <trans-unit id="117" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Note<ept id="1">&lt;/strong&gt;</ept>: The numbers in the diagram correspond to the section titles.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Note<ept id="1">&lt;/strong&gt;</ept>: The numbers in the diagram correspond to the section titles.</target>
          </trans-unit>
          <trans-unit id="118" xml:space="preserve">
            <source>The main portion of the tutorial shows you how to use one Windows PowerShell script to perform the following:</source>
            <target state="new">The main portion of the tutorial shows you how to use one Windows PowerShell script to perform the following:</target>
          </trans-unit>
          <trans-unit id="119" xml:space="preserve">
            <source>Provision an HDInsight cluster.</source>
            <target state="new">Provision an HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="120" xml:space="preserve">
            <source>Run a Hive job on the cluster to calculate average delays at airports.</source>
            <target state="new">Run a Hive job on the cluster to calculate average delays at airports.</target>
          </trans-unit>
          <trans-unit id="121" xml:space="preserve">
            <source>The flight delay data is stored in an Azure Blob storage account.</source>
            <target state="new">The flight delay data is stored in an Azure Blob storage account.</target>
          </trans-unit>
          <trans-unit id="122" xml:space="preserve">
            <source>Run a Sqoop job to export the Hive job output to an Azure SQL database.</source>
            <target state="new">Run a Sqoop job to export the Hive job output to an Azure SQL database.</target>
          </trans-unit>
          <trans-unit id="123" xml:space="preserve">
            <source>Delete the HDInsight cluster.</source>
            <target state="new">Delete the HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="124" xml:space="preserve">
            <source>In the appendixes, you can find the instructions for uploading flight delay data, creating/uploading a Hive query string, and preparing the Azure SQL database for the Sqoop job.</source>
            <target state="new">In the appendixes, you can find the instructions for uploading flight delay data, creating/uploading a Hive query string, and preparing the Azure SQL database for the Sqoop job.</target>
          </trans-unit>
          <trans-unit id="125" xml:space="preserve">
            <source>The steps in this document are specific to Windows-based HDInsight clusters.</source>
            <target state="new">The steps in this document are specific to Windows-based HDInsight clusters.</target>
          </trans-unit>
          <trans-unit id="126" xml:space="preserve">
            <source>For steps that will work with a Linux-based cluster, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Analyze flight delay data using Hive in HDInsight (Linux)<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new">For steps that will work with a Linux-based cluster, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Analyze flight delay data using Hive in HDInsight (Linux)<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="127" xml:space="preserve">
            <source>Prerequisites</source>
            <target state="new">Prerequisites</target>
          </trans-unit>
          <trans-unit id="128" xml:space="preserve">
            <source>Before you begin this tutorial, you must have the following:</source>
            <target state="new">Before you begin this tutorial, you must have the following:</target>
          </trans-unit>
          <trans-unit id="129" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>An Azure subscription<ept id="1">&lt;/strong&gt;</ept>.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>An Azure subscription<ept id="1">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="130" xml:space="preserve">
            <source>See <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Get Azure free trial<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">See <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Get Azure free trial<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="131" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>A workstation with Azure PowerShell<ept id="1">&lt;/strong&gt;</ept>.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>A workstation with Azure PowerShell<ept id="1">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="132" xml:space="preserve">
            <source>See <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Install and use Azure PowerShell<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">See <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Install and use Azure PowerShell<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="133" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Understand HDInsight storage<ept id="1">&lt;/strong&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Understand HDInsight storage<ept id="1">&lt;/strong&gt;</ept></target>
          </trans-unit>
          <trans-unit id="134" xml:space="preserve">
            <source>Hadoop clusters in HDInsight use Azure Blob storage for data storage.</source>
            <target state="new">Hadoop clusters in HDInsight use Azure Blob storage for data storage.</target>
          </trans-unit>
          <trans-unit id="135" xml:space="preserve">
            <source>For more information, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use Azure Blob storage with HDInsight[hdinsight-storage]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use Azure Blob storage with HDInsight[hdinsight-storage]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="136" xml:space="preserve">
            <source>When you provision an HDInsight cluster, a Blob storage container of an Azure Storage account is designated as the default file system, just like in Hadoop Distributed File System (HDFS).</source>
            <target state="new">When you provision an HDInsight cluster, a Blob storage container of an Azure Storage account is designated as the default file system, just like in Hadoop Distributed File System (HDFS).</target>
          </trans-unit>
          <trans-unit id="137" xml:space="preserve">
            <source>This Storage account is referred to as the <bpt id="2">&lt;em&gt;</bpt>default Storage account<ept id="2">&lt;/em&gt;</ept>, and the Blob container is referred to as the <bpt id="4">&lt;em&gt;</bpt>default Blob container<ept id="4">&lt;/em&gt;</ept> or <bpt id="6">&lt;em&gt;</bpt>default container<ept id="6">&lt;/em&gt;</ept>.</source>
            <target state="new">This Storage account is referred to as the <bpt id="2">&lt;em&gt;</bpt>default Storage account<ept id="2">&lt;/em&gt;</ept>, and the Blob container is referred to as the <bpt id="4">&lt;em&gt;</bpt>default Blob container<ept id="4">&lt;/em&gt;</ept> or <bpt id="6">&lt;em&gt;</bpt>default container<ept id="6">&lt;/em&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="138" xml:space="preserve">
            <source>The default Storage account must be co-located in the same datacenter as the HDInsight cluster.</source>
            <target state="new">The default Storage account must be co-located in the same datacenter as the HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="139" xml:space="preserve">
            <source>Deleting an HDInsight cluster does not delete the default container or the default Storage account.</source>
            <target state="new">Deleting an HDInsight cluster does not delete the default container or the default Storage account.</target>
          </trans-unit>
          <trans-unit id="140" xml:space="preserve">
            <source>In addition to the default Storage account, other Azure Storage accounts can be bound to an HDInsight cluster during the provisioning process.</source>
            <target state="new">In addition to the default Storage account, other Azure Storage accounts can be bound to an HDInsight cluster during the provisioning process.</target>
          </trans-unit>
          <trans-unit id="141" xml:space="preserve">
            <source>The binding is to add the Storage account and Storage account key to the configuration file so the cluster can access those Storage accounts at run time.</source>
            <target state="new">The binding is to add the Storage account and Storage account key to the configuration file so the cluster can access those Storage accounts at run time.</target>
          </trans-unit>
          <trans-unit id="142" xml:space="preserve">
            <source>For instructions on adding additional Storage accounts, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Hadoop clusters in HDInsight[hdinsight-provision]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For instructions on adding additional Storage accounts, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Hadoop clusters in HDInsight[hdinsight-provision]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="143" xml:space="preserve">
            <source>The Azure Blob storage syntax is:</source>
            <target state="new">The Azure Blob storage syntax is:</target>
          </trans-unit>
          <trans-unit id="144" xml:space="preserve">
            <source>The Blob storage path is a virtual path.</source>
            <target state="new">The Blob storage path is a virtual path.</target>
          </trans-unit>
          <trans-unit id="145" xml:space="preserve">
            <source>For more information, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use Azure Blob storage with HDInsight[hdinsight-storage]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Use Azure Blob storage with HDInsight[hdinsight-storage]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="146" xml:space="preserve">
            <source>Files stored in the default container can be accessed from HDInsight by using any of the following URIs (using flightdelays.hql as an example):</source>
            <target state="new">Files stored in the default container can be accessed from HDInsight by using any of the following URIs (using flightdelays.hql as an example):</target>
          </trans-unit>
          <trans-unit id="147" xml:space="preserve">
            <source>For accessing the file directly from the Storage account, the blob name for the file is:</source>
            <target state="new">For accessing the file directly from the Storage account, the blob name for the file is:</target>
          </trans-unit>
          <trans-unit id="148" xml:space="preserve">
            <source>Notice there is no "/" in the front of the blob name.</source>
            <target state="new">Notice there is no "/" in the front of the blob name.</target>
          </trans-unit>
          <trans-unit id="149" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Files used in this tutorial<ept id="1">&lt;/strong&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Files used in this tutorial<ept id="1">&lt;/strong&gt;</ept></target>
          </trans-unit>
          <trans-unit id="150" xml:space="preserve">
            <source>This tutorial uses the on-time performance of airline flight data from <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Research and Innovative Technology Administration, Bureau of Transportation Statistics or RITA[rita-website]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">This tutorial uses the on-time performance of airline flight data from <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Research and Innovative Technology Administration, Bureau of Transportation Statistics or RITA[rita-website]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="151" xml:space="preserve">
            <source>The data has been uploaded to an Azure Blob storage container with the Public Blob access permission.</source>
            <target state="new">The data has been uploaded to an Azure Blob storage container with the Public Blob access permission.</target>
          </trans-unit>
          <trans-unit id="152" xml:space="preserve">
            <source>Because it is a public Blob container, you do not need to bind this Storage account to the HDInsight cluster running the Hive script.</source>
            <target state="new">Because it is a public Blob container, you do not need to bind this Storage account to the HDInsight cluster running the Hive script.</target>
          </trans-unit>
          <trans-unit id="153" xml:space="preserve">
            <source>The HiveQL script is also uploaded to the same Blob container.</source>
            <target state="new">The HiveQL script is also uploaded to the same Blob container.</target>
          </trans-unit>
          <trans-unit id="154" xml:space="preserve">
            <source>If you want to learn how to get/upload the data to your own Storage account, and how to create/upload the HiveQL script file, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Appendix A<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> and <bpt id="4CapsExtId1">&lt;link&gt;</bpt><bpt id="4CapsExtId2">&lt;linkText&gt;</bpt>Appendix B<ept id="4CapsExtId2">&lt;/linkText&gt;</ept><bpt id="4CapsExtId3">&lt;title&gt;</bpt><ept id="4CapsExtId3">&lt;/title&gt;</ept><ept id="4CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">If you want to learn how to get/upload the data to your own Storage account, and how to create/upload the HiveQL script file, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Appendix A<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> and <bpt id="4CapsExtId1">&lt;link&gt;</bpt><bpt id="4CapsExtId2">&lt;linkText&gt;</bpt>Appendix B<ept id="4CapsExtId2">&lt;/linkText&gt;</ept><bpt id="4CapsExtId3">&lt;title&gt;</bpt><ept id="4CapsExtId3">&lt;/title&gt;</ept><ept id="4CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="155" xml:space="preserve">
            <source>The following table lists the files used in this tutorial:</source>
            <target state="new">The following table lists the files used in this tutorial:</target>
          </trans-unit>
          <trans-unit id="156" xml:space="preserve">
            <source>Files</source>
            <target state="new">Files</target>
          </trans-unit>
          <trans-unit id="157" xml:space="preserve">
            <source>Description</source>
            <target state="new">Description</target>
          </trans-unit>
          <trans-unit id="158" xml:space="preserve">
            <source>wasb://flightdelay@hditutorialdata.blob.core.windows.net/flightdelays.hql</source>
            <target state="new">wasb://flightdelay@hditutorialdata.blob.core.windows.net/flightdelays.hql</target>
          </trans-unit>
          <trans-unit id="159" xml:space="preserve">
            <source>The HiveQL script file used by the Hive job that you will run. This script has been uploaded to an Azure Blob storage account with the public access. </source>
            <target state="new">The HiveQL script file used by the Hive job that you will run. This script has been uploaded to an Azure Blob storage account with the public access. </target>
          </trans-unit>
          <trans-unit id="160" xml:space="preserve">
            <source>Appendix B</source>
            <target state="new">Appendix B</target>
          </trans-unit>
          <trans-unit id="161" xml:space="preserve">
            <source> has instructions on preparing and uploading this file to your own Azure Blob storage account.</source>
            <target state="new"> has instructions on preparing and uploading this file to your own Azure Blob storage account.</target>
          </trans-unit>
          <trans-unit id="162" xml:space="preserve">
            <source>wasb://flightdelay@hditutorialdata.blob.core.windows.net/2013Data</source>
            <target state="new">wasb://flightdelay@hditutorialdata.blob.core.windows.net/2013Data</target>
          </trans-unit>
          <trans-unit id="163" xml:space="preserve">
            <source>Input data for the Hive job. The data has been uploaded to an Azure Blob storage account with the public access. </source>
            <target state="new">Input data for the Hive job. The data has been uploaded to an Azure Blob storage account with the public access. </target>
          </trans-unit>
          <trans-unit id="164" xml:space="preserve">
            <source>Appendix A</source>
            <target state="new">Appendix A</target>
          </trans-unit>
          <trans-unit id="165" xml:space="preserve">
            <source> has instructions on getting the data and uploading the data to your own Azure Blob storage account.</source>
            <target state="new"> has instructions on getting the data and uploading the data to your own Azure Blob storage account.</target>
          </trans-unit>
          <trans-unit id="166" xml:space="preserve">
            <source>\tutorials\flightdelays\output</source>
            <target state="new">\tutorials\flightdelays\output</target>
          </trans-unit>
          <trans-unit id="167" xml:space="preserve">
            <source>The output path for the Hive job. The default container is used for storing the output data.</source>
            <target state="new">The output path for the Hive job. The default container is used for storing the output data.</target>
          </trans-unit>
          <trans-unit id="168" xml:space="preserve">
            <source>\tutorials\flightdelays\jobstatus</source>
            <target state="new">\tutorials\flightdelays\jobstatus</target>
          </trans-unit>
          <trans-unit id="169" xml:space="preserve">
            <source>The Hive job status folder on the default container.</source>
            <target state="new">The Hive job status folder on the default container.</target>
          </trans-unit>
          <trans-unit id="170" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Understand the Hive internal table and external table<ept id="1">&lt;/strong&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Understand the Hive internal table and external table<ept id="1">&lt;/strong&gt;</ept></target>
          </trans-unit>
          <trans-unit id="171" xml:space="preserve">
            <source>There are a few things you need to know about the Hive internal table and external table:</source>
            <target state="new">There are a few things you need to know about the Hive internal table and external table:</target>
          </trans-unit>
          <trans-unit id="172" xml:space="preserve">
            <source>The <bpt id="2">&lt;strong&gt;</bpt>CREATE TABLE<ept id="2">&lt;/strong&gt;</ept> command creates an internal table.</source>
            <target state="new">The <bpt id="2">&lt;strong&gt;</bpt>CREATE TABLE<ept id="2">&lt;/strong&gt;</ept> command creates an internal table.</target>
          </trans-unit>
          <trans-unit id="173" xml:space="preserve">
            <source>The data file must be located in the default container.</source>
            <target state="new">The data file must be located in the default container.</target>
          </trans-unit>
          <trans-unit id="174" xml:space="preserve">
            <source>The <bpt id="2">&lt;strong&gt;</bpt>CREATE TABLE<ept id="2">&lt;/strong&gt;</ept> command moves the data file to the /hive/warehouse/<bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept> folder.</source>
            <target state="new">The <bpt id="2">&lt;strong&gt;</bpt>CREATE TABLE<ept id="2">&lt;/strong&gt;</ept> command moves the data file to the /hive/warehouse/<bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept> folder.</target>
          </trans-unit>
          <trans-unit id="175" xml:space="preserve">
            <source>The <bpt id="2">&lt;strong&gt;</bpt>CREATE EXTERNAL TABLE<ept id="2">&lt;/strong&gt;</ept> command creates an external table.</source>
            <target state="new">The <bpt id="2">&lt;strong&gt;</bpt>CREATE EXTERNAL TABLE<ept id="2">&lt;/strong&gt;</ept> command creates an external table.</target>
          </trans-unit>
          <trans-unit id="176" xml:space="preserve">
            <source>The data file can be located outside the default container.</source>
            <target state="new">The data file can be located outside the default container.</target>
          </trans-unit>
          <trans-unit id="177" xml:space="preserve">
            <source>The <bpt id="2">&lt;strong&gt;</bpt>CREATE EXTERNAL TABLE<ept id="2">&lt;/strong&gt;</ept> command does not move the data file.</source>
            <target state="new">The <bpt id="2">&lt;strong&gt;</bpt>CREATE EXTERNAL TABLE<ept id="2">&lt;/strong&gt;</ept> command does not move the data file.</target>
          </trans-unit>
          <trans-unit id="178" xml:space="preserve">
            <source>The <bpt id="2">&lt;strong&gt;</bpt>CREATE EXTERNAL TABLE<ept id="2">&lt;/strong&gt;</ept> command doesn't allow any folders in the LOCATION.</source>
            <target state="new">The <bpt id="2">&lt;strong&gt;</bpt>CREATE EXTERNAL TABLE<ept id="2">&lt;/strong&gt;</ept> command doesn't allow any folders in the LOCATION.</target>
          </trans-unit>
          <trans-unit id="179" xml:space="preserve">
            <source>This is the reason why the tutorial makes a copy of the sample.log file.</source>
            <target state="new">This is the reason why the tutorial makes a copy of the sample.log file.</target>
          </trans-unit>
          <trans-unit id="180" xml:space="preserve">
            <source>For more information, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>HDInsight: Hive Internal and External Tables Intro[cindygross-hive-tables]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>HDInsight: Hive Internal and External Tables Intro[cindygross-hive-tables]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="181" xml:space="preserve">
            <source>One of the HiveQL statements creates a Hive external table.</source>
            <target state="new">One of the HiveQL statements creates a Hive external table.</target>
          </trans-unit>
          <trans-unit id="182" xml:space="preserve">
            <source>The Hive external table keeps the data file in the original location.</source>
            <target state="new">The Hive external table keeps the data file in the original location.</target>
          </trans-unit>
          <trans-unit id="183" xml:space="preserve">
            <source>The Hive internal table moves the data file to hive\warehouse.</source>
            <target state="new">The Hive internal table moves the data file to hive\warehouse.</target>
          </trans-unit>
          <trans-unit id="184" xml:space="preserve">
            <source>The Hive internal table requires the data file to be located in the default container.</source>
            <target state="new">The Hive internal table requires the data file to be located in the default container.</target>
          </trans-unit>
          <trans-unit id="185" xml:space="preserve">
            <source>For data stored outside the default Blob container, you must use Hive external tables.</source>
            <target state="new">For data stored outside the default Blob container, you must use Hive external tables.</target>
          </trans-unit>
          <trans-unit id="186" xml:space="preserve">
            <source>Provision an HDInsight cluster and run Hive/Sqoop jobs</source>
            <target state="new">Provision an HDInsight cluster and run Hive/Sqoop jobs</target>
          </trans-unit>
          <trans-unit id="187" xml:space="preserve">
            <source>Hadoop MapReduce is batch processing.</source>
            <target state="new">Hadoop MapReduce is batch processing.</target>
          </trans-unit>
          <trans-unit id="188" xml:space="preserve">
            <source>The most cost-effective way to run a Hive job is to provision a cluster for the job, and delete the job after the job is completed.</source>
            <target state="new">The most cost-effective way to run a Hive job is to provision a cluster for the job, and delete the job after the job is completed.</target>
          </trans-unit>
          <trans-unit id="189" xml:space="preserve">
            <source>The following script covers the whole process.</source>
            <target state="new">The following script covers the whole process.</target>
          </trans-unit>
          <trans-unit id="190" xml:space="preserve">
            <source>For more information on provisioning an HDInsight cluster and running Hive jobs, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Hadoop clusters in HDInsight[hdinsight-provision]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> and <bpt id="4CapsExtId1">&lt;link&gt;</bpt><bpt id="4CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with HDInsight[hdinsight-use-hive]<ept id="4CapsExtId2">&lt;/linkText&gt;</ept><bpt id="4CapsExtId3">&lt;title&gt;</bpt><ept id="4CapsExtId3">&lt;/title&gt;</ept><ept id="4CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information on provisioning an HDInsight cluster and running Hive jobs, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Hadoop clusters in HDInsight[hdinsight-provision]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> and <bpt id="4CapsExtId1">&lt;link&gt;</bpt><bpt id="4CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with HDInsight[hdinsight-use-hive]<ept id="4CapsExtId2">&lt;/linkText&gt;</ept><bpt id="4CapsExtId3">&lt;title&gt;</bpt><ept id="4CapsExtId3">&lt;/title&gt;</ept><ept id="4CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="191" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>To run the Hive queries by using Windows PowerShell<ept id="1">&lt;/strong&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>To run the Hive queries by using Windows PowerShell<ept id="1">&lt;/strong&gt;</ept></target>
          </trans-unit>
          <trans-unit id="192" xml:space="preserve">
            <source>Create an Azure SQL database and the table for the Sqoop job output by using the instructions in <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Appendix C<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">Create an Azure SQL database and the table for the Sqoop job output by using the instructions in <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Appendix C<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="193" xml:space="preserve">
            <source>Prepare the parameters:</source>
            <target state="new">Prepare the parameters:</target>
          </trans-unit>
          <trans-unit id="194" xml:space="preserve">
            <source>Variable Name</source>
            <target state="new">Variable Name</target>
          </trans-unit>
          <trans-unit id="195" xml:space="preserve">
            <source>Notes</source>
            <target state="new">Notes</target>
          </trans-unit>
          <trans-unit id="196" xml:space="preserve">
            <source>$hdinsightClusterName</source>
            <target state="new">$hdinsightClusterName</target>
          </trans-unit>
          <trans-unit id="197" xml:space="preserve">
            <source>The HDInsight cluster name. If the cluster doesn't exist, the script will create one with the name entered.</source>
            <target state="new">The HDInsight cluster name. If the cluster doesn't exist, the script will create one with the name entered.</target>
          </trans-unit>
          <trans-unit id="198" xml:space="preserve">
            <source>$storageAccountName</source>
            <target state="new">$storageAccountName</target>
          </trans-unit>
          <trans-unit id="199" xml:space="preserve">
            <source>The Azure Storage account that will be used as the default Storage account. This value is needed only when the script needs to create an HDInsight cluster. Leave it blank if you have specified an existing HDInsight cluster name for $hdinsightClusterName. If the Storage account with the value entered doesn't exist, the script will create one with the name.</source>
            <target state="new">The Azure Storage account that will be used as the default Storage account. This value is needed only when the script needs to create an HDInsight cluster. Leave it blank if you have specified an existing HDInsight cluster name for $hdinsightClusterName. If the Storage account with the value entered doesn't exist, the script will create one with the name.</target>
          </trans-unit>
          <trans-unit id="200" xml:space="preserve">
            <source>$blobContainerName</source>
            <target state="new">$blobContainerName</target>
          </trans-unit>
          <trans-unit id="201" xml:space="preserve">
            <source>The Blob container that will be used for the default file system. If you leave it blank, the $hdinsightClusterName value will be used. </source>
            <target state="new">The Blob container that will be used for the default file system. If you leave it blank, the $hdinsightClusterName value will be used. </target>
          </trans-unit>
          <trans-unit id="202" xml:space="preserve">
            <source>$sqlDatabaseServerName</source>
            <target state="new">$sqlDatabaseServerName</target>
          </trans-unit>
          <trans-unit id="203" xml:space="preserve">
            <source>The Azure SQL database server name. It has to be an existing server. See </source>
            <target state="new">The Azure SQL database server name. It has to be an existing server. See </target>
          </trans-unit>
          <trans-unit id="204" xml:space="preserve">
            <source>Appendix C</source>
            <target state="new">Appendix C</target>
          </trans-unit>
          <trans-unit id="205" xml:space="preserve">
            <source> for information about creating one.</source>
            <target state="new"> for information about creating one.</target>
          </trans-unit>
          <trans-unit id="206" xml:space="preserve">
            <source>$sqlDatabaseUsername</source>
            <target state="new">$sqlDatabaseUsername</target>
          </trans-unit>
          <trans-unit id="207" xml:space="preserve">
            <source>The login name for the Azure SQL database server.</source>
            <target state="new">The login name for the Azure SQL database server.</target>
          </trans-unit>
          <trans-unit id="208" xml:space="preserve">
            <source>$sqlDatabasePassword</source>
            <target state="new">$sqlDatabasePassword</target>
          </trans-unit>
          <trans-unit id="209" xml:space="preserve">
            <source>The login password for the Azure SQL database server.</source>
            <target state="new">The login password for the Azure SQL database server.</target>
          </trans-unit>
          <trans-unit id="210" xml:space="preserve">
            <source>$sqlDatabaseName</source>
            <target state="new">$sqlDatabaseName</target>
          </trans-unit>
          <trans-unit id="211" xml:space="preserve">
            <source>The SQL database where Sqoop will export data to. The default name is HDISqoop. The table name for the Sqoop job output is AvgDelays. </source>
            <target state="new">The SQL database where Sqoop will export data to. The default name is HDISqoop. The table name for the Sqoop job output is AvgDelays. </target>
          </trans-unit>
          <trans-unit id="212" xml:space="preserve">
            <source>Open Windows PowerShell Integrated Scripting Environment (ISE).</source>
            <target state="new">Open Windows PowerShell Integrated Scripting Environment (ISE).</target>
          </trans-unit>
          <trans-unit id="213" xml:space="preserve">
            <source>Copy and paste the following script into the script pane:</source>
            <target state="new">Copy and paste the following script into the script pane:</target>
          </trans-unit>
          <trans-unit id="214" xml:space="preserve">
            <source>Press <bpt id="2">&lt;strong&gt;</bpt>F5<ept id="2">&lt;/strong&gt;</ept> to run the script.</source>
            <target state="new">Press <bpt id="2">&lt;strong&gt;</bpt>F5<ept id="2">&lt;/strong&gt;</ept> to run the script.</target>
          </trans-unit>
          <trans-unit id="215" xml:space="preserve">
            <source>The output shall be similar to:</source>
            <target state="new">The output shall be similar to:</target>
          </trans-unit>
          <trans-unit id="216" xml:space="preserve">
            <source><bpt id="1">&lt;linkText&gt;</bpt>HDI.FlightDelays.RunHiveJob.output<ept id="1">&lt;/linkText&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;linkText&gt;</bpt>HDI.FlightDelays.RunHiveJob.output<ept id="1">&lt;/linkText&gt;</ept></target>
          </trans-unit>
          <trans-unit id="217" xml:space="preserve">
            <source>Connect to your SQL database and see average flight delays by city in the AvgDelays table:</source>
            <target state="new">Connect to your SQL database and see average flight delays by city in the AvgDelays table:</target>
          </trans-unit>
          <trans-unit id="218" xml:space="preserve">
            <source><bpt id="1">&lt;linkText&gt;</bpt>HDI.FlightDelays.AvgDelays.Dataset<ept id="1">&lt;/linkText&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;linkText&gt;</bpt>HDI.FlightDelays.AvgDelays.Dataset<ept id="1">&lt;/linkText&gt;</ept></target>
          </trans-unit>
          <trans-unit id="219" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Appendix A - Upload flight delay data to Azure Blob storage</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Appendix A - Upload flight delay data to Azure Blob storage</target>
          </trans-unit>
          <trans-unit id="220" xml:space="preserve">
            <source>Uploading the data file and the HiveQL script files (see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Appendix B<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> requires some planning.</source>
            <target state="new">Uploading the data file and the HiveQL script files (see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Appendix B<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> requires some planning.</target>
          </trans-unit>
          <trans-unit id="221" xml:space="preserve">
            <source>The idea is to store the data files and the HiveQL file before provisioning an HDInsight cluster and running the Hive job.</source>
            <target state="new">The idea is to store the data files and the HiveQL file before provisioning an HDInsight cluster and running the Hive job.</target>
          </trans-unit>
          <trans-unit id="222" xml:space="preserve">
            <source>You have two options:</source>
            <target state="new">You have two options:</target>
          </trans-unit>
          <trans-unit id="223" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Use the same Azure Storage account that will be used by the HDInsight cluster as the default file system.<ept id="1">&lt;/strong&gt;</ept> Because the HDInsight cluster will have the Storage account access key, you don't need to make any additional changes.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Use the same Azure Storage account that will be used by the HDInsight cluster as the default file system.<ept id="1">&lt;/strong&gt;</ept> Because the HDInsight cluster will have the Storage account access key, you don't need to make any additional changes.</target>
          </trans-unit>
          <trans-unit id="224" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Use a different Azure Storage account from the HDInsight cluster default file system.<ept id="1">&lt;/strong&gt;</ept> If this is the case, you must modify the provisioning part of the Windows PowerShell script found in <bpt id="3CapsExtId1">&lt;link&gt;</bpt><bpt id="3CapsExtId2">&lt;linkText&gt;</bpt>Provision HDInsight cluster and run Hive/Sqoop jobs<ept id="3CapsExtId2">&lt;/linkText&gt;</ept><bpt id="3CapsExtId3">&lt;title&gt;</bpt><ept id="3CapsExtId3">&lt;/title&gt;</ept><ept id="3CapsExtId1">&lt;/link&gt;</ept> to include the Storage account as an additional Storage account.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Use a different Azure Storage account from the HDInsight cluster default file system.<ept id="1">&lt;/strong&gt;</ept> If this is the case, you must modify the provisioning part of the Windows PowerShell script found in <bpt id="3CapsExtId1">&lt;link&gt;</bpt><bpt id="3CapsExtId2">&lt;linkText&gt;</bpt>Provision HDInsight cluster and run Hive/Sqoop jobs<ept id="3CapsExtId2">&lt;/linkText&gt;</ept><bpt id="3CapsExtId3">&lt;title&gt;</bpt><ept id="3CapsExtId3">&lt;/title&gt;</ept><ept id="3CapsExtId1">&lt;/link&gt;</ept> to include the Storage account as an additional Storage account.</target>
          </trans-unit>
          <trans-unit id="225" xml:space="preserve">
            <source>For instructions, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Hadoop clusters in HDInsight[hdinsight-provision]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For instructions, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Hadoop clusters in HDInsight[hdinsight-provision]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="226" xml:space="preserve">
            <source>The HDInsight cluster then knows the access key for the Storage account.</source>
            <target state="new">The HDInsight cluster then knows the access key for the Storage account.</target>
          </trans-unit>
          <trans-unit id="227" xml:space="preserve">
            <source>The Blob storage path for the data file is hard coded in the HiveQL script file.</source>
            <target state="new">The Blob storage path for the data file is hard coded in the HiveQL script file.</target>
          </trans-unit>
          <trans-unit id="228" xml:space="preserve">
            <source>You must update it accordingly.</source>
            <target state="new">You must update it accordingly.</target>
          </trans-unit>
          <trans-unit id="229" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>To download the flight data<ept id="1">&lt;/strong&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>To download the flight data<ept id="1">&lt;/strong&gt;</ept></target>
          </trans-unit>
          <trans-unit id="230" xml:space="preserve">
            <source>Browse to <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Research and Innovative Technology Administration, Bureau of Transportation Statistics[rita-website]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">Browse to <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Research and Innovative Technology Administration, Bureau of Transportation Statistics[rita-website]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="231" xml:space="preserve">
            <source>On the page, select the following values:</source>
            <target state="new">On the page, select the following values:</target>
          </trans-unit>
          <trans-unit id="232" xml:space="preserve">
            <source>Name</source>
            <target state="new">Name</target>
          </trans-unit>
          <trans-unit id="233" xml:space="preserve">
            <source>Value</source>
            <target state="new">Value</target>
          </trans-unit>
          <trans-unit id="234" xml:space="preserve">
            <source>Filter Year</source>
            <target state="new">Filter Year</target>
          </trans-unit>
          <trans-unit id="235" xml:space="preserve">
            <source>2013 </source>
            <target state="new">2013 </target>
          </trans-unit>
          <trans-unit id="236" xml:space="preserve">
            <source>Filter Period</source>
            <target state="new">Filter Period</target>
          </trans-unit>
          <trans-unit id="237" xml:space="preserve">
            <source>January</source>
            <target state="new">January</target>
          </trans-unit>
          <trans-unit id="238" xml:space="preserve">
            <source>Fields</source>
            <target state="new">Fields</target>
          </trans-unit>
          <trans-unit id="239" xml:space="preserve">
            <source><bpt id="1">&lt;em&gt;</bpt>Year<ept id="1">&lt;/em&gt;</ept>, <bpt id="3">&lt;em&gt;</bpt>FlightDate<ept id="3">&lt;/em&gt;</ept>, <bpt id="5">&lt;em&gt;</bpt>UniqueCarrier<ept id="5">&lt;/em&gt;</ept>, <bpt id="7">&lt;em&gt;</bpt>Carrier<ept id="7">&lt;/em&gt;</ept>, <bpt id="9">&lt;em&gt;</bpt>FlightNum<ept id="9">&lt;/em&gt;</ept>, <bpt id="11">&lt;em&gt;</bpt>OriginAirportID<ept id="11">&lt;/em&gt;</ept>, <bpt id="13">&lt;em&gt;</bpt>Origin<ept id="13">&lt;/em&gt;</ept>, <bpt id="15">&lt;em&gt;</bpt>OriginCityName<ept id="15">&lt;/em&gt;</ept>, <bpt id="17">&lt;em&gt;</bpt>OriginState<ept id="17">&lt;/em&gt;</ept>, <bpt id="19">&lt;em&gt;</bpt>DestAirportID<ept id="19">&lt;/em&gt;</ept>, <bpt id="21">&lt;em&gt;</bpt>Dest<ept id="21">&lt;/em&gt;</ept>, <bpt id="23">&lt;em&gt;</bpt>DestCityName<ept id="23">&lt;/em&gt;</ept>, <bpt id="25">&lt;em&gt;</bpt>DestState<ept id="25">&lt;/em&gt;</ept>, <bpt id="27">&lt;em&gt;</bpt>DepDelayMinutes<ept id="27">&lt;/em&gt;</ept>, <bpt id="29">&lt;em&gt;</bpt>ArrDelay<ept id="29">&lt;/em&gt;</ept>, <bpt id="31">&lt;em&gt;</bpt>ArrDelayMinutes<ept id="31">&lt;/em&gt;</ept>, <bpt id="33">&lt;em&gt;</bpt>CarrierDelay<ept id="33">&lt;/em&gt;</ept>, <bpt id="35">&lt;em&gt;</bpt>WeatherDelay<ept id="35">&lt;/em&gt;</ept>, <bpt id="37">&lt;em&gt;</bpt>NASDelay<ept id="37">&lt;/em&gt;</ept>, <bpt id="39">&lt;em&gt;</bpt>SecurityDelay<ept id="39">&lt;/em&gt;</ept>, <bpt id="41">&lt;em&gt;</bpt>LateAircraftDelay<ept id="41">&lt;/em&gt;</ept> (clear all other fields)</source>
            <target state="new"><bpt id="1">&lt;em&gt;</bpt>Year<ept id="1">&lt;/em&gt;</ept>, <bpt id="3">&lt;em&gt;</bpt>FlightDate<ept id="3">&lt;/em&gt;</ept>, <bpt id="5">&lt;em&gt;</bpt>UniqueCarrier<ept id="5">&lt;/em&gt;</ept>, <bpt id="7">&lt;em&gt;</bpt>Carrier<ept id="7">&lt;/em&gt;</ept>, <bpt id="9">&lt;em&gt;</bpt>FlightNum<ept id="9">&lt;/em&gt;</ept>, <bpt id="11">&lt;em&gt;</bpt>OriginAirportID<ept id="11">&lt;/em&gt;</ept>, <bpt id="13">&lt;em&gt;</bpt>Origin<ept id="13">&lt;/em&gt;</ept>, <bpt id="15">&lt;em&gt;</bpt>OriginCityName<ept id="15">&lt;/em&gt;</ept>, <bpt id="17">&lt;em&gt;</bpt>OriginState<ept id="17">&lt;/em&gt;</ept>, <bpt id="19">&lt;em&gt;</bpt>DestAirportID<ept id="19">&lt;/em&gt;</ept>, <bpt id="21">&lt;em&gt;</bpt>Dest<ept id="21">&lt;/em&gt;</ept>, <bpt id="23">&lt;em&gt;</bpt>DestCityName<ept id="23">&lt;/em&gt;</ept>, <bpt id="25">&lt;em&gt;</bpt>DestState<ept id="25">&lt;/em&gt;</ept>, <bpt id="27">&lt;em&gt;</bpt>DepDelayMinutes<ept id="27">&lt;/em&gt;</ept>, <bpt id="29">&lt;em&gt;</bpt>ArrDelay<ept id="29">&lt;/em&gt;</ept>, <bpt id="31">&lt;em&gt;</bpt>ArrDelayMinutes<ept id="31">&lt;/em&gt;</ept>, <bpt id="33">&lt;em&gt;</bpt>CarrierDelay<ept id="33">&lt;/em&gt;</ept>, <bpt id="35">&lt;em&gt;</bpt>WeatherDelay<ept id="35">&lt;/em&gt;</ept>, <bpt id="37">&lt;em&gt;</bpt>NASDelay<ept id="37">&lt;/em&gt;</ept>, <bpt id="39">&lt;em&gt;</bpt>SecurityDelay<ept id="39">&lt;/em&gt;</ept>, <bpt id="41">&lt;em&gt;</bpt>LateAircraftDelay<ept id="41">&lt;/em&gt;</ept> (clear all other fields)</target>
          </trans-unit>
          <trans-unit id="240" xml:space="preserve">
            <source>Click <bpt id="2">&lt;strong&gt;</bpt>Download<ept id="2">&lt;/strong&gt;</ept>.</source>
            <target state="new">Click <bpt id="2">&lt;strong&gt;</bpt>Download<ept id="2">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="241" xml:space="preserve">
            <source>Unzip the file to the <bpt id="2">&lt;strong&gt;</bpt>C:\Tutorials\FlightDelays\Data<ept id="2">&lt;/strong&gt;</ept> folder.</source>
            <target state="new">Unzip the file to the <bpt id="2">&lt;strong&gt;</bpt>C:\Tutorials\FlightDelays\Data<ept id="2">&lt;/strong&gt;</ept> folder.</target>
          </trans-unit>
          <trans-unit id="242" xml:space="preserve">
            <source>Each file is a CSV file and is approximately 60GB in size.</source>
            <target state="new">Each file is a CSV file and is approximately 60GB in size.</target>
          </trans-unit>
          <trans-unit id="243" xml:space="preserve">
            <source>Rename the file to the name of the month that it contains data for.</source>
            <target state="new">Rename the file to the name of the month that it contains data for.</target>
          </trans-unit>
          <trans-unit id="244" xml:space="preserve">
            <source>For example, the file containing the January data would be named <bpt id="2">&lt;em&gt;</bpt>January.csv<ept id="2">&lt;/em&gt;</ept>.</source>
            <target state="new">For example, the file containing the January data would be named <bpt id="2">&lt;em&gt;</bpt>January.csv<ept id="2">&lt;/em&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="245" xml:space="preserve">
            <source>Repeat steps 2 and 5 to download a file for each of the 12 months in 2013.</source>
            <target state="new">Repeat steps 2 and 5 to download a file for each of the 12 months in 2013.</target>
          </trans-unit>
          <trans-unit id="246" xml:space="preserve">
            <source>You will need a minimum of one file to run the tutorial.</source>
            <target state="new">You will need a minimum of one file to run the tutorial.</target>
          </trans-unit>
          <trans-unit id="247" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>To upload the flight delay data to Azure Blob storage<ept id="1">&lt;/strong&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>To upload the flight delay data to Azure Blob storage<ept id="1">&lt;/strong&gt;</ept></target>
          </trans-unit>
          <trans-unit id="248" xml:space="preserve">
            <source>Prepare the parameters:</source>
            <target state="new">Prepare the parameters:</target>
          </trans-unit>
          <trans-unit id="249" xml:space="preserve">
            <source>Variable Name</source>
            <target state="new">Variable Name</target>
          </trans-unit>
          <trans-unit id="250" xml:space="preserve">
            <source>Notes</source>
            <target state="new">Notes</target>
          </trans-unit>
          <trans-unit id="251" xml:space="preserve">
            <source>$storageAccountName</source>
            <target state="new">$storageAccountName</target>
          </trans-unit>
          <trans-unit id="252" xml:space="preserve">
            <source>The Azure Storage account where you want to upload the data to.</source>
            <target state="new">The Azure Storage account where you want to upload the data to.</target>
          </trans-unit>
          <trans-unit id="253" xml:space="preserve">
            <source>$blobContainerName</source>
            <target state="new">$blobContainerName</target>
          </trans-unit>
          <trans-unit id="254" xml:space="preserve">
            <source>The Blob container where you want to upload the data to.</source>
            <target state="new">The Blob container where you want to upload the data to.</target>
          </trans-unit>
          <trans-unit id="255" xml:space="preserve">
            <source>Open Azure PowerShell ISE.</source>
            <target state="new">Open Azure PowerShell ISE.</target>
          </trans-unit>
          <trans-unit id="256" xml:space="preserve">
            <source>Paste the following script into the script pane:</source>
            <target state="new">Paste the following script into the script pane:</target>
          </trans-unit>
          <trans-unit id="257" xml:space="preserve">
            <source>Press <bpt id="2">&lt;strong&gt;</bpt>F5<ept id="2">&lt;/strong&gt;</ept> to run the script.</source>
            <target state="new">Press <bpt id="2">&lt;strong&gt;</bpt>F5<ept id="2">&lt;/strong&gt;</ept> to run the script.</target>
          </trans-unit>
          <trans-unit id="258" xml:space="preserve">
            <source>If you choose to use a different method for uploading the files, please make sure the file path is tutorials/flightdelays/data.</source>
            <target state="new">If you choose to use a different method for uploading the files, please make sure the file path is tutorials/flightdelays/data.</target>
          </trans-unit>
          <trans-unit id="259" xml:space="preserve">
            <source>The syntax for accessing the files is:</source>
            <target state="new">The syntax for accessing the files is:</target>
          </trans-unit>
          <trans-unit id="260" xml:space="preserve">
            <source>The path tutorials/flightdelays/data is the virtual folder you created when you uploaded the files.</source>
            <target state="new">The path tutorials/flightdelays/data is the virtual folder you created when you uploaded the files.</target>
          </trans-unit>
          <trans-unit id="261" xml:space="preserve">
            <source>Verify that there are 12 files, one for each month.</source>
            <target state="new">Verify that there are 12 files, one for each month.</target>
          </trans-unit>
          <trans-unit id="262" xml:space="preserve">
            <source>You must update the Hive query to read from the new location.</source>
            <target state="new">You must update the Hive query to read from the new location.</target>
          </trans-unit>
          <trans-unit id="263" xml:space="preserve">
            <source>You must either configure the container access permission to be public or bind the Storage account to the HDInsight cluster.</source>
            <target state="new">You must either configure the container access permission to be public or bind the Storage account to the HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="264" xml:space="preserve">
            <source>Otherwise, the Hive query string will not be able to access the data files.</source>
            <target state="new">Otherwise, the Hive query string will not be able to access the data files.</target>
          </trans-unit>
          <trans-unit id="265" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Appendix B - Create and upload a HiveQL script</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Appendix B - Create and upload a HiveQL script</target>
          </trans-unit>
          <trans-unit id="266" xml:space="preserve">
            <source>Using Azure PowerShell, you can run multiple HiveQL statements one at a time, or package the HiveQL statement into a script file.</source>
            <target state="new">Using Azure PowerShell, you can run multiple HiveQL statements one at a time, or package the HiveQL statement into a script file.</target>
          </trans-unit>
          <trans-unit id="267" xml:space="preserve">
            <source>This section shows you how to create a HiveQL script and upload the script to Azure Blob storage by using Azure PowerShell.</source>
            <target state="new">This section shows you how to create a HiveQL script and upload the script to Azure Blob storage by using Azure PowerShell.</target>
          </trans-unit>
          <trans-unit id="268" xml:space="preserve">
            <source>Hive requires the HiveQL scripts to be stored in Azure Blob storage.</source>
            <target state="new">Hive requires the HiveQL scripts to be stored in Azure Blob storage.</target>
          </trans-unit>
          <trans-unit id="269" xml:space="preserve">
            <source>The HiveQL script will perform the following:</source>
            <target state="new">The HiveQL script will perform the following:</target>
          </trans-unit>
          <trans-unit id="270" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Drop the delays_raw table<ept id="1">&lt;/strong&gt;</ept>, in case the table already exists.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Drop the delays_raw table<ept id="1">&lt;/strong&gt;</ept>, in case the table already exists.</target>
          </trans-unit>
          <trans-unit id="271" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Create the delays_raw external Hive table<ept id="1">&lt;/strong&gt;</ept> pointing to the Blob storage location with the flight delay files.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Create the delays_raw external Hive table<ept id="1">&lt;/strong&gt;</ept> pointing to the Blob storage location with the flight delay files.</target>
          </trans-unit>
          <trans-unit id="272" xml:space="preserve">
            <source>This query specifies that fields are delimited by "," and that lines are terminated by "\n".</source>
            <target state="new">This query specifies that fields are delimited by "," and that lines are terminated by "\n".</target>
          </trans-unit>
          <trans-unit id="273" xml:space="preserve">
            <source>This poses a problem when field values contain commas because Hive cannot differentiate between a comma that is a field delimiter and a one that is part of a field value (which is the case in field values for ORIGIN\_CITY\_NAME and DEST\_CITY\_NAME).</source>
            <target state="new">This poses a problem when field values contain commas because Hive cannot differentiate between a comma that is a field delimiter and a one that is part of a field value (which is the case in field values for ORIGIN\_CITY\_NAME and DEST\_CITY\_NAME).</target>
          </trans-unit>
          <trans-unit id="274" xml:space="preserve">
            <source>To address this, the query creates TEMP columns to hold data that is incorrectly split into columns.</source>
            <target state="new">To address this, the query creates TEMP columns to hold data that is incorrectly split into columns.</target>
          </trans-unit>
          <trans-unit id="275" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Drop the delays table<ept id="1">&lt;/strong&gt;</ept>, in case the table already exists.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Drop the delays table<ept id="1">&lt;/strong&gt;</ept>, in case the table already exists.</target>
          </trans-unit>
          <trans-unit id="276" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Create the delays table<ept id="1">&lt;/strong&gt;</ept>.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Create the delays table<ept id="1">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="277" xml:space="preserve">
            <source>It is helpful to clean up the data before further processing.</source>
            <target state="new">It is helpful to clean up the data before further processing.</target>
          </trans-unit>
          <trans-unit id="278" xml:space="preserve">
            <source>This query creates a new table, <bpt id="2">&lt;em&gt;</bpt>delays<ept id="2">&lt;/em&gt;</ept>, from the delays_raw table.</source>
            <target state="new">This query creates a new table, <bpt id="2">&lt;em&gt;</bpt>delays<ept id="2">&lt;/em&gt;</ept>, from the delays_raw table.</target>
          </trans-unit>
          <trans-unit id="279" xml:space="preserve">
            <source>Note that the TEMP columns (as mentioned previously) are not copied, and that the <bpt id="2">&lt;strong&gt;</bpt>substring<ept id="2">&lt;/strong&gt;</ept> function is used to remove quotation marks from the data.</source>
            <target state="new">Note that the TEMP columns (as mentioned previously) are not copied, and that the <bpt id="2">&lt;strong&gt;</bpt>substring<ept id="2">&lt;/strong&gt;</ept> function is used to remove quotation marks from the data.</target>
          </trans-unit>
          <trans-unit id="280" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Compute the average weather delay and groups the results by city name.<ept id="1">&lt;/strong&gt;</ept> It will also output the results to Blob storage.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Compute the average weather delay and groups the results by city name.<ept id="1">&lt;/strong&gt;</ept> It will also output the results to Blob storage.</target>
          </trans-unit>
          <trans-unit id="281" xml:space="preserve">
            <source>Note that the query will remove apostrophes from the data and will exclude rows where the value for <bpt id="2">&lt;strong&gt;</bpt>weather_delay<ept id="2">&lt;/strong&gt;</ept> is null.</source>
            <target state="new">Note that the query will remove apostrophes from the data and will exclude rows where the value for <bpt id="2">&lt;strong&gt;</bpt>weather_delay<ept id="2">&lt;/strong&gt;</ept> is null.</target>
          </trans-unit>
          <trans-unit id="282" xml:space="preserve">
            <source>This is necessary because Sqoop, used later in this tutorial, doesn't handle those values gracefully by default.</source>
            <target state="new">This is necessary because Sqoop, used later in this tutorial, doesn't handle those values gracefully by default.</target>
          </trans-unit>
          <trans-unit id="283" xml:space="preserve">
            <source>For a full list of the HiveQL commands, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Hive Data Definition Language[hadoop-hiveql]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For a full list of the HiveQL commands, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Hive Data Definition Language[hadoop-hiveql]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="284" xml:space="preserve">
            <source>Each HiveQL command must terminate with a semicolon.</source>
            <target state="new">Each HiveQL command must terminate with a semicolon.</target>
          </trans-unit>
          <trans-unit id="285" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>To create a HiveQL script file<ept id="1">&lt;/strong&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>To create a HiveQL script file<ept id="1">&lt;/strong&gt;</ept></target>
          </trans-unit>
          <trans-unit id="286" xml:space="preserve">
            <source>Prepare the parameters:</source>
            <target state="new">Prepare the parameters:</target>
          </trans-unit>
          <trans-unit id="287" xml:space="preserve">
            <source>Variable Name</source>
            <target state="new">Variable Name</target>
          </trans-unit>
          <trans-unit id="288" xml:space="preserve">
            <source>Notes</source>
            <target state="new">Notes</target>
          </trans-unit>
          <trans-unit id="289" xml:space="preserve">
            <source>$storageAccountName</source>
            <target state="new">$storageAccountName</target>
          </trans-unit>
          <trans-unit id="290" xml:space="preserve">
            <source>The Azure Storage account where you want to upload the HiveQL script to.</source>
            <target state="new">The Azure Storage account where you want to upload the HiveQL script to.</target>
          </trans-unit>
          <trans-unit id="291" xml:space="preserve">
            <source>$blobContainerName</source>
            <target state="new">$blobContainerName</target>
          </trans-unit>
          <trans-unit id="292" xml:space="preserve">
            <source>The Blob container where you want to upload the HiveQL script to.</source>
            <target state="new">The Blob container where you want to upload the HiveQL script to.</target>
          </trans-unit>
          <trans-unit id="293" xml:space="preserve">
            <source>Open Azure PowerShell ISE.</source>
            <target state="new">Open Azure PowerShell ISE.</target>
          </trans-unit>
          <trans-unit id="294" xml:space="preserve">
            <source>Copy and paste the following script into the script pane:</source>
            <target state="new">Copy and paste the following script into the script pane:</target>
          </trans-unit>
          <trans-unit id="295" xml:space="preserve">
            <source>Here are the variables used in the script:</source>
            <target state="new">Here are the variables used in the script:</target>
          </trans-unit>
          <trans-unit id="296" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>$hqlLocalFileName<ept id="1">&lt;/strong&gt;</ept> - The script saves the HiveQL script file locally before uploading it to Blob storage.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>$hqlLocalFileName<ept id="1">&lt;/strong&gt;</ept> - The script saves the HiveQL script file locally before uploading it to Blob storage.</target>
          </trans-unit>
          <trans-unit id="297" xml:space="preserve">
            <source>This is the file name.</source>
            <target state="new">This is the file name.</target>
          </trans-unit>
          <trans-unit id="298" xml:space="preserve">
            <source>The default value is <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>C:\tutorials\flightdelays\flightdelays.hql<bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept>.</source>
            <target state="new">The default value is <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>C:\tutorials\flightdelays\flightdelays.hql<bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="299" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>$hqlBlobName<ept id="1">&lt;/strong&gt;</ept> - This is the HiveQL script file blob name used in the Azure Blob storage.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>$hqlBlobName<ept id="1">&lt;/strong&gt;</ept> - This is the HiveQL script file blob name used in the Azure Blob storage.</target>
          </trans-unit>
          <trans-unit id="300" xml:space="preserve">
            <source>The default value is tutorials/flightdelays/flightdelays.hql.</source>
            <target state="new">The default value is tutorials/flightdelays/flightdelays.hql.</target>
          </trans-unit>
          <trans-unit id="301" xml:space="preserve">
            <source>Because the file will be written directly to Azure Blob storage, there is NOT a "/" at the beginning of the blob name.</source>
            <target state="new">Because the file will be written directly to Azure Blob storage, there is NOT a "/" at the beginning of the blob name.</target>
          </trans-unit>
          <trans-unit id="302" xml:space="preserve">
            <source>If you want to access the file from Blob storage, you will need to add a "/" at the beginning of the file name.</source>
            <target state="new">If you want to access the file from Blob storage, you will need to add a "/" at the beginning of the file name.</target>
          </trans-unit>
          <trans-unit id="303" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>$srcDataFolder<ept id="1">&lt;/strong&gt;</ept> and <bpt id="3">&lt;strong&gt;</bpt>$dstDataFolder<ept id="3">&lt;/strong&gt;</ept> - = "tutorials/flightdelays/data"</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>$srcDataFolder<ept id="1">&lt;/strong&gt;</ept> and <bpt id="3">&lt;strong&gt;</bpt>$dstDataFolder<ept id="3">&lt;/strong&gt;</ept> - = "tutorials/flightdelays/data"</target>
          </trans-unit>
          <trans-unit id="304" xml:space="preserve">
            <source>= "tutorials/flightdelays/output"</source>
            <target state="new">= "tutorials/flightdelays/output"</target>
          </trans-unit>
          <trans-unit id="305" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Appendix C - Prepare an Azure SQL database for the Sqoop job output</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Appendix C - Prepare an Azure SQL database for the Sqoop job output</target>
          </trans-unit>
          <trans-unit id="306" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>To prepare the SQL database (merge this with the Sqoop script)<ept id="1">&lt;/strong&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>To prepare the SQL database (merge this with the Sqoop script)<ept id="1">&lt;/strong&gt;</ept></target>
          </trans-unit>
          <trans-unit id="307" xml:space="preserve">
            <source>Prepare the parameters:</source>
            <target state="new">Prepare the parameters:</target>
          </trans-unit>
          <trans-unit id="308" xml:space="preserve">
            <source>Variable Name</source>
            <target state="new">Variable Name</target>
          </trans-unit>
          <trans-unit id="309" xml:space="preserve">
            <source>Notes</source>
            <target state="new">Notes</target>
          </trans-unit>
          <trans-unit id="310" xml:space="preserve">
            <source>$sqlDatabaseServerName</source>
            <target state="new">$sqlDatabaseServerName</target>
          </trans-unit>
          <trans-unit id="311" xml:space="preserve">
            <source>The name of the Azure SQL database server. Enter nothing to create a new server.</source>
            <target state="new">The name of the Azure SQL database server. Enter nothing to create a new server.</target>
          </trans-unit>
          <trans-unit id="312" xml:space="preserve">
            <source>$sqlDatabaseUsername</source>
            <target state="new">$sqlDatabaseUsername</target>
          </trans-unit>
          <trans-unit id="313" xml:space="preserve">
            <source>The login name for the Azure SQL database server. If $sqlDatabaseServerName is an existing server, the login and login password are used to authenticate with the server. Otherwise they are used to create a new server.</source>
            <target state="new">The login name for the Azure SQL database server. If $sqlDatabaseServerName is an existing server, the login and login password are used to authenticate with the server. Otherwise they are used to create a new server.</target>
          </trans-unit>
          <trans-unit id="314" xml:space="preserve">
            <source>$sqlDatabasePassword</source>
            <target state="new">$sqlDatabasePassword</target>
          </trans-unit>
          <trans-unit id="315" xml:space="preserve">
            <source>The login password for the Azure SQL database server.</source>
            <target state="new">The login password for the Azure SQL database server.</target>
          </trans-unit>
          <trans-unit id="316" xml:space="preserve">
            <source>$sqlDatabaseLocation</source>
            <target state="new">$sqlDatabaseLocation</target>
          </trans-unit>
          <trans-unit id="317" xml:space="preserve">
            <source>This value is used only when you're creating a new Azure database server.</source>
            <target state="new">This value is used only when you're creating a new Azure database server.</target>
          </trans-unit>
          <trans-unit id="318" xml:space="preserve">
            <source>$sqlDatabaseName</source>
            <target state="new">$sqlDatabaseName</target>
          </trans-unit>
          <trans-unit id="319" xml:space="preserve">
            <source>The SQL database used to create the AvgDelays table for the Sqoop job. Leaving it blank will create a database called HDISqoop. The table name for the Sqoop job output is AvgDelays. </source>
            <target state="new">The SQL database used to create the AvgDelays table for the Sqoop job. Leaving it blank will create a database called HDISqoop. The table name for the Sqoop job output is AvgDelays. </target>
          </trans-unit>
          <trans-unit id="320" xml:space="preserve">
            <source>Open Azure PowerShell ISE.</source>
            <target state="new">Open Azure PowerShell ISE.</target>
          </trans-unit>
          <trans-unit id="321" xml:space="preserve">
            <source>Copy and paste the following script into the script pane:</source>
            <target state="new">Copy and paste the following script into the script pane:</target>
          </trans-unit>
          <trans-unit id="322" xml:space="preserve">
            <source>The script uses a representational state transfer (REST) service, http://bot.whatismyipaddress.com, to retrieve your external IP address.</source>
            <target state="new">The script uses a representational state transfer (REST) service, http://bot.whatismyipaddress.com, to retrieve your external IP address.</target>
          </trans-unit>
          <trans-unit id="323" xml:space="preserve">
            <source>The IP address is used for creating a firewall rule for your SQL database server.</source>
            <target state="new">The IP address is used for creating a firewall rule for your SQL database server.</target>
          </trans-unit>
          <trans-unit id="324" xml:space="preserve">
            <source>Here are some variables used in the script:</source>
            <target state="new">Here are some variables used in the script:</target>
          </trans-unit>
          <trans-unit id="325" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>$ipAddressRestService<ept id="1">&lt;/strong&gt;</ept> - The default value is http://bot.whatismyipaddress.com.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>$ipAddressRestService<ept id="1">&lt;/strong&gt;</ept> - The default value is http://bot.whatismyipaddress.com.</target>
          </trans-unit>
          <trans-unit id="326" xml:space="preserve">
            <source>It is a public IP address REST service for getting your external IP address.</source>
            <target state="new">It is a public IP address REST service for getting your external IP address.</target>
          </trans-unit>
          <trans-unit id="327" xml:space="preserve">
            <source>You can use other services if you want.</source>
            <target state="new">You can use other services if you want.</target>
          </trans-unit>
          <trans-unit id="328" xml:space="preserve">
            <source>The external IP address retrieved through the service will be used to create a firewall rule for your Azure SQL database server, so that you can access the database from your workstation (by using a Windows PowerShell script).</source>
            <target state="new">The external IP address retrieved through the service will be used to create a firewall rule for your Azure SQL database server, so that you can access the database from your workstation (by using a Windows PowerShell script).</target>
          </trans-unit>
          <trans-unit id="329" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>$fireWallRuleName<ept id="1">&lt;/strong&gt;</ept> - This is the name of the firewall rule for the Azure SQL database server.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>$fireWallRuleName<ept id="1">&lt;/strong&gt;</ept> - This is the name of the firewall rule for the Azure SQL database server.</target>
          </trans-unit>
          <trans-unit id="330" xml:space="preserve">
            <source>The default name is <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>FlightDelay<bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept>.</source>
            <target state="new">The default name is <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>FlightDelay<bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="331" xml:space="preserve">
            <source>You can rename it if you want.</source>
            <target state="new">You can rename it if you want.</target>
          </trans-unit>
          <trans-unit id="332" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>$sqlDatabaseMaxSizeGB<ept id="1">&lt;/strong&gt;</ept> - This value is used only when you're creating a new Azure SQL database server.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>$sqlDatabaseMaxSizeGB<ept id="1">&lt;/strong&gt;</ept> - This value is used only when you're creating a new Azure SQL database server.</target>
          </trans-unit>
          <trans-unit id="333" xml:space="preserve">
            <source>The default value is 10GB.</source>
            <target state="new">The default value is 10GB.</target>
          </trans-unit>
          <trans-unit id="334" xml:space="preserve">
            <source>10GB is sufficient for this tutorial.</source>
            <target state="new">10GB is sufficient for this tutorial.</target>
          </trans-unit>
          <trans-unit id="335" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>$sqlDatabaseName<ept id="1">&lt;/strong&gt;</ept> - This value is used only when you're creating a new Azure SQL database.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>$sqlDatabaseName<ept id="1">&lt;/strong&gt;</ept> - This value is used only when you're creating a new Azure SQL database.</target>
          </trans-unit>
          <trans-unit id="336" xml:space="preserve">
            <source>The default value is HDISqoop.</source>
            <target state="new">The default value is HDISqoop.</target>
          </trans-unit>
          <trans-unit id="337" xml:space="preserve">
            <source>If you rename it, you must update the Sqoop Windows PowerShell script accordingly.</source>
            <target state="new">If you rename it, you must update the Sqoop Windows PowerShell script accordingly.</target>
          </trans-unit>
          <trans-unit id="338" xml:space="preserve">
            <source>Press <bpt id="2">&lt;strong&gt;</bpt>F5<ept id="2">&lt;/strong&gt;</ept> to run the script.</source>
            <target state="new">Press <bpt id="2">&lt;strong&gt;</bpt>F5<ept id="2">&lt;/strong&gt;</ept> to run the script.</target>
          </trans-unit>
          <trans-unit id="339" xml:space="preserve">
            <source>Validate the script output.</source>
            <target state="new">Validate the script output.</target>
          </trans-unit>
          <trans-unit id="340" xml:space="preserve">
            <source>Make sure the script ran successfully.</source>
            <target state="new">Make sure the script ran successfully.</target>
          </trans-unit>
          <trans-unit id="341" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> Next steps</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> Next steps</target>
          </trans-unit>
          <trans-unit id="342" xml:space="preserve">
            <source>Now you understand how to upload a file to Azure Blob storage, how to populate a Hive table by using the data from Azure Blob storage, how to run Hive queries, and how to use Sqoop to export data from HDFS to an Azure SQL database.</source>
            <target state="new">Now you understand how to upload a file to Azure Blob storage, how to populate a Hive table by using the data from Azure Blob storage, how to run Hive queries, and how to use Sqoop to export data from HDFS to an Azure SQL database.</target>
          </trans-unit>
          <trans-unit id="343" xml:space="preserve">
            <source>To learn more, see the following articles:</source>
            <target state="new">To learn more, see the following articles:</target>
          </trans-unit>
          <trans-unit id="344" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Getting started with HDInsight[hdinsight-get-started]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Getting started with HDInsight[hdinsight-get-started]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="345" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with HDInsight[hdinsight-use-hive]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with HDInsight[hdinsight-use-hive]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="346" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Oozie with HDInsight[hdinsight-use-oozie]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Oozie with HDInsight[hdinsight-use-oozie]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="347" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Sqoop with HDInsight[hdinsight-use-sqoop]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Sqoop with HDInsight[hdinsight-use-sqoop]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="348" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Pig with HDInsight[hdinsight-use-pig]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Pig with HDInsight[hdinsight-use-pig]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="349" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Develop Java MapReduce programs for HDInsight[hdinsight-develop-mapreduce]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Develop Java MapReduce programs for HDInsight[hdinsight-develop-mapreduce]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="350" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Develop C# Hadoop streaming programs for HDInsight[hdinsight-develop-streaming]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Develop C# Hadoop streaming programs for HDInsight[hdinsight-develop-streaming]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
        </group>
      </group>
    </body>
  </file>
</xliff>