<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="ja-jp" original="2/20/2016 9:00:59 AM" tool-id="MarkdownTransformer" product-name="N/A" product-version="N/A" build-num="1">
    <header>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">3006262b04e7c1d39272266b3a0ce559cd4a802e</xliffext:olfilehash>
      <tool tool-id="MarkdownTransformer" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group extype="content">
        <group id="101">
          <trans-unit id="101" xml:space="preserve">
            <source>Use Script Action to install Spark on Hadoop cluster | Microsoft Azure</source>
            <target state="new">Use Script Action to install Spark on Hadoop cluster | Microsoft Azure</target>
          </trans-unit>
          <trans-unit id="102" xml:space="preserve">
            <source>Learn how to customize an HDInsight cluster with Spark. You'll use a Script Action configuration option to use a script to install Spark.</source>
            <target state="new">Learn how to customize an HDInsight cluster with Spark. You'll use a Script Action configuration option to use a script to install Spark.</target>
          </trans-unit>
          <trans-unit id="103" xml:space="preserve">
            <source>Install and use Spark on HDInsight Hadoop clusters</source>
            <target state="new">Install and use Spark on HDInsight Hadoop clusters</target>
          </trans-unit>
          <trans-unit id="104" xml:space="preserve">
            <source>In this document, you will learn how to install Spark by using Script Action.</source>
            <target state="new">In this document, you will learn how to install Spark by using Script Action.</target>
          </trans-unit>
          <trans-unit id="105" xml:space="preserve">
            <source>Script Action lets you run scripts to customize a cluster, only when the cluster is being created.</source>
            <target state="new">Script Action lets you run scripts to customize a cluster, only when the cluster is being created.</target>
          </trans-unit>
          <trans-unit id="106" xml:space="preserve">
            <source>For more information, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Customize HDInsight cluster using Script Action[hdinsight-cluster-customize]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Customize HDInsight cluster using Script Action[hdinsight-cluster-customize]<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="107" xml:space="preserve">
            <source>Once you have installed Spark, you'll also learn how to run a Spark query on HDInsight clusters.</source>
            <target state="new">Once you have installed Spark, you'll also learn how to run a Spark query on HDInsight clusters.</target>
          </trans-unit>
          <trans-unit id="108" xml:space="preserve">
            <source>HDInsight also provides Spark as a cluster type, which means you can now directly provision a Spark cluster without modifying a Hadoop cluster.</source>
            <target state="new">HDInsight also provides Spark as a cluster type, which means you can now directly provision a Spark cluster without modifying a Hadoop cluster.</target>
          </trans-unit>
          <trans-unit id="109" xml:space="preserve">
            <source>However, this is limited to Windows-based clusters currently.</source>
            <target state="new">However, this is limited to Windows-based clusters currently.</target>
          </trans-unit>
          <trans-unit id="110" xml:space="preserve">
            <source>Using the Spark cluster type, you get a Windows-based HDInsight version 3.2 cluster with Spark version 1.3.1.</source>
            <target state="new">Using the Spark cluster type, you get a Windows-based HDInsight version 3.2 cluster with Spark version 1.3.1.</target>
          </trans-unit>
          <trans-unit id="111" xml:space="preserve">
            <source>For more information, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Get Started with Apache Spark on HDInsight<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Get Started with Apache Spark on HDInsight<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="112" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>What is Spark?</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>What is Spark?</target>
          </trans-unit>
          <trans-unit id="113" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept>Apache Spark<bpt id="3">&lt;html&gt;</bpt><ept id="3">&lt;/html&gt;</ept> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept>Apache Spark<bpt id="3">&lt;html&gt;</bpt><ept id="3">&lt;/html&gt;</ept> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</target>
          </trans-unit>
          <trans-unit id="114" xml:space="preserve">
            <source>Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.</source>
            <target state="new">Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.</target>
          </trans-unit>
          <trans-unit id="115" xml:space="preserve">
            <source>Spark can also be used to perform conventional disk-based data processing.</source>
            <target state="new">Spark can also be used to perform conventional disk-based data processing.</target>
          </trans-unit>
          <trans-unit id="116" xml:space="preserve">
            <source>Spark improves the traditional MapReduce framework by avoiding writes to disk in the intermediate stages.</source>
            <target state="new">Spark improves the traditional MapReduce framework by avoiding writes to disk in the intermediate stages.</target>
          </trans-unit>
          <trans-unit id="117" xml:space="preserve">
            <source>Also, Spark is compatible with the Hadoop Distributed File System (HDFS) and Azure Blob storage so the existing data can easily be processed via Spark.</source>
            <target state="new">Also, Spark is compatible with the Hadoop Distributed File System (HDFS) and Azure Blob storage so the existing data can easily be processed via Spark.</target>
          </trans-unit>
          <trans-unit id="118" xml:space="preserve">
            <source>This topic provides instructions on how to customize an HDInsight cluster to install Spark.</source>
            <target state="new">This topic provides instructions on how to customize an HDInsight cluster to install Spark.</target>
          </trans-unit>
          <trans-unit id="119" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Which version of Spark can I install?</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Which version of Spark can I install?</target>
          </trans-unit>
          <trans-unit id="120" xml:space="preserve">
            <source>In this topic, we use a Script Action custom script to install Spark on an HDInsight cluster.</source>
            <target state="new">In this topic, we use a Script Action custom script to install Spark on an HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="121" xml:space="preserve">
            <source>This script installs Spark 1.3.1.</source>
            <target state="new">This script installs Spark 1.3.1.</target>
          </trans-unit>
          <trans-unit id="122" xml:space="preserve">
            <source>You can modify this script or create your own script to install other versions of Spark.</source>
            <target state="new">You can modify this script or create your own script to install other versions of Spark.</target>
          </trans-unit>
          <trans-unit id="123" xml:space="preserve">
            <source>What the script does</source>
            <target state="new">What the script does</target>
          </trans-unit>
          <trans-unit id="124" xml:space="preserve">
            <source>This script installs Spark version 1.3.1 into <bpt id="2">&lt;code&gt;</bpt>/usr/hdp/current/spark<ept id="2">&lt;/code&gt;</ept>.</source>
            <target state="new">This script installs Spark version 1.3.1 into <bpt id="2">&lt;code&gt;</bpt>/usr/hdp/current/spark<ept id="2">&lt;/code&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="125" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Install Spark using Script Actions</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Install Spark using Script Actions</target>
          </trans-unit>
          <trans-unit id="126" xml:space="preserve">
            <source>A sample script to install Spark on an HDInsight cluster is available from a read-only Azure storage blob at <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>https://hdiconfigactions.blob.core.windows.net/linuxsparkconfigactionv01/spark-installer-v01.sh<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">A sample script to install Spark on an HDInsight cluster is available from a read-only Azure storage blob at <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>https://hdiconfigactions.blob.core.windows.net/linuxsparkconfigactionv01/spark-installer-v01.sh<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="127" xml:space="preserve">
            <source>This section provides instructions on how to use the sample script while provisioning the cluster by using the Azure portal.</source>
            <target state="new">This section provides instructions on how to use the sample script while provisioning the cluster by using the Azure portal.</target>
          </trans-unit>
          <trans-unit id="128" xml:space="preserve">
            <source>You can also use Azure PowerShell or the HDInsight .NET SDK to create a cluster using this script.</source>
            <target state="new">You can also use Azure PowerShell or the HDInsight .NET SDK to create a cluster using this script.</target>
          </trans-unit>
          <trans-unit id="129" xml:space="preserve">
            <source>For more information on using these methods, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Customize HDInsight clusters with Script Actions<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information on using these methods, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Customize HDInsight clusters with Script Actions<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="130" xml:space="preserve">
            <source>Start provisioning a cluster by using the steps in <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Linux-based HDInsight clusters<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>, but do not complete provisioning.</source>
            <target state="new">Start provisioning a cluster by using the steps in <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Linux-based HDInsight clusters<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>, but do not complete provisioning.</target>
          </trans-unit>
          <trans-unit id="131" xml:space="preserve">
            <source>On the <bpt id="2">&lt;strong&gt;</bpt>Optional Configuration<ept id="2">&lt;/strong&gt;</ept> blade, select <bpt id="4">&lt;strong&gt;</bpt>Script Actions<ept id="4">&lt;/strong&gt;</ept>, and provide the information below:</source>
            <target state="new">On the <bpt id="2">&lt;strong&gt;</bpt>Optional Configuration<ept id="2">&lt;/strong&gt;</ept> blade, select <bpt id="4">&lt;strong&gt;</bpt>Script Actions<ept id="4">&lt;/strong&gt;</ept>, and provide the information below:</target>
          </trans-unit>
          <trans-unit id="132" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>NAME<ept id="1">&lt;/strong&gt;</ept>: Enter a friendly name for the script action.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>NAME<ept id="1">&lt;/strong&gt;</ept>: Enter a friendly name for the script action.</target>
          </trans-unit>
          <trans-unit id="133" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>SCRIPT URI<ept id="1">&lt;/strong&gt;</ept>: https://hdiconfigactions.blob.core.windows.net/linuxsparkconfigactionv01/spark-installer-v01.sh</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>SCRIPT URI<ept id="1">&lt;/strong&gt;</ept>: https://hdiconfigactions.blob.core.windows.net/linuxsparkconfigactionv01/spark-installer-v01.sh</target>
          </trans-unit>
          <trans-unit id="134" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>HEAD<ept id="1">&lt;/strong&gt;</ept>: Check this option</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>HEAD<ept id="1">&lt;/strong&gt;</ept>: Check this option</target>
          </trans-unit>
          <trans-unit id="135" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>WORKER<ept id="1">&lt;/strong&gt;</ept>: Check this option</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>WORKER<ept id="1">&lt;/strong&gt;</ept>: Check this option</target>
          </trans-unit>
          <trans-unit id="136" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>ZOOKEEPER<ept id="1">&lt;/strong&gt;</ept>: Check this option to install on the Zookeeper node.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>ZOOKEEPER<ept id="1">&lt;/strong&gt;</ept>: Check this option to install on the Zookeeper node.</target>
          </trans-unit>
          <trans-unit id="137" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>PARAMETERS<ept id="1">&lt;/strong&gt;</ept>: Leave this field blank</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>PARAMETERS<ept id="1">&lt;/strong&gt;</ept>: Leave this field blank</target>
          </trans-unit>
          <trans-unit id="138" xml:space="preserve">
            <source>At the bottom of the <bpt id="2">&lt;strong&gt;</bpt>Script Actions<ept id="2">&lt;/strong&gt;</ept>, use the <bpt id="4">&lt;strong&gt;</bpt>Select<ept id="4">&lt;/strong&gt;</ept> button to save the configuration.</source>
            <target state="new">At the bottom of the <bpt id="2">&lt;strong&gt;</bpt>Script Actions<ept id="2">&lt;/strong&gt;</ept>, use the <bpt id="4">&lt;strong&gt;</bpt>Select<ept id="4">&lt;/strong&gt;</ept> button to save the configuration.</target>
          </trans-unit>
          <trans-unit id="139" xml:space="preserve">
            <source>Finally, use the <bpt id="2">&lt;strong&gt;</bpt>Select<ept id="2">&lt;/strong&gt;</ept> button at the bottom of the <bpt id="4">&lt;strong&gt;</bpt>Optional Configuration<ept id="4">&lt;/strong&gt;</ept> blade to save the optional configuration information.</source>
            <target state="new">Finally, use the <bpt id="2">&lt;strong&gt;</bpt>Select<ept id="2">&lt;/strong&gt;</ept> button at the bottom of the <bpt id="4">&lt;strong&gt;</bpt>Optional Configuration<ept id="4">&lt;/strong&gt;</ept> blade to save the optional configuration information.</target>
          </trans-unit>
          <trans-unit id="140" xml:space="preserve">
            <source>Continue provisining the cluster as described in <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Linux-based HDInsight clusters<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">Continue provisining the cluster as described in <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Provision Linux-based HDInsight clusters<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="141" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>How do I use Spark in HDInsight?</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>How do I use Spark in HDInsight?</target>
          </trans-unit>
          <trans-unit id="142" xml:space="preserve">
            <source>Spark provides APIs in Scala, Python, and Java.</source>
            <target state="new">Spark provides APIs in Scala, Python, and Java.</target>
          </trans-unit>
          <trans-unit id="143" xml:space="preserve">
            <source>You can also use the interactive Spark shell to run Spark queries.</source>
            <target state="new">You can also use the interactive Spark shell to run Spark queries.</target>
          </trans-unit>
          <trans-unit id="144" xml:space="preserve">
            <source>Once your cluster has finished provisioning, use the following to connect to your HDInsight cluster:</source>
            <target state="new">Once your cluster has finished provisioning, use the following to connect to your HDInsight cluster:</target>
          </trans-unit>
          <trans-unit id="145" xml:space="preserve">
            <source>For more information on using SSH with HDInsight, see the following:</source>
            <target state="new">For more information on using SSH with HDInsight, see the following:</target>
          </trans-unit>
          <trans-unit id="146" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="147" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="148" xml:space="preserve">
            <source>Once connected, use the following sections for specific steps on using Spark:</source>
            <target state="new">Once connected, use the following sections for specific steps on using Spark:</target>
          </trans-unit>
          <trans-unit id="149" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Using the Spark shell to run interactive queries<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Using the Spark shell to run interactive queries<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="150" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Using the Spark shell to run Spark SQL queries<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Using the Spark shell to run Spark SQL queries<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="151" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Using a standalone Scala program<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Using a standalone Scala program<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="152" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Using the Spark shell to run interactive queries</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Using the Spark shell to run interactive queries</target>
          </trans-unit>
          <trans-unit id="153" xml:space="preserve">
            <source>Run the following command to start the Spark shell:</source>
            <target state="new">Run the following command to start the Spark shell:</target>
          </trans-unit>
          <trans-unit id="154" xml:space="preserve">
            <source>After the command finishes running, you should get a Scala prompt:</source>
            <target state="new">After the command finishes running, you should get a Scala prompt:</target>
          </trans-unit>
          <trans-unit id="155" xml:space="preserve">
            <source>On the Scala prompt, enter the Spark query shown below.</source>
            <target state="new">On the Scala prompt, enter the Spark query shown below.</target>
          </trans-unit>
          <trans-unit id="156" xml:space="preserve">
            <source>This query counts the occurrence of each word in the davinci.txt file that is available at the /example/data/gutenberg/ location on the Azure Blob storage associated with the cluster.</source>
            <target state="new">This query counts the occurrence of each word in the davinci.txt file that is available at the /example/data/gutenberg/ location on the Azure Blob storage associated with the cluster.</target>
          </trans-unit>
          <trans-unit id="157" xml:space="preserve">
            <source>The output should resemble the following:</source>
            <target state="new">The output should resemble the following:</target>
          </trans-unit>
          <trans-unit id="158" xml:space="preserve">
            <source>Enter :q to exit the Scala prompt.</source>
            <target state="new">Enter :q to exit the Scala prompt.</target>
          </trans-unit>
          <trans-unit id="159" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Using the Spark shell to run Spark SQL queries</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Using the Spark shell to run Spark SQL queries</target>
          </trans-unit>
          <trans-unit id="160" xml:space="preserve">
            <source>Spark SQL allows you to use Spark to run relational queries expressed in Structured Query Language (SQL), HiveQL, or Scala.</source>
            <target state="new">Spark SQL allows you to use Spark to run relational queries expressed in Structured Query Language (SQL), HiveQL, or Scala.</target>
          </trans-unit>
          <trans-unit id="161" xml:space="preserve">
            <source>In this section, we look at using Spark to run a Hive query on a sample Hive table.</source>
            <target state="new">In this section, we look at using Spark to run a Hive query on a sample Hive table.</target>
          </trans-unit>
          <trans-unit id="162" xml:space="preserve">
            <source>The Hive table used in this section (called <bpt id="2">&lt;strong&gt;</bpt>hivesampletable<ept id="2">&lt;/strong&gt;</ept>) is available by default when you provision a cluster.</source>
            <target state="new">The Hive table used in this section (called <bpt id="2">&lt;strong&gt;</bpt>hivesampletable<ept id="2">&lt;/strong&gt;</ept>) is available by default when you provision a cluster.</target>
          </trans-unit>
          <trans-unit id="163" xml:space="preserve">
            <source>Run the following command to start the Spark shell:</source>
            <target state="new">Run the following command to start the Spark shell:</target>
          </trans-unit>
          <trans-unit id="164" xml:space="preserve">
            <source>After the command finishes running, you should get a Scala prompt:</source>
            <target state="new">After the command finishes running, you should get a Scala prompt:</target>
          </trans-unit>
          <trans-unit id="165" xml:space="preserve">
            <source>On the Scala prompt, set the Hive context.</source>
            <target state="new">On the Scala prompt, set the Hive context.</target>
          </trans-unit>
          <trans-unit id="166" xml:space="preserve">
            <source>This is required to work with Hive queries by using Spark.</source>
            <target state="new">This is required to work with Hive queries by using Spark.</target>
          </trans-unit>
          <trans-unit id="167" xml:space="preserve">
            <source><bpt id="1">&lt;code&gt;</bpt>sc<ept id="1">&lt;/code&gt;</ept> in this statement is the default Spark context that is set when you start the Spark shell.</source>
            <target state="new"><bpt id="1">&lt;code&gt;</bpt>sc<ept id="1">&lt;/code&gt;</ept> in this statement is the default Spark context that is set when you start the Spark shell.</target>
          </trans-unit>
          <trans-unit id="168" xml:space="preserve">
            <source>Run a Hive query by using the Hive context and print the output to the console.</source>
            <target state="new">Run a Hive query by using the Hive context and print the output to the console.</target>
          </trans-unit>
          <trans-unit id="169" xml:space="preserve">
            <source>The query retrieves data on devices of a specific make and limits the number of records retrieved to 20.</source>
            <target state="new">The query retrieves data on devices of a specific make and limits the number of records retrieved to 20.</target>
          </trans-unit>
          <trans-unit id="170" xml:space="preserve">
            <source>You should see an output like the following:</source>
            <target state="new">You should see an output like the following:</target>
          </trans-unit>
          <trans-unit id="171" xml:space="preserve">
            <source>Enter :q to exit the Scala prompt.</source>
            <target state="new">Enter :q to exit the Scala prompt.</target>
          </trans-unit>
          <trans-unit id="172" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Using a standalone Scala program</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>Using a standalone Scala program</target>
          </trans-unit>
          <trans-unit id="173" xml:space="preserve">
            <source>In this section, you will create a Scala application that counts the number of lines containing the letters 'a' and 'b' in a sample data file (/example/data/gutenberg/davinci.txt.)</source>
            <target state="new">In this section, you will create a Scala application that counts the number of lines containing the letters 'a' and 'b' in a sample data file (/example/data/gutenberg/davinci.txt.)</target>
          </trans-unit>
          <trans-unit id="174" xml:space="preserve">
            <source>Use the following commands to install the Scala Build Tool:</source>
            <target state="new">Use the following commands to install the Scala Build Tool:</target>
          </trans-unit>
          <trans-unit id="175" xml:space="preserve">
            <source>When prompted, select <bpt id="2">&lt;strong&gt;</bpt>Y<ept id="2">&lt;/strong&gt;</ept> to continue.</source>
            <target state="new">When prompted, select <bpt id="2">&lt;strong&gt;</bpt>Y<ept id="2">&lt;/strong&gt;</ept> to continue.</target>
          </trans-unit>
          <trans-unit id="176" xml:space="preserve">
            <source>Create the directory structure for the Scala project:</source>
            <target state="new">Create the directory structure for the Scala project:</target>
          </trans-unit>
          <trans-unit id="177" xml:space="preserve">
            <source>Create a new file named <bpt id="2">&lt;strong&gt;</bpt>simple.sbt<ept id="2">&lt;/strong&gt;</ept>, which contains the configuration information for this project.</source>
            <target state="new">Create a new file named <bpt id="2">&lt;strong&gt;</bpt>simple.sbt<ept id="2">&lt;/strong&gt;</ept>, which contains the configuration information for this project.</target>
          </trans-unit>
          <trans-unit id="178" xml:space="preserve">
            <source>Use the following as the contents of the file:</source>
            <target state="new">Use the following as the contents of the file:</target>
          </trans-unit>
          <trans-unit id="179" xml:space="preserve">
            <source>Make sure you retain the empty lines between each entry.</source>
            <target state="new">Make sure you retain the empty lines between each entry.</target>
          </trans-unit>
          <trans-unit id="180" xml:space="preserve">
            <source>Use <bpt id="2">&lt;strong&gt;</bpt>Ctrl+X<ept id="2">&lt;/strong&gt;</ept>, then <bpt id="4">&lt;strong&gt;</bpt>Y<ept id="4">&lt;/strong&gt;</ept> and <bpt id="6">&lt;strong&gt;</bpt>Enter<ept id="6">&lt;/strong&gt;</ept> to save the file.</source>
            <target state="new">Use <bpt id="2">&lt;strong&gt;</bpt>Ctrl+X<ept id="2">&lt;/strong&gt;</ept>, then <bpt id="4">&lt;strong&gt;</bpt>Y<ept id="4">&lt;/strong&gt;</ept> and <bpt id="6">&lt;strong&gt;</bpt>Enter<ept id="6">&lt;/strong&gt;</ept> to save the file.</target>
          </trans-unit>
          <trans-unit id="181" xml:space="preserve">
            <source>Use the following command to create a new file named <bpt id="2">&lt;strong&gt;</bpt>SimpleApp.scala<ept id="2">&lt;/strong&gt;</ept> in the <bpt id="4">&lt;strong&gt;</bpt>SimpleScalaApp/src/main/scala<ept id="4">&lt;/strong&gt;</ept> directory:</source>
            <target state="new">Use the following command to create a new file named <bpt id="2">&lt;strong&gt;</bpt>SimpleApp.scala<ept id="2">&lt;/strong&gt;</ept> in the <bpt id="4">&lt;strong&gt;</bpt>SimpleScalaApp/src/main/scala<ept id="4">&lt;/strong&gt;</ept> directory:</target>
          </trans-unit>
          <trans-unit id="182" xml:space="preserve">
            <source>Use the following as the contents of the file:</source>
            <target state="new">Use the following as the contents of the file:</target>
          </trans-unit>
          <trans-unit id="183" xml:space="preserve">
            <source>Use <bpt id="2">&lt;strong&gt;</bpt>Ctrl+X<ept id="2">&lt;/strong&gt;</ept>, then <bpt id="4">&lt;strong&gt;</bpt>Y<ept id="4">&lt;/strong&gt;</ept>, and <bpt id="6">&lt;strong&gt;</bpt>Enter<ept id="6">&lt;/strong&gt;</ept> to save the file.</source>
            <target state="new">Use <bpt id="2">&lt;strong&gt;</bpt>Ctrl+X<ept id="2">&lt;/strong&gt;</ept>, then <bpt id="4">&lt;strong&gt;</bpt>Y<ept id="4">&lt;/strong&gt;</ept>, and <bpt id="6">&lt;strong&gt;</bpt>Enter<ept id="6">&lt;/strong&gt;</ept> to save the file.</target>
          </trans-unit>
          <trans-unit id="184" xml:space="preserve">
            <source>From the <bpt id="2">&lt;strong&gt;</bpt>SimpleScalaApp<ept id="2">&lt;/strong&gt;</ept> directory, use the following command to build the application, and store it in a jar file:</source>
            <target state="new">From the <bpt id="2">&lt;strong&gt;</bpt>SimpleScalaApp<ept id="2">&lt;/strong&gt;</ept> directory, use the following command to build the application, and store it in a jar file:</target>
          </trans-unit>
          <trans-unit id="185" xml:space="preserve">
            <source>Once the application is compiled, you will see a <bpt id="2">&lt;strong&gt;</bpt>simpleapp_2.10-1.0.jar<ept id="2">&lt;/strong&gt;</ept> file created in the __SimpleScalaApp/target/scala-2.10** directory.</source>
            <target state="new">Once the application is compiled, you will see a <bpt id="2">&lt;strong&gt;</bpt>simpleapp_2.10-1.0.jar<ept id="2">&lt;/strong&gt;</ept> file created in the __SimpleScalaApp/target/scala-2.10** directory.</target>
          </trans-unit>
          <trans-unit id="186" xml:space="preserve">
            <source>Use the following command to run the SimpleApp.scala program:</source>
            <target state="new">Use the following command to run the SimpleApp.scala program:</target>
          </trans-unit>
          <trans-unit id="187" xml:space="preserve">
            <source>When the program finishes running, the output is displayed on the console.</source>
            <target state="new">When the program finishes running, the output is displayed on the console.</target>
          </trans-unit>
          <trans-unit id="188" xml:space="preserve">
            <source>Next steps</source>
            <target state="new">Next steps</target>
          </trans-unit>
          <trans-unit id="189" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install and use Hue on HDInsight clusters<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install and use Hue on HDInsight clusters<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="190" xml:space="preserve">
            <source>Hue is a web UI that makes it easy to create, run and save Pig and Hive jobs, as well as browse the default storage for your HDInsight cluster.</source>
            <target state="new">Hue is a web UI that makes it easy to create, run and save Pig and Hive jobs, as well as browse the default storage for your HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="191" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install R on HDInsight clusters[hdinsight-install-r]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept> provides instructions on how to use cluster customization to install and use R on HDInsight Hadoop clusters.</source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install R on HDInsight clusters[hdinsight-install-r]<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept> provides instructions on how to use cluster customization to install and use R on HDInsight Hadoop clusters.</target>
          </trans-unit>
          <trans-unit id="192" xml:space="preserve">
            <source>R is an open-source language and environment for statistical computing.</source>
            <target state="new">R is an open-source language and environment for statistical computing.</target>
          </trans-unit>
          <trans-unit id="193" xml:space="preserve">
            <source>It provides hundreds of built-in statistical functions and its own programming language that combines aspects of functional and object-oriented programming.</source>
            <target state="new">It provides hundreds of built-in statistical functions and its own programming language that combines aspects of functional and object-oriented programming.</target>
          </trans-unit>
          <trans-unit id="194" xml:space="preserve">
            <source>It also provides extensive graphical capabilities.</source>
            <target state="new">It also provides extensive graphical capabilities.</target>
          </trans-unit>
          <trans-unit id="195" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install Giraph on HDInsight clusters<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install Giraph on HDInsight clusters<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="196" xml:space="preserve">
            <source>Use cluster customization to install Giraph on HDInsight Hadoop clusters.</source>
            <target state="new">Use cluster customization to install Giraph on HDInsight Hadoop clusters.</target>
          </trans-unit>
          <trans-unit id="197" xml:space="preserve">
            <source>Giraph allows you to perform graph processing by using Hadoop, and can be used with Azure HDInsight.</source>
            <target state="new">Giraph allows you to perform graph processing by using Hadoop, and can be used with Azure HDInsight.</target>
          </trans-unit>
          <trans-unit id="198" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install Solr on HDInsight clusters<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install Solr on HDInsight clusters<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="199" xml:space="preserve">
            <source>Use cluster customization to install Solr on HDInsight Hadoop clusters.</source>
            <target state="new">Use cluster customization to install Solr on HDInsight Hadoop clusters.</target>
          </trans-unit>
          <trans-unit id="200" xml:space="preserve">
            <source>Solr allows you to perform powerful search operations on data stored.</source>
            <target state="new">Solr allows you to perform powerful search operations on data stored.</target>
          </trans-unit>
          <trans-unit id="201" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install Hue on HDInsight clusters<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Install Hue on HDInsight clusters<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="202" xml:space="preserve">
            <source>Use cluster customization to install Hue on HDInsight Hadoop clusters.</source>
            <target state="new">Use cluster customization to install Hue on HDInsight Hadoop clusters.</target>
          </trans-unit>
          <trans-unit id="203" xml:space="preserve">
            <source>Hue is a set of Web applications used to interact with a Hadoop cluster.</source>
            <target state="new">Hue is a set of Web applications used to interact with a Hadoop cluster.</target>
          </trans-unit>
        </group>
      </group>
    </body>
  </file>
</xliff>