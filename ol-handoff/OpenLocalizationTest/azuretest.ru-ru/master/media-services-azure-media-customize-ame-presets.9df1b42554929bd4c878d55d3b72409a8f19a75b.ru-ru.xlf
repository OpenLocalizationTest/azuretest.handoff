<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="ru-ru" original="2/20/2016 3:53:52 PM" tool-id="MarkdownTransformer" product-name="N/A" product-version="N/A" build-num="1">
    <header>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">42635bb0cf53457eb03a7fd505f400d6b7338d89</xliffext:olfilehash>
      <tool tool-id="MarkdownTransformer" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group extype="content">
        <group id="101">
          <trans-unit id="101" xml:space="preserve">
            <source>Manipulate encoding tasks by customizing task presets</source>
            <target state="new">Manipulate encoding tasks by customizing task presets</target>
          </trans-unit>
          <trans-unit id="102" xml:space="preserve">
            <source>The Azure Media Services Encoder allows you to pass custom preset files to Azure Media Encoder. This topic shows how to customize preset files in order to achieve the following tasks: overlay an image onto an existing video, control the output file names that the encoder produces, stitch videos. </source>
            <target state="new">The Azure Media Services Encoder allows you to pass custom preset files to Azure Media Encoder. This topic shows how to customize preset files in order to achieve the following tasks: overlay an image onto an existing video, control the output file names that the encoder produces, stitch videos. </target>
          </trans-unit>
          <trans-unit id="103" xml:space="preserve">
            <source>Manipulate encoding tasks by customizing task presets</source>
            <target state="new">Manipulate encoding tasks by customizing task presets</target>
          </trans-unit>
          <trans-unit id="104" xml:space="preserve">
            <source>The Azure Media Services Encoder allows you to pass custom preset files to Azure Media Encoder.</source>
            <target state="new">The Azure Media Services Encoder allows you to pass custom preset files to Azure Media Encoder.</target>
          </trans-unit>
          <trans-unit id="105" xml:space="preserve">
            <source>This topic shows how to customize preset files in order to achieve the following tasks:</source>
            <target state="new">This topic shows how to customize preset files in order to achieve the following tasks:</target>
          </trans-unit>
          <trans-unit id="106" xml:space="preserve">
            <source>overlay an image onto an existing video,</source>
            <target state="new">overlay an image onto an existing video,</target>
          </trans-unit>
          <trans-unit id="107" xml:space="preserve">
            <source>control the output file names that the encoder produces,</source>
            <target state="new">control the output file names that the encoder produces,</target>
          </trans-unit>
          <trans-unit id="108" xml:space="preserve">
            <source>stitch videos,</source>
            <target state="new">stitch videos,</target>
          </trans-unit>
          <trans-unit id="109" xml:space="preserve">
            <source>encode presentations with mostly speech.</source>
            <target state="new">encode presentations with mostly speech.</target>
          </trans-unit>
          <trans-unit id="110" xml:space="preserve">
            <source>Controlling Azure Media Encoder Output File Names</source>
            <target state="new">Controlling Azure Media Encoder Output File Names</target>
          </trans-unit>
          <trans-unit id="111" xml:space="preserve">
            <source>By default, the Azure Media Encoder creates output filenames by combining various attributes of the input asset and the encoding process.</source>
            <target state="new">By default, the Azure Media Encoder creates output filenames by combining various attributes of the input asset and the encoding process.</target>
          </trans-unit>
          <trans-unit id="112" xml:space="preserve">
            <source>Each attribute is identified using a macro as discussed below.</source>
            <target state="new">Each attribute is identified using a macro as discussed below.</target>
          </trans-unit>
          <trans-unit id="113" xml:space="preserve">
            <source>The following is a complete list of the macros available for output file naming:</source>
            <target state="new">The following is a complete list of the macros available for output file naming:</target>
          </trans-unit>
          <trans-unit id="114" xml:space="preserve">
            <source>Audio Bitrate - the bitrate used when encoding the audio, specified in kbps</source>
            <target state="new">Audio Bitrate - the bitrate used when encoding the audio, specified in kbps</target>
          </trans-unit>
          <trans-unit id="115" xml:space="preserve">
            <source>Audio Codec the codec used for encoding audio, valid values are: AAC, WMA, and DDP</source>
            <target state="new">Audio Codec the codec used for encoding audio, valid values are: AAC, WMA, and DDP</target>
          </trans-unit>
          <trans-unit id="116" xml:space="preserve">
            <source>Channel Count the number of audio channels encoded, valid values are: 1, 2, or 6</source>
            <target state="new">Channel Count the number of audio channels encoded, valid values are: 1, 2, or 6</target>
          </trans-unit>
          <trans-unit id="117" xml:space="preserve">
            <source>Default extension – the default file extension</source>
            <target state="new">Default extension – the default file extension</target>
          </trans-unit>
          <trans-unit id="118" xml:space="preserve">
            <source>Language the BCP-47 language code representing the language used in the audio.</source>
            <target state="new">Language the BCP-47 language code representing the language used in the audio.</target>
          </trans-unit>
          <trans-unit id="119" xml:space="preserve">
            <source>This currently defaults to “und”.</source>
            <target state="new">This currently defaults to “und”.</target>
          </trans-unit>
          <trans-unit id="120" xml:space="preserve">
            <source>Original File Name the name of the file uploaded into Azure Storage</source>
            <target state="new">Original File Name the name of the file uploaded into Azure Storage</target>
          </trans-unit>
          <trans-unit id="121" xml:space="preserve">
            <source>StreamId – the stream ID as defined by the streamID attribute of the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element in the preset file</source>
            <target state="new">StreamId – the stream ID as defined by the streamID attribute of the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element in the preset file</target>
          </trans-unit>
          <trans-unit id="122" xml:space="preserve">
            <source>Video Codec the codec used for encoding, valid values are: H264 and VC1</source>
            <target state="new">Video Codec the codec used for encoding, valid values are: H264 and VC1</target>
          </trans-unit>
          <trans-unit id="123" xml:space="preserve">
            <source>Video Bitrate the bitrate used when encoding the video, specified in kbps</source>
            <target state="new">Video Bitrate the bitrate used when encoding the video, specified in kbps</target>
          </trans-unit>
          <trans-unit id="124" xml:space="preserve">
            <source>These macros can be combine in any permutation to control the name of the files generated by the Media Services Encoder.</source>
            <target state="new">These macros can be combine in any permutation to control the name of the files generated by the Media Services Encoder.</target>
          </trans-unit>
          <trans-unit id="125" xml:space="preserve">
            <source>For example, the default naming convention is:</source>
            <target state="new">For example, the default naming convention is:</target>
          </trans-unit>
          <trans-unit id="126" xml:space="preserve">
            <source>The file naming convention is specified using the DefaultMediaOutputFileName attribute of the <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Preset<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> element.</source>
            <target state="new">The file naming convention is specified using the DefaultMediaOutputFileName attribute of the <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Preset<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> element.</target>
          </trans-unit>
          <trans-unit id="127" xml:space="preserve">
            <source>For example:</source>
            <target state="new">For example:</target>
          </trans-unit>
          <trans-unit id="128" xml:space="preserve">
            <source>The encoder will insert underscores between each macro, for example, configuration above would result in a file name like: MyVideo_H264_4500kpbs_AAC_und_ch2_128kbps.mp4.</source>
            <target state="new">The encoder will insert underscores between each macro, for example, configuration above would result in a file name like: MyVideo_H264_4500kpbs_AAC_und_ch2_128kbps.mp4.</target>
          </trans-unit>
          <trans-unit id="129" xml:space="preserve">
            <source>Creating Overlays</source>
            <target state="new">Creating Overlays</target>
          </trans-unit>
          <trans-unit id="130" xml:space="preserve">
            <source>The Azure Media Services Encoder allows you to overlay an image (jpg, bmp, gif, tif), a video, or an audio track (*.wma, *.mp3, *.wav) onto an existing video.</source>
            <target state="new">The Azure Media Services Encoder allows you to overlay an image (jpg, bmp, gif, tif), a video, or an audio track (*.wma, *.mp3, *.wav) onto an existing video.</target>
          </trans-unit>
          <trans-unit id="131" xml:space="preserve">
            <source>This functionality is similar to that of Expression Encoder 4 (Service Pack 2).</source>
            <target state="new">This functionality is similar to that of Expression Encoder 4 (Service Pack 2).</target>
          </trans-unit>
          <trans-unit id="132" xml:space="preserve">
            <source>Overlays with the Media Services Encoder</source>
            <target state="new">Overlays with the Media Services Encoder</target>
          </trans-unit>
          <trans-unit id="133" xml:space="preserve">
            <source>You can specify when the overlay will be presented, the duration the overlay will presented, and for image/video overlays where on the screen the overlay will appear. You can also have the overlays fade in and/or fade out. The audio/video files to overlay can be contained in multiple assets or a single asset. Overlays are controlled by the preset XML that is passed to the encoder. For a complete description of the preset schema, see Azure Media Encoder Schemas. Overlays are specified in the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element as shown in the following preset snippet:</source>
            <target state="new">You can specify when the overlay will be presented, the duration the overlay will presented, and for image/video overlays where on the screen the overlay will appear. You can also have the overlays fade in and/or fade out. The audio/video files to overlay can be contained in multiple assets or a single asset. Overlays are controlled by the preset XML that is passed to the encoder. For a complete description of the preset schema, see Azure Media Encoder Schemas. Overlays are specified in the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element as shown in the following preset snippet:</target>
          </trans-unit>
          <trans-unit id="134" xml:space="preserve">
            <source>Presets for Video or Image Overlays</source>
            <target state="new">Presets for Video or Image Overlays</target>
          </trans-unit>
          <trans-unit id="135" xml:space="preserve">
            <source>Overlays can be from a single or multiple assets.</source>
            <target state="new">Overlays can be from a single or multiple assets.</target>
          </trans-unit>
          <trans-unit id="136" xml:space="preserve">
            <source>When creating video overlays using multiple assets, the overlay filename is specified in the OverlayFileName attribute using %n% syntax where n is the zero-based index of the input assets for the encoding task.</source>
            <target state="new">When creating video overlays using multiple assets, the overlay filename is specified in the OverlayFileName attribute using %n% syntax where n is the zero-based index of the input assets for the encoding task.</target>
          </trans-unit>
          <trans-unit id="137" xml:space="preserve">
            <source>When creating video overlays with a single asset, the overlay file name is specified directly into the OverlayFileName attribute, as shown in the following preset snippets:</source>
            <target state="new">When creating video overlays with a single asset, the overlay file name is specified directly into the OverlayFileName attribute, as shown in the following preset snippets:</target>
          </trans-unit>
          <trans-unit id="138" xml:space="preserve">
            <source>Example 1:</source>
            <target state="new">Example 1:</target>
          </trans-unit>
          <trans-unit id="139" xml:space="preserve">
            <source>Example 2:</source>
            <target state="new">Example 2:</target>
          </trans-unit>
          <trans-unit id="140" xml:space="preserve">
            <source>The location and size of the video overlay is controlled by the OverlayRect attribute.</source>
            <target state="new">The location and size of the video overlay is controlled by the OverlayRect attribute.</target>
          </trans-unit>
          <trans-unit id="141" xml:space="preserve">
            <source>The content that is to be overlaid will be re-sized to fit this rectangle.</source>
            <target state="new">The content that is to be overlaid will be re-sized to fit this rectangle.</target>
          </trans-unit>
          <trans-unit id="142" xml:space="preserve">
            <source>Opacity is controlled by the OverlayOpacity attribute.</source>
            <target state="new">Opacity is controlled by the OverlayOpacity attribute.</target>
          </trans-unit>
          <trans-unit id="143" xml:space="preserve">
            <source>Valid values are 0.0 – 1.0, where 1.0 is 100% opaque.</source>
            <target state="new">Valid values are 0.0 – 1.0, where 1.0 is 100% opaque.</target>
          </trans-unit>
          <trans-unit id="144" xml:space="preserve">
            <source>The overlay will be displayed at the time specified by the OverlayStartTime attribute and will end at the time specified by the OverlayEndTime attribute.</source>
            <target state="new">The overlay will be displayed at the time specified by the OverlayStartTime attribute and will end at the time specified by the OverlayEndTime attribute.</target>
          </trans-unit>
          <trans-unit id="145" xml:space="preserve">
            <source>Both OverlayStartTime and OverlayEndTime should fall within the timeline of the source video.</source>
            <target state="new">Both OverlayStartTime and OverlayEndTime should fall within the timeline of the source video.</target>
          </trans-unit>
          <trans-unit id="146" xml:space="preserve">
            <source>For more information about each overlay-specific attribute, please see Azure Media Encoder Schemas.</source>
            <target state="new">For more information about each overlay-specific attribute, please see Azure Media Encoder Schemas.</target>
          </trans-unit>
          <trans-unit id="147" xml:space="preserve">
            <source>Presets for Audio Overlays</source>
            <target state="new">Presets for Audio Overlays</target>
          </trans-unit>
          <trans-unit id="148" xml:space="preserve">
            <source>Audio overlays can be any supported audio file format, for example. For a complete list of supported audio file formats, see Formats Supported by the Media Services Encoder. Audio overlays are also specified in the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element as shown in the following preset snippet:</source>
            <target state="new">Audio overlays can be any supported audio file format, for example. For a complete list of supported audio file formats, see Formats Supported by the Media Services Encoder. Audio overlays are also specified in the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element as shown in the following preset snippet:</target>
          </trans-unit>
          <trans-unit id="149" xml:space="preserve">
            <source>For audio overlays stored in multiple assets, the audio overlay filename is specified in the AudioOverlayFileName attribute using %n% syntax, where n is the zero-based index of the collection of input assets to the encoding Task.</source>
            <target state="new">For audio overlays stored in multiple assets, the audio overlay filename is specified in the AudioOverlayFileName attribute using %n% syntax, where n is the zero-based index of the collection of input assets to the encoding Task.</target>
          </trans-unit>
          <trans-unit id="150" xml:space="preserve">
            <source>For audio overlays stored in a single asset the overlay filename is specified directly in the AudioOverlayFileName attribute.</source>
            <target state="new">For audio overlays stored in a single asset the overlay filename is specified directly in the AudioOverlayFileName attribute.</target>
          </trans-unit>
          <trans-unit id="151" xml:space="preserve">
            <source>The AudioOverlayLayoutMode determines when the audio overlay will be presented.</source>
            <target state="new">The AudioOverlayLayoutMode determines when the audio overlay will be presented.</target>
          </trans-unit>
          <trans-unit id="152" xml:space="preserve">
            <source>When set to “WholeSequence” the audio track will be presented during the entire duration of the video.</source>
            <target state="new">When set to “WholeSequence” the audio track will be presented during the entire duration of the video.</target>
          </trans-unit>
          <trans-unit id="153" xml:space="preserve">
            <source>When set to “Custom” the AudioOverlayStartTime and AudioOverlayEndTime attributes determine when the audio overlay begins and ends.</source>
            <target state="new">When set to “Custom” the AudioOverlayStartTime and AudioOverlayEndTime attributes determine when the audio overlay begins and ends.</target>
          </trans-unit>
          <trans-unit id="154" xml:space="preserve">
            <source>Both OverlayStartTime and OverlayEndTime should fall within the timeline of the source video.</source>
            <target state="new">Both OverlayStartTime and OverlayEndTime should fall within the timeline of the source video.</target>
          </trans-unit>
          <trans-unit id="155" xml:space="preserve">
            <source>For more information on all of the audio overlay attributes, see the Azure Media Encoder Schemas.</source>
            <target state="new">For more information on all of the audio overlay attributes, see the Azure Media Encoder Schemas.</target>
          </trans-unit>
          <trans-unit id="156" xml:space="preserve">
            <source>Audio overlays can be combined with video overlays as shown in the following preset snippet:</source>
            <target state="new">Audio overlays can be combined with video overlays as shown in the following preset snippet:</target>
          </trans-unit>
          <trans-unit id="157" xml:space="preserve">
            <source>Submitting Tasks with Overlays</source>
            <target state="new">Submitting Tasks with Overlays</target>
          </trans-unit>
          <trans-unit id="158" xml:space="preserve">
            <source>Once you have created a preset file you must do the following:</source>
            <target state="new">Once you have created a preset file you must do the following:</target>
          </trans-unit>
          <trans-unit id="159" xml:space="preserve">
            <source>Upload your asset(s)</source>
            <target state="new">Upload your asset(s)</target>
          </trans-unit>
          <trans-unit id="160" xml:space="preserve">
            <source>Load the preset configuration (Note: the code below assumes the Preset above.</source>
            <target state="new">Load the preset configuration (Note: the code below assumes the Preset above.</target>
          </trans-unit>
          <trans-unit id="161" xml:space="preserve">
            <source>Create a job</source>
            <target state="new">Create a job</target>
          </trans-unit>
          <trans-unit id="162" xml:space="preserve">
            <source>Get a reference to the Media Services Encoder</source>
            <target state="new">Get a reference to the Media Services Encoder</target>
          </trans-unit>
          <trans-unit id="163" xml:space="preserve">
            <source>Create a task specifying the collection of input assets, the preset configuration, the media encoder, and the output asset</source>
            <target state="new">Create a task specifying the collection of input assets, the preset configuration, the media encoder, and the output asset</target>
          </trans-unit>
          <trans-unit id="164" xml:space="preserve">
            <source>Submit the job</source>
            <target state="new">Submit the job</target>
          </trans-unit>
          <trans-unit id="165" xml:space="preserve">
            <source>The following code snippet shows how to do these steps:</source>
            <target state="new">The following code snippet shows how to do these steps:</target>
          </trans-unit>
          <trans-unit id="166" xml:space="preserve">
            <source>This snippet loads each asset sequentially for simplicity.</source>
            <target state="new">This snippet loads each asset sequentially for simplicity.</target>
          </trans-unit>
          <trans-unit id="167" xml:space="preserve">
            <source>In production environments assets would be loaded in bulk.</source>
            <target state="new">In production environments assets would be loaded in bulk.</target>
          </trans-unit>
          <trans-unit id="168" xml:space="preserve">
            <source>For more information on uploading multiple assets in bulk see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Ingesting Assets in Bulk with the Media Services SDK for .NET<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information on uploading multiple assets in bulk see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Ingesting Assets in Bulk with the Media Services SDK for .NET<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="169" xml:space="preserve">
            <source>For complete sample code see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Creating Overlays with Media Services Encoder<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For complete sample code see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Creating Overlays with Media Services Encoder<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="170" xml:space="preserve">
            <source>Error Conditions</source>
            <target state="new">Error Conditions</target>
          </trans-unit>
          <trans-unit id="171" xml:space="preserve">
            <source>When editing the Preset string, you must ensure the following:</source>
            <target state="new">When editing the Preset string, you must ensure the following:</target>
          </trans-unit>
          <trans-unit id="172" xml:space="preserve">
            <source>For video/image overlays, the overlay rectangle must fit entirely within the dimensions of the source video</source>
            <target state="new">For video/image overlays, the overlay rectangle must fit entirely within the dimensions of the source video</target>
          </trans-unit>
          <trans-unit id="173" xml:space="preserve">
            <source>The start and end time of the overlays should be within the timeline of the source video</source>
            <target state="new">The start and end time of the overlays should be within the timeline of the source video</target>
          </trans-unit>
          <trans-unit id="174" xml:space="preserve">
            <source>If the preset XML contains a reference to ?OverlayFileName=”%n%”, then the InputAssets collection for the Tasks should contain at least n+1 Assets</source>
            <target state="new">If the preset XML contains a reference to ?OverlayFileName=”%n%”, then the InputAssets collection for the Tasks should contain at least n+1 Assets</target>
          </trans-unit>
          <trans-unit id="175" xml:space="preserve">
            <source>Stitching Video Segments</source>
            <target state="new">Stitching Video Segments</target>
          </trans-unit>
          <trans-unit id="176" xml:space="preserve">
            <source>The media services encoder provides support for stitching together a set of videos.</source>
            <target state="new">The media services encoder provides support for stitching together a set of videos.</target>
          </trans-unit>
          <trans-unit id="177" xml:space="preserve">
            <source>Videos can be stitched together end-to-end or you can specify portions of one or both videos to be stitched together.</source>
            <target state="new">Videos can be stitched together end-to-end or you can specify portions of one or both videos to be stitched together.</target>
          </trans-unit>
          <trans-unit id="178" xml:space="preserve">
            <source>The result of the stitching is a single output asset that contains the specified video from the input assets.</source>
            <target state="new">The result of the stitching is a single output asset that contains the specified video from the input assets.</target>
          </trans-unit>
          <trans-unit id="179" xml:space="preserve">
            <source>The videos to be stitched can be contained in multiple assets or a single asset.</source>
            <target state="new">The videos to be stitched can be contained in multiple assets or a single asset.</target>
          </trans-unit>
          <trans-unit id="180" xml:space="preserve">
            <source>Stitching is controlled by the preset XML passed to the encoder.</source>
            <target state="new">Stitching is controlled by the preset XML passed to the encoder.</target>
          </trans-unit>
          <trans-unit id="181" xml:space="preserve">
            <source>For a complete description of the preset schema, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Azure Media Encoder Schema<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For a complete description of the preset schema, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Azure Media Encoder Schema<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="182" xml:space="preserve">
            <source>Stitching with Media Services Encoder</source>
            <target state="new">Stitching with Media Services Encoder</target>
          </trans-unit>
          <trans-unit id="183" xml:space="preserve">
            <source>Stitching is controlled within the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element as shown in the following preset:</source>
            <target state="new">Stitching is controlled within the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element as shown in the following preset:</target>
          </trans-unit>
          <trans-unit id="184" xml:space="preserve">
            <source>For each video to be stitched, a <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element is added to the <bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept> element. Each <bpt id="6">&lt;html&gt;</bpt><ept id="6">&lt;/html&gt;</ept> element contains a <bpt id="8">&lt;html&gt;</bpt><ept id="8">&lt;/html&gt;</ept> element. Each <bpt id="10">&lt;html&gt;</bpt><ept id="10">&lt;/html&gt;</ept> element contains one or more <bpt id="12">&lt;html&gt;</bpt><ept id="12">&lt;/html&gt;</ept> element that specifies how much of the video will be stitched into the output asset, by specifying a start and end time. The <bpt id="14">&lt;html&gt;</bpt><ept id="14">&lt;/html&gt;</ept> element references the asset on which it acts. The format of the reference depends on whether the videos to be stitched are in separate assets or in a single asset. If you want to stitch an entire video, simply omit the <bpt id="16">&lt;html&gt;</bpt><ept id="16">&lt;/html&gt;</ept> element.</source>
            <target state="new">For each video to be stitched, a <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element is added to the <bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept> element. Each <bpt id="6">&lt;html&gt;</bpt><ept id="6">&lt;/html&gt;</ept> element contains a <bpt id="8">&lt;html&gt;</bpt><ept id="8">&lt;/html&gt;</ept> element. Each <bpt id="10">&lt;html&gt;</bpt><ept id="10">&lt;/html&gt;</ept> element contains one or more <bpt id="12">&lt;html&gt;</bpt><ept id="12">&lt;/html&gt;</ept> element that specifies how much of the video will be stitched into the output asset, by specifying a start and end time. The <bpt id="14">&lt;html&gt;</bpt><ept id="14">&lt;/html&gt;</ept> element references the asset on which it acts. The format of the reference depends on whether the videos to be stitched are in separate assets or in a single asset. If you want to stitch an entire video, simply omit the <bpt id="16">&lt;html&gt;</bpt><ept id="16">&lt;/html&gt;</ept> element.</target>
          </trans-unit>
          <trans-unit id="185" xml:space="preserve">
            <source>Stitching Videos from Multiple Assets</source>
            <target state="new">Stitching Videos from Multiple Assets</target>
          </trans-unit>
          <trans-unit id="186" xml:space="preserve">
            <source>When stitching videos from multiple assets, a zero-based index is used for the MediaFile attribute of the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element to identify which asset the <bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept> element corresponds to. The zero index is not specified, the <bpt id="6">&lt;html&gt;</bpt><ept id="6">&lt;/html&gt;</ept> element that does not specify a MediaFile attribute references the first input asset. All other <bpt id="8">&lt;html&gt;</bpt><ept id="8">&lt;/html&gt;</ept> elements must specify the zero-based index of the input asset to which it refers by using %n% syntax where n is the zero-based index of the input asset. In the preceding example the first <bpt id="10">&lt;html&gt;</bpt><ept id="10">&lt;/html&gt;</ept> element specifies the first input asset, the second <bpt id="12">&lt;html&gt;</bpt><ept id="12">&lt;/html&gt;</ept> element specifies the second input asset, and so on. There is no requirement that the input assets be referenced in order, for example:</source>
            <target state="new">When stitching videos from multiple assets, a zero-based index is used for the MediaFile attribute of the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element to identify which asset the <bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept> element corresponds to. The zero index is not specified, the <bpt id="6">&lt;html&gt;</bpt><ept id="6">&lt;/html&gt;</ept> element that does not specify a MediaFile attribute references the first input asset. All other <bpt id="8">&lt;html&gt;</bpt><ept id="8">&lt;/html&gt;</ept> elements must specify the zero-based index of the input asset to which it refers by using %n% syntax where n is the zero-based index of the input asset. In the preceding example the first <bpt id="10">&lt;html&gt;</bpt><ept id="10">&lt;/html&gt;</ept> element specifies the first input asset, the second <bpt id="12">&lt;html&gt;</bpt><ept id="12">&lt;/html&gt;</ept> element specifies the second input asset, and so on. There is no requirement that the input assets be referenced in order, for example:</target>
          </trans-unit>
          <trans-unit id="187" xml:space="preserve">
            <source>This example stitches together portions of the second, the first, and the third input assets.</source>
            <target state="new">This example stitches together portions of the second, the first, and the third input assets.</target>
          </trans-unit>
          <trans-unit id="188" xml:space="preserve">
            <source>Note that since each video is referenced by a zero-based index it is possible to stitch two videos together that have the same name.</source>
            <target state="new">Note that since each video is referenced by a zero-based index it is possible to stitch two videos together that have the same name.</target>
          </trans-unit>
          <trans-unit id="189" xml:space="preserve">
            <source>Once you have created a preset file you must do the following:</source>
            <target state="new">Once you have created a preset file you must do the following:</target>
          </trans-unit>
          <trans-unit id="190" xml:space="preserve">
            <source>Upload your assets</source>
            <target state="new">Upload your assets</target>
          </trans-unit>
          <trans-unit id="191" xml:space="preserve">
            <source>Load the preset configuration</source>
            <target state="new">Load the preset configuration</target>
          </trans-unit>
          <trans-unit id="192" xml:space="preserve">
            <source>Create a job</source>
            <target state="new">Create a job</target>
          </trans-unit>
          <trans-unit id="193" xml:space="preserve">
            <source>Get a reference to the Media Services Encoder</source>
            <target state="new">Get a reference to the Media Services Encoder</target>
          </trans-unit>
          <trans-unit id="194" xml:space="preserve">
            <source>Create a task specifying the input assets, the preset configuration, the media encoder, and the output asset</source>
            <target state="new">Create a task specifying the input assets, the preset configuration, the media encoder, and the output asset</target>
          </trans-unit>
          <trans-unit id="195" xml:space="preserve">
            <source>Submit the job</source>
            <target state="new">Submit the job</target>
          </trans-unit>
          <trans-unit id="196" xml:space="preserve">
            <source>The following code snippet shows how to do these steps:</source>
            <target state="new">The following code snippet shows how to do these steps:</target>
          </trans-unit>
          <trans-unit id="197" xml:space="preserve">
            <source>This snippet loads each asset sequentially for simplicity.</source>
            <target state="new">This snippet loads each asset sequentially for simplicity.</target>
          </trans-unit>
          <trans-unit id="198" xml:space="preserve">
            <source>In production environments assets would be loaded in bulk.</source>
            <target state="new">In production environments assets would be loaded in bulk.</target>
          </trans-unit>
          <trans-unit id="199" xml:space="preserve">
            <source>For more information on uploading multiple assets in bulk see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Ingesting Assets in Bulk with the Media Services SDK for .NET<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For more information on uploading multiple assets in bulk see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Ingesting Assets in Bulk with the Media Services SDK for .NET<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="200" xml:space="preserve">
            <source>For complete sample code see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Stitching with Media Services Encoder<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">For complete sample code see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Stitching with Media Services Encoder<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="201" xml:space="preserve">
            <source>Stitching Videos from a Single Asset</source>
            <target state="new">Stitching Videos from a Single Asset</target>
          </trans-unit>
          <trans-unit id="202" xml:space="preserve">
            <source>When stitching videos within a single asset, each video must have a unique name.</source>
            <target state="new">When stitching videos within a single asset, each video must have a unique name.</target>
          </trans-unit>
          <trans-unit id="203" xml:space="preserve">
            <source>The videos are specified using the MediaFile attribute using the filename as the attribute’s value.</source>
            <target state="new">The videos are specified using the MediaFile attribute using the filename as the attribute’s value.</target>
          </trans-unit>
          <trans-unit id="204" xml:space="preserve">
            <source>For example:</source>
            <target state="new">For example:</target>
          </trans-unit>
          <trans-unit id="205" xml:space="preserve">
            <source>This preset stitches parts of video1.mp4, video2.wmv, and video3.wmv into the output asset.</source>
            <target state="new">This preset stitches parts of video1.mp4, video2.wmv, and video3.wmv into the output asset.</target>
          </trans-unit>
          <trans-unit id="206" xml:space="preserve">
            <source>The creation of the job and tasks is the same as stitching videos from multiple assets, you only need to upload a single asset as shown in the following code:</source>
            <target state="new">The creation of the job and tasks is the same as stitching videos from multiple assets, you only need to upload a single asset as shown in the following code:</target>
          </trans-unit>
          <trans-unit id="207" xml:space="preserve">
            <source>Encoding Presentations or Audio Streams With Mostly Speech</source>
            <target state="new">Encoding Presentations or Audio Streams With Mostly Speech</target>
          </trans-unit>
          <trans-unit id="208" xml:space="preserve">
            <source>When encoding video whose audio track contains mostly speech, the default encoder presets may cause background noise to be amplified in the encoded asset.</source>
            <target state="new">When encoding video whose audio track contains mostly speech, the default encoder presets may cause background noise to be amplified in the encoded asset.</target>
          </trans-unit>
          <trans-unit id="209" xml:space="preserve">
            <source>This behavior is caused by the NormalizeAudio attribute being set to true.</source>
            <target state="new">This behavior is caused by the NormalizeAudio attribute being set to true.</target>
          </trans-unit>
          <trans-unit id="210" xml:space="preserve">
            <source>Encoding Presentations with Mostly Speech</source>
            <target state="new">Encoding Presentations with Mostly Speech</target>
          </trans-unit>
          <trans-unit id="211" xml:space="preserve">
            <source>To prevent the amplification of background noise, do the following:</source>
            <target state="new">To prevent the amplification of background noise, do the following:</target>
          </trans-unit>
          <trans-unit id="212" xml:space="preserve">
            <source>Copy the contents of the encoder preset you are using into an XML file.</source>
            <target state="new">Copy the contents of the encoder preset you are using into an XML file.</target>
          </trans-unit>
          <trans-unit id="213" xml:space="preserve">
            <source>The encoder presets can be found at: Azure Media Encoder Schemas</source>
            <target state="new">The encoder presets can be found at: Azure Media Encoder Schemas</target>
          </trans-unit>
          <trans-unit id="214" xml:space="preserve">
            <source>Delete the NormalizeAudio attribute, it can be found near the top of the preset file under the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element:</source>
            <target state="new">Delete the NormalizeAudio attribute, it can be found near the top of the preset file under the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> element:</target>
          </trans-unit>
          <trans-unit id="215" xml:space="preserve">
            <source>&lt;MediaFile</source>
            <target state="new">&lt;MediaFile</target>
          </trans-unit>
          <trans-unit id="216" xml:space="preserve">
            <source>DeinterlaceMode="AutoPixelAdaptive"</source>
            <target state="new">DeinterlaceMode="AutoPixelAdaptive"</target>
          </trans-unit>
          <trans-unit id="217" xml:space="preserve">
            <source>ResizeQuality="Super"</source>
            <target state="new">ResizeQuality="Super"</target>
          </trans-unit>
          <trans-unit id="218" xml:space="preserve">
            <source>NormalizeAudio="True"</source>
            <target state="new">NormalizeAudio="True"</target>
          </trans-unit>
          <trans-unit id="219" xml:space="preserve">
            <source>AudioGainLevel="1"</source>
            <target state="new">AudioGainLevel="1"</target>
          </trans-unit>
          <trans-unit id="220" xml:space="preserve">
            <source>VideoResizeMode="Stretch"&gt;</source>
            <target state="new">VideoResizeMode="Stretch"&gt;</target>
          </trans-unit>
          <trans-unit id="221" xml:space="preserve">
            <source>Save the modified preset file to your local hard drive, and use code such as the following to encode with the custom preset:</source>
            <target state="new">Save the modified preset file to your local hard drive, and use code such as the following to encode with the custom preset:</target>
          </trans-unit>
          <trans-unit id="222" xml:space="preserve">
            <source>See Also</source>
            <target state="new">See Also</target>
          </trans-unit>
          <trans-unit id="223" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Azure Media Encoder XML Schema<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Azure Media Encoder XML Schema<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
        </group>
      </group>
    </body>
  </file>
</xliff>