<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="ru-ru" original="2/20/2016 4:58:40 PM" tool-id="MarkdownTransformer" product-name="N/A" product-version="N/A" build-num="1">
    <header>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">34e8abcff8ea5c30355a894d63ac04115a499d12</xliffext:olfilehash>
      <tool tool-id="MarkdownTransformer" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group extype="content">
        <group id="101">
          <trans-unit id="101" xml:space="preserve">
            <source>Comparison: Apache Storm vs. Azure Stream Analytics | Microsoft Azure</source>
            <target state="new">Comparison: Apache Storm vs. Azure Stream Analytics | Microsoft Azure</target>
          </trans-unit>
          <trans-unit id="102" xml:space="preserve">
            <source>Learn how to use Stream Analytics for real-time Twitter sentiment analysis. Step-by-step guidance from event generation to data on a live dashboard.</source>
            <target state="new">Learn how to use Stream Analytics for real-time Twitter sentiment analysis. Step-by-step guidance from event generation to data on a live dashboard.</target>
          </trans-unit>
          <trans-unit id="103" xml:space="preserve">
            <source>Comparison of Apache Storm and Azure Stream Analytics</source>
            <target state="new">Comparison of Apache Storm and Azure Stream Analytics</target>
          </trans-unit>
          <trans-unit id="104" xml:space="preserve">
            <source>Introduction</source>
            <target state="new">Introduction</target>
          </trans-unit>
          <trans-unit id="105" xml:space="preserve">
            <source>This document illustrates the positioning of Azure Stream Analytics and Apache Storm as a managed service on HDInsight.</source>
            <target state="new">This document illustrates the positioning of Azure Stream Analytics and Apache Storm as a managed service on HDInsight.</target>
          </trans-unit>
          <trans-unit id="106" xml:space="preserve">
            <source>The goal is to help customers understand the value proposition of both services, and make a decision on which is the right choice for their business use case.</source>
            <target state="new">The goal is to help customers understand the value proposition of both services, and make a decision on which is the right choice for their business use case.</target>
          </trans-unit>
          <trans-unit id="107" xml:space="preserve">
            <source>While both provide benefits of a PaaS solution, there are a few major distinguishing capabilities that differentiate these services.</source>
            <target state="new">While both provide benefits of a PaaS solution, there are a few major distinguishing capabilities that differentiate these services.</target>
          </trans-unit>
          <trans-unit id="108" xml:space="preserve">
            <source>We believe that listing out the capabilities, as well as the limitations, of these services will help customers land on the solution they need to achieve their goals.</source>
            <target state="new">We believe that listing out the capabilities, as well as the limitations, of these services will help customers land on the solution they need to achieve their goals.</target>
          </trans-unit>
          <trans-unit id="109" xml:space="preserve">
            <source>General</source>
            <target state="new">General</target>
          </trans-unit>
          <trans-unit id="110" xml:space="preserve">
            <source>Azure Stream Analytics</source>
            <target state="new">Azure Stream Analytics</target>
          </trans-unit>
          <trans-unit id="111" xml:space="preserve">
            <source>Apache Storm on HDInsight</source>
            <target state="new">Apache Storm on HDInsight</target>
          </trans-unit>
          <trans-unit id="112" xml:space="preserve">
            <source>Open Source</source>
            <target state="new">Open Source</target>
          </trans-unit>
          <trans-unit id="113" xml:space="preserve">
            <source>
                    No, Azure Stream Analytics is a Microsoft proprietary offering.
                </source>
            <target state="new">
                    No, Azure Stream Analytics is a Microsoft proprietary offering.
                </target>
          </trans-unit>
          <trans-unit id="114" xml:space="preserve">
            <source>
                    Yes, Apache Storm is an Apache licensed technology.
                </source>
            <target state="new">
                    Yes, Apache Storm is an Apache licensed technology.
                </target>
          </trans-unit>
          <trans-unit id="115" xml:space="preserve">
            <source>Microsoft Supported</source>
            <target state="new">Microsoft Supported</target>
          </trans-unit>
          <trans-unit id="116" xml:space="preserve">
            <source>
                    Yes
                </source>
            <target state="new">
                    Yes
                </target>
          </trans-unit>
          <trans-unit id="117" xml:space="preserve">
            <source>
                    Yes
                </source>
            <target state="new">
                    Yes
                </target>
          </trans-unit>
          <trans-unit id="118" xml:space="preserve">
            <source>Hardware requirements</source>
            <target state="new">Hardware requirements</target>
          </trans-unit>
          <trans-unit id="119" xml:space="preserve">
            <source>
                    There are no hardware requirements. Azure Stream Analytics is an Azure Service.
                </source>
            <target state="new">
                    There are no hardware requirements. Azure Stream Analytics is an Azure Service.
                </target>
          </trans-unit>
          <trans-unit id="120" xml:space="preserve">
            <source>
                    There are no hardware requirements. Apache Storm is an Azure Service.
                </source>
            <target state="new">
                    There are no hardware requirements. Apache Storm is an Azure Service.
                </target>
          </trans-unit>
          <trans-unit id="121" xml:space="preserve">
            <source>Top Level Unit</source>
            <target state="new">Top Level Unit</target>
          </trans-unit>
          <trans-unit id="122" xml:space="preserve">
            <source>
                    With Azure Stream Analytics customers deploy and monitor streaming jobs.
                </source>
            <target state="new">
                    With Azure Stream Analytics customers deploy and monitor streaming jobs.
                </target>
          </trans-unit>
          <trans-unit id="123" xml:space="preserve">
            <source>
                    With Apache Storm on HDInsight customers deploy and monitor a whole cluster, which can host multiple Storm jobs as well as other  workloads (incl. batch).
                </source>
            <target state="new">
                    With Apache Storm on HDInsight customers deploy and monitor a whole cluster, which can host multiple Storm jobs as well as other  workloads (incl. batch).
                </target>
          </trans-unit>
          <trans-unit id="124" xml:space="preserve">
            <source>Price</source>
            <target state="new">Price</target>
          </trans-unit>
          <trans-unit id="125" xml:space="preserve">
            <source>
                    Stream Analytics is priced by volume of data processed and the number of streaming units (per hour the job is running) required.
                </source>
            <target state="new">
                    Stream Analytics is priced by volume of data processed and the number of streaming units (per hour the job is running) required.
                </target>
          </trans-unit>
          <trans-unit id="126" xml:space="preserve">
            <source>Further pricing information can be found here.</source>
            <target state="new">Further pricing information can be found here.</target>
          </trans-unit>
          <trans-unit id="127" xml:space="preserve">
            <source>
                    For Apache Storm on HDInsight, the unit of purchase is cluster-based, and is charged based on the time the cluster is running, independent of jobs deployed.
                </source>
            <target state="new">
                    For Apache Storm on HDInsight, the unit of purchase is cluster-based, and is charged based on the time the cluster is running, independent of jobs deployed.
                </target>
          </trans-unit>
          <trans-unit id="128" xml:space="preserve">
            <source>Further pricing information can be found here.</source>
            <target state="new">Further pricing information can be found here.</target>
          </trans-unit>
          <trans-unit id="129" xml:space="preserve">
            <source>Authoring</source>
            <target state="new">Authoring</target>
          </trans-unit>
          <trans-unit id="130" xml:space="preserve">
            <source>Azure Stream Analytics</source>
            <target state="new">Azure Stream Analytics</target>
          </trans-unit>
          <trans-unit id="131" xml:space="preserve">
            <source>Apache Storm on HDInsight</source>
            <target state="new">Apache Storm on HDInsight</target>
          </trans-unit>
          <trans-unit id="132" xml:space="preserve">
            <source>Capabilities: SQL DSL</source>
            <target state="new">Capabilities: SQL DSL</target>
          </trans-unit>
          <trans-unit id="133" xml:space="preserve">
            <source>
                    Yes, an easy to use SQL language support is available.
                </source>
            <target state="new">
                    Yes, an easy to use SQL language support is available.
                </target>
          </trans-unit>
          <trans-unit id="134" xml:space="preserve">
            <source>
                    No, users must write code in Java C# or use Trident APIs.
                </source>
            <target state="new">
                    No, users must write code in Java C# or use Trident APIs.
                </target>
          </trans-unit>
          <trans-unit id="135" xml:space="preserve">
            <source>Capabilities: Temporal operators</source>
            <target state="new">Capabilities: Temporal operators</target>
          </trans-unit>
          <trans-unit id="136" xml:space="preserve">
            <source>
                    Windowed aggregates, and temporal joins are supported out of the box.
                </source>
            <target state="new">
                    Windowed aggregates, and temporal joins are supported out of the box.
                </target>
          </trans-unit>
          <trans-unit id="137" xml:space="preserve">
            <source>
                    Temporal operators must to be implemented by the user.
                </source>
            <target state="new">
                    Temporal operators must to be implemented by the user.
                </target>
          </trans-unit>
          <trans-unit id="138" xml:space="preserve">
            <source>Development Experience</source>
            <target state="new">Development Experience</target>
          </trans-unit>
          <trans-unit id="139" xml:space="preserve">
            <source>
                    Interactive authoring and debugging experience through Azure Portal on sample data.
                </source>
            <target state="new">
                    Interactive authoring and debugging experience through Azure Portal on sample data.
                </target>
          </trans-unit>
          <trans-unit id="140" xml:space="preserve">
            <source>
                    Development, debugging and monitoring experience is provided through the Visual Studio experience for .NET users, while for Java and other languages developers may use the IDE of their choice.
                </source>
            <target state="new">
                    Development, debugging and monitoring experience is provided through the Visual Studio experience for .NET users, while for Java and other languages developers may use the IDE of their choice.
                </target>
          </trans-unit>
          <trans-unit id="141" xml:space="preserve">
            <source>Debugging support</source>
            <target state="new">Debugging support</target>
          </trans-unit>
          <trans-unit id="142" xml:space="preserve">
            <source>
                    Stream Analytics offers basic job status and Operations logs as a way of debugging, but currently does not offer flexibility in what/how much is included in the logs ie: verbose mode.
                </source>
            <target state="new">
                    Stream Analytics offers basic job status and Operations logs as a way of debugging, but currently does not offer flexibility in what/how much is included in the logs ie: verbose mode.
                </target>
          </trans-unit>
          <trans-unit id="143" xml:space="preserve">
            <source>
                    Detailed logs are available for debugging purposes. There are two ways to surface logs to user, via visual Studio or user can RDP into the cluster to access logs.
                </source>
            <target state="new">
                    Detailed logs are available for debugging purposes. There are two ways to surface logs to user, via visual Studio or user can RDP into the cluster to access logs.
                </target>
          </trans-unit>
          <trans-unit id="144" xml:space="preserve">
            <source>Support for UDF (User Defined Functions)</source>
            <target state="new">Support for UDF (User Defined Functions)</target>
          </trans-unit>
          <trans-unit id="145" xml:space="preserve">
            <source>
                    Currently there is no support for UDFs.
                </source>
            <target state="new">
                    Currently there is no support for UDFs.
                </target>
          </trans-unit>
          <trans-unit id="146" xml:space="preserve">
            <source>
                    UDFs can be written in C#, Java or the language of your choice.
                </source>
            <target state="new">
                    UDFs can be written in C#, Java or the language of your choice.
                </target>
          </trans-unit>
          <trans-unit id="147" xml:space="preserve">
            <source>Extensible - custom code </source>
            <target state="new">Extensible - custom code </target>
          </trans-unit>
          <trans-unit id="148" xml:space="preserve">
            <source>
                    There is no support for extensible code in Stream Analytics.
                </source>
            <target state="new">
                    There is no support for extensible code in Stream Analytics.
                </target>
          </trans-unit>
          <trans-unit id="149" xml:space="preserve">
            <source>
                    Yes, there is availability to write custom code in C#, Java or other supported languages on Storm.
                </source>
            <target state="new">
                    Yes, there is availability to write custom code in C#, Java or other supported languages on Storm.
                </target>
          </trans-unit>
          <trans-unit id="150" xml:space="preserve">
            <source>Input and Output</source>
            <target state="new">Input and Output</target>
          </trans-unit>
          <trans-unit id="151" xml:space="preserve">
            <source>Azure Stream Analytics</source>
            <target state="new">Azure Stream Analytics</target>
          </trans-unit>
          <trans-unit id="152" xml:space="preserve">
            <source>Apache Storm on HDInsight</source>
            <target state="new">Apache Storm on HDInsight</target>
          </trans-unit>
          <trans-unit id="153" xml:space="preserve">
            <source>Input Data Sources</source>
            <target state="new">Input Data Sources</target>
          </trans-unit>
          <trans-unit id="154" xml:space="preserve">
            <source>The supported input sources are Azure Event Hubs and Azure Blobs.
                </source>
            <target state="new">The supported input sources are Azure Event Hubs and Azure Blobs.
                </target>
          </trans-unit>
          <trans-unit id="155" xml:space="preserve">
            <source>
                    There are connectors available for Event Hubs, Service Bus, Kafka, etc. Unsupported connectors may be implemented via custom code.
                </source>
            <target state="new">
                    There are connectors available for Event Hubs, Service Bus, Kafka, etc. Unsupported connectors may be implemented via custom code.
                </target>
          </trans-unit>
          <trans-unit id="156" xml:space="preserve">
            <source>Input Data formats</source>
            <target state="new">Input Data formats</target>
          </trans-unit>
          <trans-unit id="157" xml:space="preserve">
            <source>
                    Supported input formats are Avro, JSON, CSV.
                </source>
            <target state="new">
                    Supported input formats are Avro, JSON, CSV.
                </target>
          </trans-unit>
          <trans-unit id="158" xml:space="preserve">
            <source>
                    Any format may be implemented via custom code.
                </source>
            <target state="new">
                    Any format may be implemented via custom code.
                </target>
          </trans-unit>
          <trans-unit id="159" xml:space="preserve">
            <source>Outputs</source>
            <target state="new">Outputs</target>
          </trans-unit>
          <trans-unit id="160" xml:space="preserve">
            <source>
                    A streaming job may have multiple outputs. Supported Outputs: Azure Event Hubs, Azure Blob Storage, Azure Tables, Azure SQL DB, and PowerBI.
                </source>
            <target state="new">
                    A streaming job may have multiple outputs. Supported Outputs: Azure Event Hubs, Azure Blob Storage, Azure Tables, Azure SQL DB, and PowerBI.
                </target>
          </trans-unit>
          <trans-unit id="161" xml:space="preserve">
            <source>
                    Support for many outputs in a topology, each output may have custom logic for downstream processing. Out of the box Storm includes connectors for PowerBI, Azure Event Hubs, Azure Blob Store, Azure DocumentDB, SQL and HBase. Unsupported connectors may be implemented via custom code.
                </source>
            <target state="new">
                    Support for many outputs in a topology, each output may have custom logic for downstream processing. Out of the box Storm includes connectors for PowerBI, Azure Event Hubs, Azure Blob Store, Azure DocumentDB, SQL and HBase. Unsupported connectors may be implemented via custom code.
                </target>
          </trans-unit>
          <trans-unit id="162" xml:space="preserve">
            <source>Data Encoding formats</source>
            <target state="new">Data Encoding formats</target>
          </trans-unit>
          <trans-unit id="163" xml:space="preserve">
            <source>
                    Stream Analytics requires UTF-8 data format to be utilized.
                </source>
            <target state="new">
                    Stream Analytics requires UTF-8 data format to be utilized.
                </target>
          </trans-unit>
          <trans-unit id="164" xml:space="preserve">
            <source>
                    Any data encoding format may be implemented via custom code.
                </source>
            <target state="new">
                    Any data encoding format may be implemented via custom code.
                </target>
          </trans-unit>
          <trans-unit id="165" xml:space="preserve">
            <source>Management and operations</source>
            <target state="new">Management and operations</target>
          </trans-unit>
          <trans-unit id="166" xml:space="preserve">
            <source>Azure Stream Analytics</source>
            <target state="new">Azure Stream Analytics</target>
          </trans-unit>
          <trans-unit id="167" xml:space="preserve">
            <source>Apache Storm on HDInsight</source>
            <target state="new">Apache Storm on HDInsight</target>
          </trans-unit>
          <trans-unit id="168" xml:space="preserve">
            <source>Job Deployment model</source>
            <target state="new">Job Deployment model</target>
          </trans-unit>
          <trans-unit id="169" xml:space="preserve">
            <source>
                    - </source>
            <target state="new">
                    - </target>
          </trans-unit>
          <trans-unit id="170" xml:space="preserve">
            <source>Azure Portal</source>
            <target state="new">Azure Portal</target>
          </trans-unit>
          <trans-unit id="171" xml:space="preserve">
            <source>
                    - </source>
            <target state="new">
                    - </target>
          </trans-unit>
          <trans-unit id="172" xml:space="preserve">
            <source>Visual Studio</source>
            <target state="new">Visual Studio</target>
          </trans-unit>
          <trans-unit id="173" xml:space="preserve">
            <source>
                    - </source>
            <target state="new">
                    - </target>
          </trans-unit>
          <trans-unit id="174" xml:space="preserve">
            <source>PowerShell</source>
            <target state="new">PowerShell</target>
          </trans-unit>
          <trans-unit id="175" xml:space="preserve">
            <source>
                    Deployment is implemented via Azure Portal, PowerShell and REST APIs.
                </source>
            <target state="new">
                    Deployment is implemented via Azure Portal, PowerShell and REST APIs.
                </target>
          </trans-unit>
          <trans-unit id="176" xml:space="preserve">
            <source>
                    Depolyment is implemented via Azure Portal, PowerShell, Visual Studio and REST APIs.
                </source>
            <target state="new">
                    Depolyment is implemented via Azure Portal, PowerShell, Visual Studio and REST APIs.
                </target>
          </trans-unit>
          <trans-unit id="177" xml:space="preserve">
            <source>Monitoring (stats, counters, etc.)</source>
            <target state="new">Monitoring (stats, counters, etc.)</target>
          </trans-unit>
          <trans-unit id="178" xml:space="preserve">
            <source>
                    Monitoring is implemented via Azure Portal and REST APIs.
                </source>
            <target state="new">
                    Monitoring is implemented via Azure Portal and REST APIs.
                </target>
          </trans-unit>
          <trans-unit id="179" xml:space="preserve">
            <source>
                    The user may also configure Azure alerts.
                </source>
            <target state="new">
                    The user may also configure Azure alerts.
                </target>
          </trans-unit>
          <trans-unit id="180" xml:space="preserve">
            <source>
                    Monitoring is implemented via Storm UI and REST APIs.
                </source>
            <target state="new">
                    Monitoring is implemented via Storm UI and REST APIs.
                </target>
          </trans-unit>
          <trans-unit id="181" xml:space="preserve">
            <source>Scalability</source>
            <target state="new">Scalability</target>
          </trans-unit>
          <trans-unit id="182" xml:space="preserve">
            <source>
                    Number of Streaming Units for each job. Each Streaming Unit processes up to 1MB/s. Max of 50 units by default. Call to increase limit.
                </source>
            <target state="new">
                    Number of Streaming Units for each job. Each Streaming Unit processes up to 1MB/s. Max of 50 units by default. Call to increase limit.
                </target>
          </trans-unit>
          <trans-unit id="183" xml:space="preserve">
            <source>
                    Number of nodes in the HDI Storm cluster. No limit on number of nodes (Top limit defined by your Azure quota). Call to increase limit.
                </source>
            <target state="new">
                    Number of nodes in the HDI Storm cluster. No limit on number of nodes (Top limit defined by your Azure quota). Call to increase limit.
                </target>
          </trans-unit>
          <trans-unit id="184" xml:space="preserve">
            <source>Data processing limits</source>
            <target state="new">Data processing limits</target>
          </trans-unit>
          <trans-unit id="185" xml:space="preserve">
            <source>
                    Users can scale up or down number of Streaming Units to increase data processing or optimize costs.
                </source>
            <target state="new">
                    Users can scale up or down number of Streaming Units to increase data processing or optimize costs.
                </target>
          </trans-unit>
          <trans-unit id="186" xml:space="preserve">
            <source>
                    Scale up to 1 GB/s
                </source>
            <target state="new">
                    Scale up to 1 GB/s
                </target>
          </trans-unit>
          <trans-unit id="187" xml:space="preserve">
            <source>
                    User can scale up or down cluster size to meet needs.
                </source>
            <target state="new">
                    User can scale up or down cluster size to meet needs.
                </target>
          </trans-unit>
          <trans-unit id="188" xml:space="preserve">
            <source>Stop/Resume</source>
            <target state="new">Stop/Resume</target>
          </trans-unit>
          <trans-unit id="189" xml:space="preserve">
            <source>
                    Stop and resume from last place stopped.
                </source>
            <target state="new">
                    Stop and resume from last place stopped.
                </target>
          </trans-unit>
          <trans-unit id="190" xml:space="preserve">
            <source>
                    Stop and resume from last place stopped based on the watermark.
                </source>
            <target state="new">
                    Stop and resume from last place stopped based on the watermark.
                </target>
          </trans-unit>
          <trans-unit id="191" xml:space="preserve">
            <source>Service and framework update</source>
            <target state="new">Service and framework update</target>
          </trans-unit>
          <trans-unit id="192" xml:space="preserve">
            <source>
                    Automatic patching with no downtime.
                </source>
            <target state="new">
                    Automatic patching with no downtime.
                </target>
          </trans-unit>
          <trans-unit id="193" xml:space="preserve">
            <source>
                    Automatic patching with no downtime.
                </source>
            <target state="new">
                    Automatic patching with no downtime.
                </target>
          </trans-unit>
          <trans-unit id="194" xml:space="preserve">
            <source>Business continuity through a Highly Available Service with guaranteed SLA’s</source>
            <target state="new">Business continuity through a Highly Available Service with guaranteed SLA’s</target>
          </trans-unit>
          <trans-unit id="195" xml:space="preserve">
            <source>
                    SLA of 99.9% uptime
                </source>
            <target state="new">
                    SLA of 99.9% uptime
                </target>
          </trans-unit>
          <trans-unit id="196" xml:space="preserve">
            <source>
                    Auto-recovery from failures
                </source>
            <target state="new">
                    Auto-recovery from failures
                </target>
          </trans-unit>
          <trans-unit id="197" xml:space="preserve">
            <source>
                    Recovery of stateful temporal operators is built-in.
                </source>
            <target state="new">
                    Recovery of stateful temporal operators is built-in.
                </target>
          </trans-unit>
          <trans-unit id="198" xml:space="preserve">
            <source>
                    SLA of 99.9% uptime of the Storm cluster. Apache Storm is a fault tolerant streaming platform however it is the customers' responsibility to ensure their streaming jobs run uninterrupted.
                </source>
            <target state="new">
                    SLA of 99.9% uptime of the Storm cluster. Apache Storm is a fault tolerant streaming platform however it is the customers' responsibility to ensure their streaming jobs run uninterrupted.
                </target>
          </trans-unit>
          <trans-unit id="199" xml:space="preserve">
            <source>Advanced Features</source>
            <target state="new">Advanced Features</target>
          </trans-unit>
          <trans-unit id="200" xml:space="preserve">
            <source>Azure Stream Analytics</source>
            <target state="new">Azure Stream Analytics</target>
          </trans-unit>
          <trans-unit id="201" xml:space="preserve">
            <source>Apache Storm on HDInsight</source>
            <target state="new">Apache Storm on HDInsight</target>
          </trans-unit>
          <trans-unit id="202" xml:space="preserve">
            <source>Late arrival and out of order event handling</source>
            <target state="new">Late arrival and out of order event handling</target>
          </trans-unit>
          <trans-unit id="203" xml:space="preserve">
            <source>
                    Built-in configurable policies to reorder, drop events or adjust event time.
                </source>
            <target state="new">
                    Built-in configurable policies to reorder, drop events or adjust event time.
                </target>
          </trans-unit>
          <trans-unit id="204" xml:space="preserve">
            <source>
                    User must implement logic to handle this scenario.
                </source>
            <target state="new">
                    User must implement logic to handle this scenario.
                </target>
          </trans-unit>
          <trans-unit id="205" xml:space="preserve">
            <source>Reference data</source>
            <target state="new">Reference data</target>
          </trans-unit>
          <trans-unit id="206" xml:space="preserve">
            <source>
                    Reference data available from Azure Blobs with max size of 100 MB of in-memory lookup cache. Refreshing of reference data is managed by the service.
                </source>
            <target state="new">
                    Reference data available from Azure Blobs with max size of 100 MB of in-memory lookup cache. Refreshing of reference data is managed by the service.
                </target>
          </trans-unit>
          <trans-unit id="207" xml:space="preserve">
            <source>
                    No limits on data size. Connectors available for HBase, DocumentDB, SQL Server and Azure. Unsupported connectors may be implemented via custom code. 
                </source>
            <target state="new">
                    No limits on data size. Connectors available for HBase, DocumentDB, SQL Server and Azure. Unsupported connectors may be implemented via custom code. 
                </target>
          </trans-unit>
          <trans-unit id="208" xml:space="preserve">
            <source>
                    Refreshing of reference data must be handled by custom code.
                </source>
            <target state="new">
                    Refreshing of reference data must be handled by custom code.
                </target>
          </trans-unit>
          <trans-unit id="209" xml:space="preserve">
            <source>Integration with Machine Learning</source>
            <target state="new">Integration with Machine Learning</target>
          </trans-unit>
          <trans-unit id="210" xml:space="preserve">
            <source>
                    Yes, by configuring published Azure Machine Learning models as functions during ASA job creation.
                </source>
            <target state="new">
                    Yes, by configuring published Azure Machine Learning models as functions during ASA job creation.
                </target>
          </trans-unit>
          <trans-unit id="211" xml:space="preserve">
            <source>
                    Available through Storm Bolts.
                </source>
            <target state="new">
                    Available through Storm Bolts.
                </target>
          </trans-unit>
        </group>
      </group>
    </body>
  </file>
</xliff>