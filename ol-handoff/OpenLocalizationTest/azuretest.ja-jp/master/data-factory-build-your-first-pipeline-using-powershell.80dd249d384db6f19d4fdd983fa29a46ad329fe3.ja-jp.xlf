<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="ja-jp" original="2/20/2016 8:54:37 AM" tool-id="MarkdownTransformer" product-name="N/A" product-version="N/A" build-num="1">
    <header>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">eeecc34a9b923db910fa7ea0fc6bef015b4b6f7e</xliffext:olfilehash>
      <tool tool-id="MarkdownTransformer" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group extype="content">
        <group id="101">
          <trans-unit id="101" xml:space="preserve">
            <source>Build your first Azure Data Factory pipeline using Azure PowerShell</source>
            <target state="new">Build your first Azure Data Factory pipeline using Azure PowerShell</target>
          </trans-unit>
          <trans-unit id="102" xml:space="preserve">
            <source>In this tutorial, you will create a sample Azure Data Factory pipeline using Azure PowerShell.</source>
            <target state="new">In this tutorial, you will create a sample Azure Data Factory pipeline using Azure PowerShell.</target>
          </trans-unit>
          <trans-unit id="103" xml:space="preserve">
            <source>Build your first Azure Data Factory pipeline using Azure PowerShell</source>
            <target state="new">Build your first Azure Data Factory pipeline using Azure PowerShell</target>
          </trans-unit>
          <trans-unit id="104" xml:space="preserve">
            <source>In this article, you will learn how to use Azure PowerShell to create your first pipeline.</source>
            <target state="new">In this article, you will learn how to use Azure PowerShell to create your first pipeline.</target>
          </trans-unit>
          <trans-unit id="105" xml:space="preserve">
            <source>This tutorial consists of the following steps:</source>
            <target state="new">This tutorial consists of the following steps:</target>
          </trans-unit>
          <trans-unit id="106" xml:space="preserve">
            <source>Creating the data factory.</source>
            <target state="new">Creating the data factory.</target>
          </trans-unit>
          <trans-unit id="107" xml:space="preserve">
            <source>Creating the linked services (data stores, computes) and datasets.</source>
            <target state="new">Creating the linked services (data stores, computes) and datasets.</target>
          </trans-unit>
          <trans-unit id="108" xml:space="preserve">
            <source>Creating the pipeline.</source>
            <target state="new">Creating the pipeline.</target>
          </trans-unit>
          <trans-unit id="109" xml:space="preserve">
            <source>This article does not provide a conceptual overview of the Azure Data Factory service.</source>
            <target state="new">This article does not provide a conceptual overview of the Azure Data Factory service.</target>
          </trans-unit>
          <trans-unit id="110" xml:space="preserve">
            <source>For a detailed overview of the service, see the <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Introduction to Azure Data Factory<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> article.</source>
            <target state="new">For a detailed overview of the service, see the <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Introduction to Azure Data Factory<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> article.</target>
          </trans-unit>
          <trans-unit id="111" xml:space="preserve">
            <source>Step 1: Creating the data factory</source>
            <target state="new">Step 1: Creating the data factory</target>
          </trans-unit>
          <trans-unit id="112" xml:space="preserve">
            <source>In this step, you use Azure PowerShell to create an Azure Data Factory named ADFTutorialDataFactoryPSH.</source>
            <target state="new">In this step, you use Azure PowerShell to create an Azure Data Factory named ADFTutorialDataFactoryPSH.</target>
          </trans-unit>
          <trans-unit id="113" xml:space="preserve">
            <source>Start Azure PowerShell and run the following commands.</source>
            <target state="new">Start Azure PowerShell and run the following commands.</target>
          </trans-unit>
          <trans-unit id="114" xml:space="preserve">
            <source>Keep Azure PowerShell open until the end of this tutorial.</source>
            <target state="new">Keep Azure PowerShell open until the end of this tutorial.</target>
          </trans-unit>
          <trans-unit id="115" xml:space="preserve">
            <source>If you close and reopen, you need to run these commands again.</source>
            <target state="new">If you close and reopen, you need to run these commands again.</target>
          </trans-unit>
          <trans-unit id="116" xml:space="preserve">
            <source>Run <bpt id="2">&lt;strong&gt;</bpt>Add-AzureAccount<ept id="2">&lt;/strong&gt;</ept> and enter the  user name and password that you use to sign in to the Azure preview portal.</source>
            <target state="new">Run <bpt id="2">&lt;strong&gt;</bpt>Add-AzureAccount<ept id="2">&lt;/strong&gt;</ept> and enter the  user name and password that you use to sign in to the Azure preview portal.</target>
          </trans-unit>
          <trans-unit id="117" xml:space="preserve">
            <source>Run <bpt id="2">&lt;strong&gt;</bpt>Get-AzureSubscription<ept id="2">&lt;/strong&gt;</ept> to view all the subscriptions for this account.</source>
            <target state="new">Run <bpt id="2">&lt;strong&gt;</bpt>Get-AzureSubscription<ept id="2">&lt;/strong&gt;</ept> to view all the subscriptions for this account.</target>
          </trans-unit>
          <trans-unit id="118" xml:space="preserve">
            <source>Run <bpt id="2">&lt;strong&gt;</bpt>Select-AzureSubscription<ept id="2">&lt;/strong&gt;</ept> to select the subscription that you want to work with.</source>
            <target state="new">Run <bpt id="2">&lt;strong&gt;</bpt>Select-AzureSubscription<ept id="2">&lt;/strong&gt;</ept> to select the subscription that you want to work with.</target>
          </trans-unit>
          <trans-unit id="119" xml:space="preserve">
            <source>This subscription should be the same as the one you used in the preview portal.</source>
            <target state="new">This subscription should be the same as the one you used in the preview portal.</target>
          </trans-unit>
          <trans-unit id="120" xml:space="preserve">
            <source>Switch to AzureResourceManager mode as the Azure Data Factory cmdlets are available in this mode.</source>
            <target state="new">Switch to AzureResourceManager mode as the Azure Data Factory cmdlets are available in this mode.</target>
          </trans-unit>
          <trans-unit id="121" xml:space="preserve">
            <source>Create an Azure resource group named <bpt id="2">&lt;em&gt;</bpt>ADFTutorialResourceGroup<ept id="2">&lt;/em&gt;</ept> by running the following command.</source>
            <target state="new">Create an Azure resource group named <bpt id="2">&lt;em&gt;</bpt>ADFTutorialResourceGroup<ept id="2">&lt;/em&gt;</ept> by running the following command.</target>
          </trans-unit>
          <trans-unit id="122" xml:space="preserve">
            <source>Some of the steps in this tutorial assume that you use the resource group named ADFTutorialResourceGroup.</source>
            <target state="new">Some of the steps in this tutorial assume that you use the resource group named ADFTutorialResourceGroup.</target>
          </trans-unit>
          <trans-unit id="123" xml:space="preserve">
            <source>If you use a different resource group, you will need to use it in place of ADFTutorialResourceGroup in this tutorial.</source>
            <target state="new">If you use a different resource group, you will need to use it in place of ADFTutorialResourceGroup in this tutorial.</target>
          </trans-unit>
          <trans-unit id="124" xml:space="preserve">
            <source>Run the <bpt id="2">&lt;strong&gt;</bpt>New-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> cmdlet to create a data factory named DataFactoryMyFirstPipelinePSH.</source>
            <target state="new">Run the <bpt id="2">&lt;strong&gt;</bpt>New-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> cmdlet to create a data factory named DataFactoryMyFirstPipelinePSH.</target>
          </trans-unit>
          <trans-unit id="125" xml:space="preserve">
            <source>The name of the Azure Data Factory must be globally unique.</source>
            <target state="new">The name of the Azure Data Factory must be globally unique.</target>
          </trans-unit>
          <trans-unit id="126" xml:space="preserve">
            <source>If you receive the error <bpt id="2">&lt;strong&gt;</bpt>Data factory name “DataFactoryMyFirstPipelinePSH” is not available<ept id="2">&lt;/strong&gt;</ept>, change the name (for example, yournameADFTutorialDataFactoryPSH).</source>
            <target state="new">If you receive the error <bpt id="2">&lt;strong&gt;</bpt>Data factory name “DataFactoryMyFirstPipelinePSH” is not available<ept id="2">&lt;/strong&gt;</ept>, change the name (for example, yournameADFTutorialDataFactoryPSH).</target>
          </trans-unit>
          <trans-unit id="127" xml:space="preserve">
            <source>Use this name in place of ADFTutorialFactoryPSH while performing steps in this tutorial.</source>
            <target state="new">Use this name in place of ADFTutorialFactoryPSH while performing steps in this tutorial.</target>
          </trans-unit>
          <trans-unit id="128" xml:space="preserve">
            <source>In the subsequent steps, you will learn how to create the linked services, datasets and pipeline that you will use in this tutorial.</source>
            <target state="new">In the subsequent steps, you will learn how to create the linked services, datasets and pipeline that you will use in this tutorial.</target>
          </trans-unit>
          <trans-unit id="129" xml:space="preserve">
            <source>Step 2: Create linked services and datasets</source>
            <target state="new">Step 2: Create linked services and datasets</target>
          </trans-unit>
          <trans-unit id="130" xml:space="preserve">
            <source>In this step, you will link your Azure Storage account and an on-demand Azure HDInsight cluster to your data factory and then create a dataset to represent the output data from Hive processing.</source>
            <target state="new">In this step, you will link your Azure Storage account and an on-demand Azure HDInsight cluster to your data factory and then create a dataset to represent the output data from Hive processing.</target>
          </trans-unit>
          <trans-unit id="131" xml:space="preserve">
            <source>Create Azure Storage linked service</source>
            <target state="new">Create Azure Storage linked service</target>
          </trans-unit>
          <trans-unit id="132" xml:space="preserve">
            <source>Create a JSON file named StorageLinkedService.json in the C:\ADFGetStartedPSH folder with the following content.</source>
            <target state="new">Create a JSON file named StorageLinkedService.json in the C:\ADFGetStartedPSH folder with the following content.</target>
          </trans-unit>
          <trans-unit id="133" xml:space="preserve">
            <source>Create the folder ADFGetStartedPSH if it does not already exist.</source>
            <target state="new">Create the folder ADFGetStartedPSH if it does not already exist.</target>
          </trans-unit>
          <trans-unit id="134" xml:space="preserve">
            <source>Replace <bpt id="2">&lt;strong&gt;</bpt>account name<ept id="2">&lt;/strong&gt;</ept> with the name of your Azure storage account and <bpt id="4">&lt;strong&gt;</bpt>account key<ept id="4">&lt;/strong&gt;</ept> with the access key of the Azure storage account.</source>
            <target state="new">Replace <bpt id="2">&lt;strong&gt;</bpt>account name<ept id="2">&lt;/strong&gt;</ept> with the name of your Azure storage account and <bpt id="4">&lt;strong&gt;</bpt>account key<ept id="4">&lt;/strong&gt;</ept> with the access key of the Azure storage account.</target>
          </trans-unit>
          <trans-unit id="135" xml:space="preserve">
            <source>To learn how to get your storage access key, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>View, copy and regenerate storage access keys<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">To learn how to get your storage access key, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>View, copy and regenerate storage access keys<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="136" xml:space="preserve">
            <source>In Azure PowerShell, switch to the ADFGetStartedPSH folder.</source>
            <target state="new">In Azure PowerShell, switch to the ADFGetStartedPSH folder.</target>
          </trans-unit>
          <trans-unit id="137" xml:space="preserve">
            <source>You can use the <bpt id="2">&lt;strong&gt;</bpt>New-AzureDataFactoryLinkedService<ept id="2">&lt;/strong&gt;</ept> cmdlet to create a linked service.</source>
            <target state="new">You can use the <bpt id="2">&lt;strong&gt;</bpt>New-AzureDataFactoryLinkedService<ept id="2">&lt;/strong&gt;</ept> cmdlet to create a linked service.</target>
          </trans-unit>
          <trans-unit id="138" xml:space="preserve">
            <source>This cmdlet and other Data Factory cmdlets you use in this tutorial require you to pass values for the <bpt id="2">&lt;em&gt;</bpt>ResourceGroupName<ept id="2">&lt;/em&gt;</ept> and <bpt id="4">&lt;em&gt;</bpt>DataFactoryName<ept id="4">&lt;/em&gt;</ept> parameters.</source>
            <target state="new">This cmdlet and other Data Factory cmdlets you use in this tutorial require you to pass values for the <bpt id="2">&lt;em&gt;</bpt>ResourceGroupName<ept id="2">&lt;/em&gt;</ept> and <bpt id="4">&lt;em&gt;</bpt>DataFactoryName<ept id="4">&lt;/em&gt;</ept> parameters.</target>
          </trans-unit>
          <trans-unit id="139" xml:space="preserve">
            <source>Alternatively, you can use <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> to get a <bpt id="4">&lt;strong&gt;</bpt>DataFactory<ept id="4">&lt;/strong&gt;</ept> object and pass the object without typing <bpt id="6">&lt;em&gt;</bpt>ResourceGroupName<ept id="6">&lt;/em&gt;</ept> and <bpt id="8">&lt;em&gt;</bpt>DataFactoryName<ept id="8">&lt;/em&gt;</ept> each time you run a cmdlet.</source>
            <target state="new">Alternatively, you can use <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> to get a <bpt id="4">&lt;strong&gt;</bpt>DataFactory<ept id="4">&lt;/strong&gt;</ept> object and pass the object without typing <bpt id="6">&lt;em&gt;</bpt>ResourceGroupName<ept id="6">&lt;/em&gt;</ept> and <bpt id="8">&lt;em&gt;</bpt>DataFactoryName<ept id="8">&lt;/em&gt;</ept> each time you run a cmdlet.</target>
          </trans-unit>
          <trans-unit id="140" xml:space="preserve">
            <source>Run the following command to assign the output of the <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> cmdlet to a <bpt id="4">&lt;strong&gt;</bpt>$df<ept id="4">&lt;/strong&gt;</ept> variable.</source>
            <target state="new">Run the following command to assign the output of the <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> cmdlet to a <bpt id="4">&lt;strong&gt;</bpt>$df<ept id="4">&lt;/strong&gt;</ept> variable.</target>
          </trans-unit>
          <trans-unit id="141" xml:space="preserve">
            <source>Now, run the <bpt id="2">&lt;strong&gt;</bpt>New-AzureDataFactoryLinkedService<ept id="2">&lt;/strong&gt;</ept> cmdlet to create the linked <bpt id="4">&lt;strong&gt;</bpt>StorageLinkedService<ept id="4">&lt;/strong&gt;</ept> service.</source>
            <target state="new">Now, run the <bpt id="2">&lt;strong&gt;</bpt>New-AzureDataFactoryLinkedService<ept id="2">&lt;/strong&gt;</ept> cmdlet to create the linked <bpt id="4">&lt;strong&gt;</bpt>StorageLinkedService<ept id="4">&lt;/strong&gt;</ept> service.</target>
          </trans-unit>
          <trans-unit id="142" xml:space="preserve">
            <source>If you hadn't run the <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> cmdlet and assigned the output to the <bpt id="4">&lt;strong&gt;</bpt>$df<ept id="4">&lt;/strong&gt;</ept> variable, you would have to specify values for the <bpt id="6">&lt;em&gt;</bpt>ResourceGroupName<ept id="6">&lt;/em&gt;</ept> and <bpt id="8">&lt;em&gt;</bpt>DataFactoryName<ept id="8">&lt;/em&gt;</ept> parameters as follows.</source>
            <target state="new">If you hadn't run the <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> cmdlet and assigned the output to the <bpt id="4">&lt;strong&gt;</bpt>$df<ept id="4">&lt;/strong&gt;</ept> variable, you would have to specify values for the <bpt id="6">&lt;em&gt;</bpt>ResourceGroupName<ept id="6">&lt;/em&gt;</ept> and <bpt id="8">&lt;em&gt;</bpt>DataFactoryName<ept id="8">&lt;/em&gt;</ept> parameters as follows.</target>
          </trans-unit>
          <trans-unit id="143" xml:space="preserve">
            <source>If you close Azure PowerShell in the middle of the tutorial, you will have run the <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> cmdlet next time you start Azure PowerShell to complete the tutorial.</source>
            <target state="new">If you close Azure PowerShell in the middle of the tutorial, you will have run the <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> cmdlet next time you start Azure PowerShell to complete the tutorial.</target>
          </trans-unit>
          <trans-unit id="144" xml:space="preserve">
            <source>Create Azure HDInsight linked service</source>
            <target state="new">Create Azure HDInsight linked service</target>
          </trans-unit>
          <trans-unit id="145" xml:space="preserve">
            <source>Now, you will create a linked service for an on-demand Azure HDInsight cluster that will be used to run the Hive script.</source>
            <target state="new">Now, you will create a linked service for an on-demand Azure HDInsight cluster that will be used to run the Hive script.</target>
          </trans-unit>
          <trans-unit id="146" xml:space="preserve">
            <source>Create a JSON file named HDInsightOnDemandLinkedService.json in the C:\ADFGetStartedPSH folder with the following content.</source>
            <target state="new">Create a JSON file named HDInsightOnDemandLinkedService.json in the C:\ADFGetStartedPSH folder with the following content.</target>
          </trans-unit>
          <trans-unit id="147" xml:space="preserve">
            <source>The following table provides descriptions for the JSON properties used in the snippet:</source>
            <target state="new">The following table provides descriptions for the JSON properties used in the snippet:</target>
          </trans-unit>
          <trans-unit id="148" xml:space="preserve">
            <source>Property</source>
            <target state="new">Property</target>
          </trans-unit>
          <trans-unit id="149" xml:space="preserve">
            <source>Description</source>
            <target state="new">Description</target>
          </trans-unit>
          <trans-unit id="150" xml:space="preserve">
            <source>Version</source>
            <target state="new">Version</target>
          </trans-unit>
          <trans-unit id="151" xml:space="preserve">
            <source>This specifies that the version of the HDInsight created to be 3.1.</source>
            <target state="new">This specifies that the version of the HDInsight created to be 3.1.</target>
          </trans-unit>
          <trans-unit id="152" xml:space="preserve">
            <source>ClusterSize</source>
            <target state="new">ClusterSize</target>
          </trans-unit>
          <trans-unit id="153" xml:space="preserve">
            <source>This creates a one node HDInsight cluster.</source>
            <target state="new">This creates a one node HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="154" xml:space="preserve">
            <source>TimeToLive</source>
            <target state="new">TimeToLive</target>
          </trans-unit>
          <trans-unit id="155" xml:space="preserve">
            <source>This specifies that the idle time for the HDInsight cluster, before it is deleted.</source>
            <target state="new">This specifies that the idle time for the HDInsight cluster, before it is deleted.</target>
          </trans-unit>
          <trans-unit id="156" xml:space="preserve">
            <source>JobsContainer</source>
            <target state="new">JobsContainer</target>
          </trans-unit>
          <trans-unit id="157" xml:space="preserve">
            <source>This specifies the name of the job container that will be created to store the logs that are generated by HDInsight</source>
            <target state="new">This specifies the name of the job container that will be created to store the logs that are generated by HDInsight</target>
          </trans-unit>
          <trans-unit id="158" xml:space="preserve">
            <source>linkedServiceName</source>
            <target state="new">linkedServiceName</target>
          </trans-unit>
          <trans-unit id="159" xml:space="preserve">
            <source>This specifies the storage account that will be used to store the logs that are generated by HDInsight</source>
            <target state="new">This specifies the storage account that will be used to store the logs that are generated by HDInsight</target>
          </trans-unit>
          <trans-unit id="160" xml:space="preserve">
            <source>Run the <bpt id="2">&lt;strong&gt;</bpt>New-AzureDataFactoryLinkedService<ept id="2">&lt;/strong&gt;</ept> cmdlet to create the linked service called HDInsightOnDemandLinkedService.</source>
            <target state="new">Run the <bpt id="2">&lt;strong&gt;</bpt>New-AzureDataFactoryLinkedService<ept id="2">&lt;/strong&gt;</ept> cmdlet to create the linked service called HDInsightOnDemandLinkedService.</target>
          </trans-unit>
          <trans-unit id="161" xml:space="preserve">
            <source>Create the output dataset</source>
            <target state="new">Create the output dataset</target>
          </trans-unit>
          <trans-unit id="162" xml:space="preserve">
            <source>Now, you will create the output dataset to represent the data stored in the Azure Blob storage.</source>
            <target state="new">Now, you will create the output dataset to represent the data stored in the Azure Blob storage.</target>
          </trans-unit>
          <trans-unit id="163" xml:space="preserve">
            <source>Create a JSON file named OutputTable.json in the C:\ADFGetStartedPSH folder with the following content:</source>
            <target state="new">Create a JSON file named OutputTable.json in the C:\ADFGetStartedPSH folder with the following content:</target>
          </trans-unit>
          <trans-unit id="164" xml:space="preserve">
            <source>In the previous example, you are creating a dataset called <bpt id="2">&lt;strong&gt;</bpt>AzureBlobOutput<ept id="2">&lt;/strong&gt;</ept>, and specifying the structure of the data that will be produced by the Hive script.</source>
            <target state="new">In the previous example, you are creating a dataset called <bpt id="2">&lt;strong&gt;</bpt>AzureBlobOutput<ept id="2">&lt;/strong&gt;</ept>, and specifying the structure of the data that will be produced by the Hive script.</target>
          </trans-unit>
          <trans-unit id="165" xml:space="preserve">
            <source>In addition, you specify that the results are stored in the blob container called <bpt id="2">&lt;strong&gt;</bpt>data<ept id="2">&lt;/strong&gt;</ept> and the folder called <bpt id="4">&lt;strong&gt;</bpt>partitioneddata<ept id="4">&lt;/strong&gt;</ept>.</source>
            <target state="new">In addition, you specify that the results are stored in the blob container called <bpt id="2">&lt;strong&gt;</bpt>data<ept id="2">&lt;/strong&gt;</ept> and the folder called <bpt id="4">&lt;strong&gt;</bpt>partitioneddata<ept id="4">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="166" xml:space="preserve">
            <source>The <bpt id="2">&lt;strong&gt;</bpt>availability<ept id="2">&lt;/strong&gt;</ept> section specifies that the output dataset is produced on a monthly basis.</source>
            <target state="new">The <bpt id="2">&lt;strong&gt;</bpt>availability<ept id="2">&lt;/strong&gt;</ept> section specifies that the output dataset is produced on a monthly basis.</target>
          </trans-unit>
          <trans-unit id="167" xml:space="preserve">
            <source>Run the following command in Azure PowerShell to create the Data Factory table.</source>
            <target state="new">Run the following command in Azure PowerShell to create the Data Factory table.</target>
          </trans-unit>
          <trans-unit id="168" xml:space="preserve">
            <source>Step 3: Creating your first pipeline</source>
            <target state="new">Step 3: Creating your first pipeline</target>
          </trans-unit>
          <trans-unit id="169" xml:space="preserve">
            <source>In this step, you will create your first pipeline.</source>
            <target state="new">In this step, you will create your first pipeline.</target>
          </trans-unit>
          <trans-unit id="170" xml:space="preserve">
            <source>Create a JSON file named MyFirstPipelinePSH.json in the C:\ADFGetStartedPSH folder with the following content:</source>
            <target state="new">Create a JSON file named MyFirstPipelinePSH.json in the C:\ADFGetStartedPSH folder with the following content:</target>
          </trans-unit>
          <trans-unit id="171" xml:space="preserve">
            <source>Replace <bpt id="2">&lt;strong&gt;</bpt>storageaccountname<ept id="2">&lt;/strong&gt;</ept> with the name of your storage account in the  JSON.</source>
            <target state="new">Replace <bpt id="2">&lt;strong&gt;</bpt>storageaccountname<ept id="2">&lt;/strong&gt;</ept> with the name of your storage account in the  JSON.</target>
          </trans-unit>
          <trans-unit id="172" xml:space="preserve">
            <source>In the previous example, you are creating a pipeline that consists of a single activity that uses Hive to process data on an HDInsight cluster.</source>
            <target state="new">In the previous example, you are creating a pipeline that consists of a single activity that uses Hive to process data on an HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="173" xml:space="preserve">
            <source>The Hive script file, partitionweblogs.hql, is stored in the Azure storage account (specified by the scriptLinkedService, called StorageLinkedService), and in a container called <bpt id="2">&lt;strong&gt;</bpt>script<ept id="2">&lt;/strong&gt;</ept>.</source>
            <target state="new">The Hive script file, partitionweblogs.hql, is stored in the Azure storage account (specified by the scriptLinkedService, called StorageLinkedService), and in a container called <bpt id="2">&lt;strong&gt;</bpt>script<ept id="2">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="174" xml:space="preserve">
            <source>The <bpt id="2">&lt;strong&gt;</bpt>extendedProperties<ept id="2">&lt;/strong&gt;</ept> section is used to specify the runtime settings that will be passed to the hive script as Hive configuration values (for example, ${hiveconf:PartitionedData}).</source>
            <target state="new">The <bpt id="2">&lt;strong&gt;</bpt>extendedProperties<ept id="2">&lt;/strong&gt;</ept> section is used to specify the runtime settings that will be passed to the hive script as Hive configuration values (for example, ${hiveconf:PartitionedData}).</target>
          </trans-unit>
          <trans-unit id="175" xml:space="preserve">
            <source>The <bpt id="2">&lt;strong&gt;</bpt>start<ept id="2">&lt;/strong&gt;</ept> and <bpt id="4">&lt;strong&gt;</bpt>end<ept id="4">&lt;/strong&gt;</ept> properties of the pipeline specifies the active period of the pipeline.</source>
            <target state="new">The <bpt id="2">&lt;strong&gt;</bpt>start<ept id="2">&lt;/strong&gt;</ept> and <bpt id="4">&lt;strong&gt;</bpt>end<ept id="4">&lt;/strong&gt;</ept> properties of the pipeline specifies the active period of the pipeline.</target>
          </trans-unit>
          <trans-unit id="176" xml:space="preserve">
            <source>In the activity JSON, you specify that the Hive script runs on the computer specified by the linked service – <bpt id="2">&lt;strong&gt;</bpt>HDInsightOnDemandLinkedService<ept id="2">&lt;/strong&gt;</ept>.</source>
            <target state="new">In the activity JSON, you specify that the Hive script runs on the computer specified by the linked service – <bpt id="2">&lt;strong&gt;</bpt>HDInsightOnDemandLinkedService<ept id="2">&lt;/strong&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="177" xml:space="preserve">
            <source>Run the following command to create the Data Factory table.</source>
            <target state="new">Run the following command to create the Data Factory table.</target>
          </trans-unit>
          <trans-unit id="178" xml:space="preserve">
            <source>Congratulations, you have successfully created your first pipeline using Azure PowerShell!</source>
            <target state="new">Congratulations, you have successfully created your first pipeline using Azure PowerShell!</target>
          </trans-unit>
          <trans-unit id="179" xml:space="preserve">
            <source><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> Monitor the datasets and pipeline</source>
            <target state="new"><bpt id="1">&lt;html&gt;</bpt><ept id="1">&lt;/html&gt;</ept><bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept> Monitor the datasets and pipeline</target>
          </trans-unit>
          <trans-unit id="180" xml:space="preserve">
            <source>In this step, you will use Azure PowerShell to monitor what’s going on in an Azure data factory.</source>
            <target state="new">In this step, you will use Azure PowerShell to monitor what’s going on in an Azure data factory.</target>
          </trans-unit>
          <trans-unit id="181" xml:space="preserve">
            <source>Run <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> and assign the output to a <bpt id="4">&lt;strong&gt;</bpt>$df<ept id="4">&lt;/strong&gt;</ept> variable.</source>
            <target state="new">Run <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactory<ept id="2">&lt;/strong&gt;</ept> and assign the output to a <bpt id="4">&lt;strong&gt;</bpt>$df<ept id="4">&lt;/strong&gt;</ept> variable.</target>
          </trans-unit>
          <trans-unit id="182" xml:space="preserve">
            <source>Run <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactorySlice<ept id="2">&lt;/strong&gt;</ept> to get details about all slices of the <bpt id="4">&lt;strong&gt;</bpt>EmpSQLTable<ept id="4">&lt;/strong&gt;</ept>, which is the output table of the pipeline.</source>
            <target state="new">Run <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactorySlice<ept id="2">&lt;/strong&gt;</ept> to get details about all slices of the <bpt id="4">&lt;strong&gt;</bpt>EmpSQLTable<ept id="4">&lt;/strong&gt;</ept>, which is the output table of the pipeline.</target>
          </trans-unit>
          <trans-unit id="183" xml:space="preserve">
            <source>Notice that the StartDateTime you specify here is the same start time specified in the pipeline JSON.</source>
            <target state="new">Notice that the StartDateTime you specify here is the same start time specified in the pipeline JSON.</target>
          </trans-unit>
          <trans-unit id="184" xml:space="preserve">
            <source>You should see output similar to the following.</source>
            <target state="new">You should see output similar to the following.</target>
          </trans-unit>
          <trans-unit id="185" xml:space="preserve">
            <source>Run <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactoryRun<ept id="2">&lt;/strong&gt;</ept> to get the details of activity runs for a specific slice.</source>
            <target state="new">Run <bpt id="2">&lt;strong&gt;</bpt>Get-AzureDataFactoryRun<ept id="2">&lt;/strong&gt;</ept> to get the details of activity runs for a specific slice.</target>
          </trans-unit>
          <trans-unit id="186" xml:space="preserve">
            <source>You should see output similar to the following.</source>
            <target state="new">You should see output similar to the following.</target>
          </trans-unit>
          <trans-unit id="187" xml:space="preserve">
            <source>You can keep running this cmdlet until you see the slice in Ready state or Failed state.</source>
            <target state="new">You can keep running this cmdlet until you see the slice in Ready state or Failed state.</target>
          </trans-unit>
          <trans-unit id="188" xml:space="preserve">
            <source>When the slice is in Ready state, check the partitioneddata folder in the data container in your blob storage for the output data.</source>
            <target state="new">When the slice is in Ready state, check the partitioneddata folder in the data container in your blob storage for the output data.</target>
          </trans-unit>
          <trans-unit id="189" xml:space="preserve">
            <source>Note that the creation of an on-demand HDInsight cluster usually takes some time.</source>
            <target state="new">Note that the creation of an on-demand HDInsight cluster usually takes some time.</target>
          </trans-unit>
          <trans-unit id="190" xml:space="preserve">
            <source>See <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Data Factory Cmdlet Reference<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> for comprehensive documentation on Data Factory cmdlets.</source>
            <target state="new">See <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Data Factory Cmdlet Reference<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept> for comprehensive documentation on Data Factory cmdlets.</target>
          </trans-unit>
          <trans-unit id="191" xml:space="preserve">
            <source>Next steps</source>
            <target state="new">Next steps</target>
          </trans-unit>
          <trans-unit id="192" xml:space="preserve">
            <source>In this article, you have created a pipeline with a transformation activity (HDInsight Activity) that runs a Hive script on an on-demand Azure HDInsight cluster.</source>
            <target state="new">In this article, you have created a pipeline with a transformation activity (HDInsight Activity) that runs a Hive script on an on-demand Azure HDInsight cluster.</target>
          </trans-unit>
          <trans-unit id="193" xml:space="preserve">
            <source>To see how to use a Copy Activity to copy data from an Azure Blob to Azure SQL, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Tutorial: Copy data from an Azure Blob to Azure SQL<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">To see how to use a Copy Activity to copy data from an Azure Blob to Azure SQL, see <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>Tutorial: Copy data from an Azure Blob to Azure SQL<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="194" xml:space="preserve">
            <source>Send Feedback</source>
            <target state="new">Send Feedback</target>
          </trans-unit>
          <trans-unit id="195" xml:space="preserve">
            <source>We would really appreciate your feedback on this article.</source>
            <target state="new">We would really appreciate your feedback on this article.</target>
          </trans-unit>
          <trans-unit id="196" xml:space="preserve">
            <source>Please take a few minutes to submit your feedback via <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>email<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</source>
            <target state="new">Please take a few minutes to submit your feedback via <bpt id="2CapsExtId1">&lt;link&gt;</bpt><bpt id="2CapsExtId2">&lt;linkText&gt;</bpt>email<ept id="2CapsExtId2">&lt;/linkText&gt;</ept><bpt id="2CapsExtId3">&lt;title&gt;</bpt><ept id="2CapsExtId3">&lt;/title&gt;</ept><ept id="2CapsExtId1">&lt;/link&gt;</ept>.</target>
          </trans-unit>
        </group>
      </group>
    </body>
  </file>
</xliff>