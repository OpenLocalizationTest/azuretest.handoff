<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="zh-tw" original="2/20/2016 11:51:31 AM" tool-id="MarkdownTransformer" product-name="N/A" product-version="N/A" build-num="1">
    <header>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">51999f93932902033d1e9a1fdd55115c73f24b2c</xliffext:olfilehash>
      <tool tool-id="MarkdownTransformer" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group extype="content">
        <group id="101">
          <trans-unit id="101" xml:space="preserve">
            <source>Develop Python MapReduce jobs with HDInsight | Microsoft Azure</source>
            <target state="new">Develop Python MapReduce jobs with HDInsight | Microsoft Azure</target>
          </trans-unit>
          <trans-unit id="102" xml:space="preserve">
            <source>Learn how to create and run Python MapReduce jobs on Linux-based HDInsight clusters.</source>
            <target state="new">Learn how to create and run Python MapReduce jobs on Linux-based HDInsight clusters.</target>
          </trans-unit>
          <trans-unit id="103" xml:space="preserve">
            <source>Develop Python streaming programs for HDInsight</source>
            <target state="new">Develop Python streaming programs for HDInsight</target>
          </trans-unit>
          <trans-unit id="104" xml:space="preserve">
            <source>Hadoop provides a streaming API for MapReduce that enables you to write map and reduce functions in languages other than Java.</source>
            <target state="new">Hadoop provides a streaming API for MapReduce that enables you to write map and reduce functions in languages other than Java.</target>
          </trans-unit>
          <trans-unit id="105" xml:space="preserve">
            <source>In this article, you will learn how to use Python to perform MapReduce operations.</source>
            <target state="new">In this article, you will learn how to use Python to perform MapReduce operations.</target>
          </trans-unit>
          <trans-unit id="106" xml:space="preserve">
            <source>While the Python code in this document can be used with a Windows-based HDInsight cluster, the steps in this document are specific to Linux-based clusters.</source>
            <target state="new">While the Python code in this document can be used with a Windows-based HDInsight cluster, the steps in this document are specific to Linux-based clusters.</target>
          </trans-unit>
          <trans-unit id="107" xml:space="preserve">
            <source>This article is based on information and examples published by Michael Noll at [http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/](Writing an Hadoop MapReduce Program in Python).</source>
            <target state="new">This article is based on information and examples published by Michael Noll at [http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/](Writing an Hadoop MapReduce Program in Python).</target>
          </trans-unit>
          <trans-unit id="108" xml:space="preserve">
            <source>Prerequisites</source>
            <target state="new">Prerequisites</target>
          </trans-unit>
          <trans-unit id="109" xml:space="preserve">
            <source>To complete the steps in this article, you will need the following:</source>
            <target state="new">To complete the steps in this article, you will need the following:</target>
          </trans-unit>
          <trans-unit id="110" xml:space="preserve">
            <source>A Linux-based Hadoop on HDInsight cluster</source>
            <target state="new">A Linux-based Hadoop on HDInsight cluster</target>
          </trans-unit>
          <trans-unit id="111" xml:space="preserve">
            <source>A text editor</source>
            <target state="new">A text editor</target>
          </trans-unit>
          <trans-unit id="112" xml:space="preserve">
            <source>For Windows clients, PuTTY and PSCP.</source>
            <target state="new">For Windows clients, PuTTY and PSCP.</target>
          </trans-unit>
          <trans-unit id="113" xml:space="preserve">
            <source>These utilities are available from the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>PuTTY Download Page<bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept>.</source>
            <target state="new">These utilities are available from the <bpt id="2">&lt;html&gt;</bpt><ept id="2">&lt;/html&gt;</ept>PuTTY Download Page<bpt id="4">&lt;html&gt;</bpt><ept id="4">&lt;/html&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="114" xml:space="preserve">
            <source>Word count</source>
            <target state="new">Word count</target>
          </trans-unit>
          <trans-unit id="115" xml:space="preserve">
            <source>For this example, you will implement a basic word count by using a mapper and reducer.</source>
            <target state="new">For this example, you will implement a basic word count by using a mapper and reducer.</target>
          </trans-unit>
          <trans-unit id="116" xml:space="preserve">
            <source>The mapper breaks sentences into individual words, and the reducer aggregates the words and counts to produce the output.</source>
            <target state="new">The mapper breaks sentences into individual words, and the reducer aggregates the words and counts to produce the output.</target>
          </trans-unit>
          <trans-unit id="117" xml:space="preserve">
            <source>The following flowchart illustrates what happens during the map and reduce phases.</source>
            <target state="new">The following flowchart illustrates what happens during the map and reduce phases.</target>
          </trans-unit>
          <trans-unit id="118" xml:space="preserve">
            <source><bpt id="1">&lt;linkText&gt;</bpt>illustration of map reduce<ept id="1">&lt;/linkText&gt;</ept></source>
            <target state="new"><bpt id="1">&lt;linkText&gt;</bpt>illustration of map reduce<ept id="1">&lt;/linkText&gt;</ept></target>
          </trans-unit>
          <trans-unit id="119" xml:space="preserve">
            <source>Why Python?</source>
            <target state="new">Why Python?</target>
          </trans-unit>
          <trans-unit id="120" xml:space="preserve">
            <source>Python is a general-purpose, high-level programming language that allows you to express concepts in fewer lines of code than many other languages.</source>
            <target state="new">Python is a general-purpose, high-level programming language that allows you to express concepts in fewer lines of code than many other languages.</target>
          </trans-unit>
          <trans-unit id="121" xml:space="preserve">
            <source>It has recently became popular with data scientists as a prototyping language because its interpreted nature, dynamic typing, and elegant syntax make it suitable for rapid application development.</source>
            <target state="new">It has recently became popular with data scientists as a prototyping language because its interpreted nature, dynamic typing, and elegant syntax make it suitable for rapid application development.</target>
          </trans-unit>
          <trans-unit id="122" xml:space="preserve">
            <source>Python is installed on all HDInsight clusters.</source>
            <target state="new">Python is installed on all HDInsight clusters.</target>
          </trans-unit>
          <trans-unit id="123" xml:space="preserve">
            <source>Streaming MapReduce</source>
            <target state="new">Streaming MapReduce</target>
          </trans-unit>
          <trans-unit id="124" xml:space="preserve">
            <source>Hadoop allows you to specify a file that contains the map and reduce logic that is used by a job.</source>
            <target state="new">Hadoop allows you to specify a file that contains the map and reduce logic that is used by a job.</target>
          </trans-unit>
          <trans-unit id="125" xml:space="preserve">
            <source>The specific requirements for the map and reduce logic are:</source>
            <target state="new">The specific requirements for the map and reduce logic are:</target>
          </trans-unit>
          <trans-unit id="126" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Input<ept id="1">&lt;/strong&gt;</ept>: The map and reduce components must read input data from STDIN.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Input<ept id="1">&lt;/strong&gt;</ept>: The map and reduce components must read input data from STDIN.</target>
          </trans-unit>
          <trans-unit id="127" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Output<ept id="1">&lt;/strong&gt;</ept>: The map and reduce components must write output data to STDOUT.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Output<ept id="1">&lt;/strong&gt;</ept>: The map and reduce components must write output data to STDOUT.</target>
          </trans-unit>
          <trans-unit id="128" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>Data format<ept id="1">&lt;/strong&gt;</ept>: The data consumed and produced must be a key/value pair, separated by a tab character.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>Data format<ept id="1">&lt;/strong&gt;</ept>: The data consumed and produced must be a key/value pair, separated by a tab character.</target>
          </trans-unit>
          <trans-unit id="129" xml:space="preserve">
            <source>Python can easily handle these requirements by using the <bpt id="2">&lt;strong&gt;</bpt>sys<ept id="2">&lt;/strong&gt;</ept> module to read from STDIN and using <bpt id="4">&lt;strong&gt;</bpt>print<ept id="4">&lt;/strong&gt;</ept> to print to STDOUT.</source>
            <target state="new">Python can easily handle these requirements by using the <bpt id="2">&lt;strong&gt;</bpt>sys<ept id="2">&lt;/strong&gt;</ept> module to read from STDIN and using <bpt id="4">&lt;strong&gt;</bpt>print<ept id="4">&lt;/strong&gt;</ept> to print to STDOUT.</target>
          </trans-unit>
          <trans-unit id="130" xml:space="preserve">
            <source>The remaining task is simply formatting the data with a tab (<bpt id="2">&lt;code&gt;</bpt>\t<ept id="2">&lt;/code&gt;</ept>) character between the key and value.</source>
            <target state="new">The remaining task is simply formatting the data with a tab (<bpt id="2">&lt;code&gt;</bpt>\t<ept id="2">&lt;/code&gt;</ept>) character between the key and value.</target>
          </trans-unit>
          <trans-unit id="131" xml:space="preserve">
            <source>Create the mapper and reducer</source>
            <target state="new">Create the mapper and reducer</target>
          </trans-unit>
          <trans-unit id="132" xml:space="preserve">
            <source>The mapper and reducer are text files, in this case <bpt id="2">&lt;strong&gt;</bpt>mapper.py<ept id="2">&lt;/strong&gt;</ept> and <bpt id="4">&lt;strong&gt;</bpt>reducer.py<ept id="4">&lt;/strong&gt;</ept> (to make it clear which does what).</source>
            <target state="new">The mapper and reducer are text files, in this case <bpt id="2">&lt;strong&gt;</bpt>mapper.py<ept id="2">&lt;/strong&gt;</ept> and <bpt id="4">&lt;strong&gt;</bpt>reducer.py<ept id="4">&lt;/strong&gt;</ept> (to make it clear which does what).</target>
          </trans-unit>
          <trans-unit id="133" xml:space="preserve">
            <source>You can create these by using the editor of your choice.</source>
            <target state="new">You can create these by using the editor of your choice.</target>
          </trans-unit>
          <trans-unit id="134" xml:space="preserve">
            <source>Mapper.py</source>
            <target state="new">Mapper.py</target>
          </trans-unit>
          <trans-unit id="135" xml:space="preserve">
            <source>Create a new file named <bpt id="2">&lt;strong&gt;</bpt>mapper.py<ept id="2">&lt;/strong&gt;</ept> and use the following code as the content:</source>
            <target state="new">Create a new file named <bpt id="2">&lt;strong&gt;</bpt>mapper.py<ept id="2">&lt;/strong&gt;</ept> and use the following code as the content:</target>
          </trans-unit>
          <trans-unit id="136" xml:space="preserve">
            <source>Take a moment to read through the code so you can understand what it does.</source>
            <target state="new">Take a moment to read through the code so you can understand what it does.</target>
          </trans-unit>
          <trans-unit id="137" xml:space="preserve">
            <source>Reducer.py</source>
            <target state="new">Reducer.py</target>
          </trans-unit>
          <trans-unit id="138" xml:space="preserve">
            <source>Create a new file named <bpt id="2">&lt;strong&gt;</bpt>reducer.py<ept id="2">&lt;/strong&gt;</ept> and use the following code as the content:</source>
            <target state="new">Create a new file named <bpt id="2">&lt;strong&gt;</bpt>reducer.py<ept id="2">&lt;/strong&gt;</ept> and use the following code as the content:</target>
          </trans-unit>
          <trans-unit id="139" xml:space="preserve">
            <source>Upload the files</source>
            <target state="new">Upload the files</target>
          </trans-unit>
          <trans-unit id="140" xml:space="preserve">
            <source>Both <bpt id="2">&lt;strong&gt;</bpt>mapper.py<ept id="2">&lt;/strong&gt;</ept> and <bpt id="4">&lt;strong&gt;</bpt>reducer.py<ept id="4">&lt;/strong&gt;</ept> must be on the head node of the cluster before we can run them.</source>
            <target state="new">Both <bpt id="2">&lt;strong&gt;</bpt>mapper.py<ept id="2">&lt;/strong&gt;</ept> and <bpt id="4">&lt;strong&gt;</bpt>reducer.py<ept id="4">&lt;/strong&gt;</ept> must be on the head node of the cluster before we can run them.</target>
          </trans-unit>
          <trans-unit id="141" xml:space="preserve">
            <source>The easiest way to upload them is to use <bpt id="2">&lt;strong&gt;</bpt>scp<ept id="2">&lt;/strong&gt;</ept> (<bpt id="4">&lt;strong&gt;</bpt>pscp<ept id="4">&lt;/strong&gt;</ept> if you are using a Windows client).</source>
            <target state="new">The easiest way to upload them is to use <bpt id="2">&lt;strong&gt;</bpt>scp<ept id="2">&lt;/strong&gt;</ept> (<bpt id="4">&lt;strong&gt;</bpt>pscp<ept id="4">&lt;/strong&gt;</ept> if you are using a Windows client).</target>
          </trans-unit>
          <trans-unit id="142" xml:space="preserve">
            <source>From the client, in the same directory as <bpt id="2">&lt;strong&gt;</bpt>mapper.py<ept id="2">&lt;/strong&gt;</ept> and <bpt id="4">&lt;strong&gt;</bpt>reducer.py<ept id="4">&lt;/strong&gt;</ept>, use the following command.</source>
            <target state="new">From the client, in the same directory as <bpt id="2">&lt;strong&gt;</bpt>mapper.py<ept id="2">&lt;/strong&gt;</ept> and <bpt id="4">&lt;strong&gt;</bpt>reducer.py<ept id="4">&lt;/strong&gt;</ept>, use the following command.</target>
          </trans-unit>
          <trans-unit id="143" xml:space="preserve">
            <source>Replace <bpt id="2">&lt;strong&gt;</bpt>username<ept id="2">&lt;/strong&gt;</ept> with an SSH user, and <bpt id="4">&lt;strong&gt;</bpt>clustername<ept id="4">&lt;/strong&gt;</ept> with the name of your cluster.</source>
            <target state="new">Replace <bpt id="2">&lt;strong&gt;</bpt>username<ept id="2">&lt;/strong&gt;</ept> with an SSH user, and <bpt id="4">&lt;strong&gt;</bpt>clustername<ept id="4">&lt;/strong&gt;</ept> with the name of your cluster.</target>
          </trans-unit>
          <trans-unit id="144" xml:space="preserve">
            <source>This copies the files from the local system to the head node.</source>
            <target state="new">This copies the files from the local system to the head node.</target>
          </trans-unit>
          <trans-unit id="145" xml:space="preserve">
            <source>If you used a password to secure your SSH account, you will be prompted for the password.</source>
            <target state="new">If you used a password to secure your SSH account, you will be prompted for the password.</target>
          </trans-unit>
          <trans-unit id="146" xml:space="preserve">
            <source>If you used an SSH key, you may have to use the <bpt id="2">&lt;code&gt;</bpt>-i<ept id="2">&lt;/code&gt;</ept> parameter and the path to the private key, for example, <bpt id="4">&lt;code&gt;</bpt>scp -i /path/to/private/key mapper.py reducer.py username@clustername-ssh.azurehdinsight.net:<ept id="4">&lt;/code&gt;</ept>.</source>
            <target state="new">If you used an SSH key, you may have to use the <bpt id="2">&lt;code&gt;</bpt>-i<ept id="2">&lt;/code&gt;</ept> parameter and the path to the private key, for example, <bpt id="4">&lt;code&gt;</bpt>scp -i /path/to/private/key mapper.py reducer.py username@clustername-ssh.azurehdinsight.net:<ept id="4">&lt;/code&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="147" xml:space="preserve">
            <source>Run MapReduce</source>
            <target state="new">Run MapReduce</target>
          </trans-unit>
          <trans-unit id="148" xml:space="preserve">
            <source>Connect to the cluster by using SSH:</source>
            <target state="new">Connect to the cluster by using SSH:</target>
          </trans-unit>
          <trans-unit id="149" xml:space="preserve">
            <source>If you used a password to secure your SSH account, you will be prompted for the password.</source>
            <target state="new">If you used a password to secure your SSH account, you will be prompted for the password.</target>
          </trans-unit>
          <trans-unit id="150" xml:space="preserve">
            <source>If you used an SSH key, you may have to use the <bpt id="2">&lt;code&gt;</bpt>-i<ept id="2">&lt;/code&gt;</ept> parameter and the path to the private key, for example, <bpt id="4">&lt;code&gt;</bpt>ssh -i /path/to/private/key username@clustername-ssh.azurehdinsight.net<ept id="4">&lt;/code&gt;</ept>.</source>
            <target state="new">If you used an SSH key, you may have to use the <bpt id="2">&lt;code&gt;</bpt>-i<ept id="2">&lt;/code&gt;</ept> parameter and the path to the private key, for example, <bpt id="4">&lt;code&gt;</bpt>ssh -i /path/to/private/key username@clustername-ssh.azurehdinsight.net<ept id="4">&lt;/code&gt;</ept>.</target>
          </trans-unit>
          <trans-unit id="151" xml:space="preserve">
            <source>Use the following command to start the MapReduce job.</source>
            <target state="new">Use the following command to start the MapReduce job.</target>
          </trans-unit>
          <trans-unit id="152" xml:space="preserve">
            <source>This command has the following parts:</source>
            <target state="new">This command has the following parts:</target>
          </trans-unit>
          <trans-unit id="153" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>hadoop-streaming.jar<ept id="1">&lt;/strong&gt;</ept>: Used when performing streaming MapReduce operations.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>hadoop-streaming.jar<ept id="1">&lt;/strong&gt;</ept>: Used when performing streaming MapReduce operations.</target>
          </trans-unit>
          <trans-unit id="154" xml:space="preserve">
            <source>It interfaces Hadoop with the external MapReduce code you provide.</source>
            <target state="new">It interfaces Hadoop with the external MapReduce code you provide.</target>
          </trans-unit>
          <trans-unit id="155" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>-files<ept id="1">&lt;/strong&gt;</ept>: Tells Hadoop that the specified files are needed for this MapReduce job, and they should be copied to all the worker nodes.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>-files<ept id="1">&lt;/strong&gt;</ept>: Tells Hadoop that the specified files are needed for this MapReduce job, and they should be copied to all the worker nodes.</target>
          </trans-unit>
          <trans-unit id="156" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>-mapper<ept id="1">&lt;/strong&gt;</ept>: Tells Hadoop which file to use as the mapper.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>-mapper<ept id="1">&lt;/strong&gt;</ept>: Tells Hadoop which file to use as the mapper.</target>
          </trans-unit>
          <trans-unit id="157" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>-reducer<ept id="1">&lt;/strong&gt;</ept>: Tells Hadoop which file to use as the reducer.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>-reducer<ept id="1">&lt;/strong&gt;</ept>: Tells Hadoop which file to use as the reducer.</target>
          </trans-unit>
          <trans-unit id="158" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>-input<ept id="1">&lt;/strong&gt;</ept>: The input file that we should count words from.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>-input<ept id="1">&lt;/strong&gt;</ept>: The input file that we should count words from.</target>
          </trans-unit>
          <trans-unit id="159" xml:space="preserve">
            <source><bpt id="1">&lt;strong&gt;</bpt>-output<ept id="1">&lt;/strong&gt;</ept>: The directory that the output will be written to.</source>
            <target state="new"><bpt id="1">&lt;strong&gt;</bpt>-output<ept id="1">&lt;/strong&gt;</ept>: The directory that the output will be written to.</target>
          </trans-unit>
          <trans-unit id="160" xml:space="preserve">
            <source>This directory will be created by the job.</source>
            <target state="new">This directory will be created by the job.</target>
          </trans-unit>
          <trans-unit id="161" xml:space="preserve">
            <source>You should see a bunch of <bpt id="2">&lt;strong&gt;</bpt>INFO<ept id="2">&lt;/strong&gt;</ept> statements as the job starts, and finally see the <bpt id="4">&lt;strong&gt;</bpt>map<ept id="4">&lt;/strong&gt;</ept> and <bpt id="6">&lt;strong&gt;</bpt>reduce<ept id="6">&lt;/strong&gt;</ept> operation displayed as percentages.</source>
            <target state="new">You should see a bunch of <bpt id="2">&lt;strong&gt;</bpt>INFO<ept id="2">&lt;/strong&gt;</ept> statements as the job starts, and finally see the <bpt id="4">&lt;strong&gt;</bpt>map<ept id="4">&lt;/strong&gt;</ept> and <bpt id="6">&lt;strong&gt;</bpt>reduce<ept id="6">&lt;/strong&gt;</ept> operation displayed as percentages.</target>
          </trans-unit>
          <trans-unit id="162" xml:space="preserve">
            <source>You will receive status information about the job when it completes.</source>
            <target state="new">You will receive status information about the job when it completes.</target>
          </trans-unit>
          <trans-unit id="163" xml:space="preserve">
            <source>View the output</source>
            <target state="new">View the output</target>
          </trans-unit>
          <trans-unit id="164" xml:space="preserve">
            <source>When the job is complete, use the following command to view the output:</source>
            <target state="new">When the job is complete, use the following command to view the output:</target>
          </trans-unit>
          <trans-unit id="165" xml:space="preserve">
            <source>This should display a list of words and how many times the word occurred.</source>
            <target state="new">This should display a list of words and how many times the word occurred.</target>
          </trans-unit>
          <trans-unit id="166" xml:space="preserve">
            <source>The following is an sample of the output data:</source>
            <target state="new">The following is an sample of the output data:</target>
          </trans-unit>
          <trans-unit id="167" xml:space="preserve">
            <source>Next steps</source>
            <target state="new">Next steps</target>
          </trans-unit>
          <trans-unit id="168" xml:space="preserve">
            <source>Now that you have learned how to use streaming MapRedcue jobs with HDInsight, use the following links to explore other ways to work with Azure HDInsight.</source>
            <target state="new">Now that you have learned how to use streaming MapRedcue jobs with HDInsight, use the following links to explore other ways to work with Azure HDInsight.</target>
          </trans-unit>
          <trans-unit id="169" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Hive with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="170" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Pig with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use Pig with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
          <trans-unit id="171" xml:space="preserve">
            <source><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce jobs with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></source>
            <target state="new"><bpt id="1CapsExtId1">&lt;link&gt;</bpt><bpt id="1CapsExtId2">&lt;linkText&gt;</bpt>Use MapReduce jobs with HDInsight<ept id="1CapsExtId2">&lt;/linkText&gt;</ept><bpt id="1CapsExtId3">&lt;title&gt;</bpt><ept id="1CapsExtId3">&lt;/title&gt;</ept><ept id="1CapsExtId1">&lt;/link&gt;</ept></target>
          </trans-unit>
        </group>
      </group>
    </body>
  </file>
</xliff>